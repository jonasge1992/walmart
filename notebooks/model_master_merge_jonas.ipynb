{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c91c641-7676-421d-aef8-79ef55aa0315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5842e-7d08-4165-90ec-b7edfc62dcc7",
   "metadata": {},
   "source": [
    "# 0 Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023fbbd9-6c97-41d6-bf76-920c4aee83ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>...</th>\n",
       "      <th>event_name_1_StPatricksDay</th>\n",
       "      <th>event_name_1_SuperBowl</th>\n",
       "      <th>event_name_1_Thanksgiving</th>\n",
       "      <th>event_name_1_ValentinesDay</th>\n",
       "      <th>event_name_1_VeteransDay</th>\n",
       "      <th>event_name_1_missing</th>\n",
       "      <th>wday_sin</th>\n",
       "      <th>wday_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_2_197_CA_1_validation</td>\n",
       "      <td>FOODS_2_197</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>CA</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_080_CA_1_validation</td>\n",
       "      <td>FOODS_3_080</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_090_CA_1_validation</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_120_CA_1_validation</td>\n",
       "      <td>FOODS_3_120</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_252_CA_1_validation</td>\n",
       "      <td>FOODS_3_252</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_555_CA_1_validation</td>\n",
       "      <td>FOODS_3_555</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_586_CA_1_validation</td>\n",
       "      <td>FOODS_3_586</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_587_CA_1_validation</td>\n",
       "      <td>FOODS_3_587</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_714_CA_1_validation</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_808_CA_1_validation</td>\n",
       "      <td>FOODS_3_808</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19130 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id      item_id  dept_id state_id  sales  \\\n",
       "date                                                                            \n",
       "2011-01-29  FOODS_2_197_CA_1_validation  FOODS_2_197  FOODS_2       CA     38   \n",
       "2011-01-29  FOODS_3_080_CA_1_validation  FOODS_3_080  FOODS_3       CA     33   \n",
       "2011-01-29  FOODS_3_090_CA_1_validation  FOODS_3_090  FOODS_3       CA    107   \n",
       "2011-01-29  FOODS_3_120_CA_1_validation  FOODS_3_120  FOODS_3       CA      0   \n",
       "2011-01-29  FOODS_3_252_CA_1_validation  FOODS_3_252  FOODS_3       CA     19   \n",
       "...                                 ...          ...      ...      ...    ...   \n",
       "2016-04-24  FOODS_3_555_CA_1_validation  FOODS_3_555  FOODS_3       CA     24   \n",
       "2016-04-24  FOODS_3_586_CA_1_validation  FOODS_3_586  FOODS_3       CA     54   \n",
       "2016-04-24  FOODS_3_587_CA_1_validation  FOODS_3_587  FOODS_3       CA     26   \n",
       "2016-04-24  FOODS_3_714_CA_1_validation  FOODS_3_714  FOODS_3       CA     27   \n",
       "2016-04-24  FOODS_3_808_CA_1_validation  FOODS_3_808  FOODS_3       CA      0   \n",
       "\n",
       "            wday  month  year event_name_2  snap_CA  ...  \\\n",
       "date                                                 ...   \n",
       "2011-01-29     1      1   0.0      missing        0  ...   \n",
       "2011-01-29     1      1   0.0      missing        0  ...   \n",
       "2011-01-29     1      1   0.0      missing        0  ...   \n",
       "2011-01-29     1      1   0.0      missing        0  ...   \n",
       "2011-01-29     1      1   0.0      missing        0  ...   \n",
       "...          ...    ...   ...          ...      ...  ...   \n",
       "2016-04-24     2      4   1.0      missing        0  ...   \n",
       "2016-04-24     2      4   1.0      missing        0  ...   \n",
       "2016-04-24     2      4   1.0      missing        0  ...   \n",
       "2016-04-24     2      4   1.0      missing        0  ...   \n",
       "2016-04-24     2      4   1.0      missing        0  ...   \n",
       "\n",
       "            event_name_1_StPatricksDay  event_name_1_SuperBowl  \\\n",
       "date                                                             \n",
       "2011-01-29                         0.0                     0.0   \n",
       "2011-01-29                         0.0                     0.0   \n",
       "2011-01-29                         0.0                     0.0   \n",
       "2011-01-29                         0.0                     0.0   \n",
       "2011-01-29                         0.0                     0.0   \n",
       "...                                ...                     ...   \n",
       "2016-04-24                         0.0                     0.0   \n",
       "2016-04-24                         0.0                     0.0   \n",
       "2016-04-24                         0.0                     0.0   \n",
       "2016-04-24                         0.0                     0.0   \n",
       "2016-04-24                         0.0                     0.0   \n",
       "\n",
       "            event_name_1_Thanksgiving  event_name_1_ValentinesDay  \\\n",
       "date                                                                \n",
       "2011-01-29                        0.0                         0.0   \n",
       "2011-01-29                        0.0                         0.0   \n",
       "2011-01-29                        0.0                         0.0   \n",
       "2011-01-29                        0.0                         0.0   \n",
       "2011-01-29                        0.0                         0.0   \n",
       "...                               ...                         ...   \n",
       "2016-04-24                        0.0                         0.0   \n",
       "2016-04-24                        0.0                         0.0   \n",
       "2016-04-24                        0.0                         0.0   \n",
       "2016-04-24                        0.0                         0.0   \n",
       "2016-04-24                        0.0                         0.0   \n",
       "\n",
       "            event_name_1_VeteransDay  event_name_1_missing  wday_sin  \\\n",
       "date                                                                   \n",
       "2011-01-29                       0.0                   1.0  0.781832   \n",
       "2011-01-29                       0.0                   1.0  0.781832   \n",
       "2011-01-29                       0.0                   1.0  0.781832   \n",
       "2011-01-29                       0.0                   1.0  0.781832   \n",
       "2011-01-29                       0.0                   1.0  0.781832   \n",
       "...                              ...                   ...       ...   \n",
       "2016-04-24                       0.0                   1.0  0.974928   \n",
       "2016-04-24                       0.0                   1.0  0.974928   \n",
       "2016-04-24                       0.0                   1.0  0.974928   \n",
       "2016-04-24                       0.0                   1.0  0.974928   \n",
       "2016-04-24                       0.0                   1.0  0.974928   \n",
       "\n",
       "            wday_cos  month_sin  month_cos  \n",
       "date                                        \n",
       "2011-01-29  0.623490   0.500000   0.866025  \n",
       "2011-01-29  0.623490   0.500000   0.866025  \n",
       "2011-01-29  0.623490   0.500000   0.866025  \n",
       "2011-01-29  0.623490   0.500000   0.866025  \n",
       "2011-01-29  0.623490   0.500000   0.866025  \n",
       "...              ...        ...        ...  \n",
       "2016-04-24 -0.222521   0.866025  -0.500000  \n",
       "2016-04-24 -0.222521   0.866025  -0.500000  \n",
       "2016-04-24 -0.222521   0.866025  -0.500000  \n",
       "2016-04-24 -0.222521   0.866025  -0.500000  \n",
       "2016-04-24 -0.222521   0.866025  -0.500000  \n",
       "\n",
       "[19130 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset\n",
    "merge_df_scaled = pd.read_csv('../raw_data/merge_df_resize.csv')\n",
    "merge_df_scaled['date'] = pd.to_datetime(merge_df_scaled['date'])\n",
    "merge_df_scaled.set_index('date', inplace=True)\n",
    "\n",
    "merge_df_scaled\n",
    "# 382600 rows × 64 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93811f0b-32c4-4beb-b498-127548d1ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(merge_df_scaled):\n",
    "    # Ignore all warnings within this function\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "        #lagged features\n",
    "        for i in range(1, 8):\n",
    "            merge_df_scaled[f'sales_lag_{i}'] = merge_df_scaled['sales'].shift(i)\n",
    "    \n",
    "        #lagged features per years\n",
    "        for i in range(1, 4):\n",
    "            merge_df_scaled[f'sales_lag_{i}years'] = merge_df_scaled['sales'].shift(i * 365)\n",
    "    \n",
    "            #rolling sum\n",
    "        merge_df_scaled['rolling_sum_7'] = merge_df_scaled['sales'].rolling(window=7).sum()\n",
    "        merge_df_scaled['rolling_sum_30'] = merge_df_scaled['sales'].rolling(window=30).sum()\n",
    "        merge_df_scaled['rolling_sum_60'] = merge_df_scaled['sales'].rolling(window=60).sum()\n",
    "        merge_df_scaled['rolling_sum_90'] = merge_df_scaled['sales'].rolling(window=90).sum()\n",
    "        merge_df_scaled['rolling_sum_120'] = merge_df_scaled['sales'].rolling(window=120).sum()\n",
    "    \n",
    "        #rolling average\n",
    "        merge_df_scaled['rolling_mean_7'] = merge_df_scaled['sales'].rolling(window=7).mean()\n",
    "        merge_df_scaled['rolling_mean_30'] = merge_df_scaled['sales'].rolling(window=30).mean()\n",
    "        merge_df_scaled['rolling_mean_60'] = merge_df_scaled['sales'].rolling(window=60).mean()\n",
    "        merge_df_scaled['rolling_mean_90'] = merge_df_scaled['sales'].rolling(window=90).mean()\n",
    "        merge_df_scaled['rolling_mean_120'] = merge_df_scaled['sales'].rolling(window=120).mean()\n",
    "    \n",
    "        #rolling stdv\n",
    "        merge_df_scaled['rolling_stdv_7'] = merge_df_scaled['sales'].rolling(window=7).std()\n",
    "        merge_df_scaled['rolling_stdv_30'] = merge_df_scaled['sales'].rolling(window=30).std()\n",
    "        merge_df_scaled['rolling_stdv_60'] = merge_df_scaled['sales'].rolling(window=60).std()\n",
    "        merge_df_scaled['rolling_stdv_90'] = merge_df_scaled['sales'].rolling(window=90).std()\n",
    "        merge_df_scaled['rolling_stdv_120'] = merge_df_scaled['sales'].rolling(window=120).std()\n",
    "    \n",
    "        merge_df_scaled.fillna(0,inplace=True)\n",
    "        \n",
    "\n",
    "    return merge_df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02df851-703f-412f-8f52-cf105070d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_transfer_test(train_df,test_df):\n",
    "\n",
    "    # Ignore all warnings within this function\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "           \n",
    "    \n",
    "        #lagged features per years\n",
    "        for i in range(1, 4):\n",
    "            test_df[f'sales_lag_{i}years'] = train_df[f'sales_lag_{i}years'].iloc[-1]\n",
    "    \n",
    "            #rolling sum\n",
    "        test_df['rolling_sum_7'] = train_df['rolling_sum_7'].iloc[-1]\n",
    "        test_df['rolling_sum_30'] = train_df['rolling_sum_30'].iloc[-1]\n",
    "        test_df['rolling_sum_60'] = train_df['rolling_sum_60'].iloc[-1]\n",
    "        test_df['rolling_sum_90'] = train_df['rolling_sum_90'].iloc[-1]\n",
    "        test_df['rolling_sum_120'] = train_df['rolling_sum_120'].iloc[-1]\n",
    "        \n",
    "        # Rolling average\n",
    "        test_df['rolling_mean_7'] = train_df['rolling_mean_7'].iloc[-1]\n",
    "        test_df['rolling_mean_30'] = train_df['rolling_mean_30'].iloc[-1]\n",
    "        test_df['rolling_mean_60'] = train_df['rolling_mean_60'].iloc[-1]\n",
    "        test_df['rolling_mean_90'] = train_df['rolling_mean_90'].iloc[-1]\n",
    "        test_df['rolling_mean_120'] = train_df['rolling_mean_120'].iloc[-1]\n",
    "        \n",
    "        # Rolling standard deviation\n",
    "        test_df['rolling_stdv_7'] = train_df['rolling_stdv_7'].iloc[-1]\n",
    "        test_df['rolling_stdv_30'] = train_df['rolling_stdv_30'].iloc[-1]\n",
    "        test_df['rolling_stdv_60'] = train_df['rolling_stdv_60'].iloc[-1]\n",
    "        test_df['rolling_stdv_90'] = train_df['rolling_stdv_90'].iloc[-1]\n",
    "        test_df['rolling_stdv_120'] = train_df['rolling_stdv_120'].iloc[-1]\n",
    "    \n",
    "        # Identify the last available date in the training data\n",
    "        last_date_train = train_df.index[-1]\n",
    "    \n",
    "        # Fill in lagged features for the first few rows where future knowledge is available\n",
    "        #for i in range(1, 8):\n",
    "        #    # Identify the lagged date for the current lag\n",
    "        #    lagged_date = last_date_train - pd.Timedelta(days=i)\n",
    "            \n",
    "            # Fill in the lagged sales values for corresponding lagged days from the training data\n",
    "        #    test_df[f'sales_lag_{i}'] = test_df.index.map(lambda x: train_df.loc[x - pd.Timedelta(days=i), 'sales'] if x <= last_date_train else train_df[f'sales_lag_{i}'].iloc[-1])\n",
    "\n",
    "\n",
    "        # Fill in lagged features for the first few rows where future knowledge is available\n",
    "        for i in range(1, 8):\n",
    "            test_df[f'sales_lag_{i}'] = np.nan  # Initialize with NaN\n",
    "            \n",
    "            # Iterate over each row in the test DataFrame\n",
    "            for idx, row in test_df.iterrows():\n",
    "                lagged_date = idx - pd.Timedelta(days=i)  # Calculate the lagged date\n",
    "                \n",
    "                # Check if the lagged date is within the training data range\n",
    "                if lagged_date in train_df.index:\n",
    "                    test_df.at[idx, f'sales_lag_{i}'] = train_df.loc[lagged_date, 'sales']\n",
    "                else:\n",
    "                    test_df.at[idx, f'sales_lag_{i}'] = train_df['sales'].iloc[-1]\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb38c254-0214-41e4-b8de-fb536aca1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = merge_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1e8448-ecde-4944-99b4-30f74e5f489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_scaled.drop(columns=[\"item_id\",\"dept_id\",\"state_id\",\"event_name_2\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9391eb6-da51-4b69-a4aa-5fd1ccba9db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_scaled.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a35134-1f8a-436c-b168-111341c17cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df_scaled[\"id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c90d7-181f-4c34-b9db-73d5632292e5",
   "metadata": {},
   "source": [
    "# 1. Defining Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c2e333-1676-4450-a8ac-b1d64ce1fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prophet(product_data):\n",
    "\n",
    "    product_data.reset_index(inplace=True,names=\"date\")\n",
    "    \n",
    "    prophet_product_df = product_data[[\"id\",\"date\",\"sales\"]]\n",
    "    prophet_product_df.columns = [\"id\",\"ds\",\"y\"]\n",
    "    prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
    "    \n",
    "    data_train = prophet_product_df.iloc[:-28]\n",
    "    data_test = prophet_product_df.iloc[-28:]\n",
    "    X_train = data_train[\"ds\"]\n",
    "    y_train = data_train[\"y\"]\n",
    "    X_test = data_test[\"ds\"]\n",
    "    y_test = data_test[\"y\"]\n",
    "    \n",
    "    fbp = Prophet()\n",
    "\n",
    "    model = fbp.fit(data_train)\n",
    "    \n",
    "    predict_placeholder = fbp.make_future_dataframe(28,freq=\"D\")\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = fbp.predict(predict_placeholder[-28:])\n",
    "    \n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    mae = mean_absolute_error(y_test, y_pred[\"yhat\"])\n",
    "    \n",
    "    return model, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "151bd3d5-e70c-41ef-8a3e-2da51e4fe900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_auto_arima(product_data):\n",
    "    data_train = product_data.iloc[:-28]\n",
    "    data_test = product_data.iloc[-28:]\n",
    "    y_train = data_train[\"sales\"]\n",
    "    y_test = data_test[\"sales\"]\n",
    "\n",
    "    # Fit ARIMA model on the training data using auto_arima to find the best (p, d, q)\n",
    "    model = auto_arima(y_train, start_p=0, start_q=0, max_p=5, max_q=5, d=1,\n",
    "                       seasonal=True, trace=False, error_action='ignore', \n",
    "                       suppress_warnings=True, stepwise=True)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(n_periods=len(y_test))\n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "    return model, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9e1224-e66f-4e66-bad4-dd867e626f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_optuna(trial, y_train, y_test):\n",
    "    \n",
    "    trend = trial.suggest_categorical('trend', ['add'])\n",
    "    seasonal = trial.suggest_categorical('seasonal', [None, 'add'])\n",
    "    seasonal_periods = trial.suggest_categorical('seasonal_periods', [None, 4, 7, 12])\n",
    "    \n",
    "    product_results = []\n",
    "\n",
    "    # Fit Holt-Winters model on the training data\n",
    "    model = ExponentialSmoothing(y_train, trend=trend, seasonal=seasonal, seasonal_periods=seasonal_periods,freq='D')\n",
    "    fitted_model = model.fit(optimized=True)\n",
    "\n",
    "    # Predict on the test data\n",
    "    predictions = fitted_model.forecast(steps=len(y_test))\n",
    "\n",
    "    # Calculate and store the error metric\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    product_results.append(mae)\n",
    "\n",
    "    # Average MAE for this product\n",
    "    average_mae = np.mean(product_results)\n",
    "    return average_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "102b594c-39b7-4817-bb4b-f3d5706c0d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_exp_smoothing(product_data):\n",
    "    data_train = product_data.iloc[:-28]\n",
    "    data_test = product_data.iloc[-28:]\n",
    "    y_train = data_train[\"sales\"]\n",
    "    y_test = data_test[\"sales\"]\n",
    "    # Create a study object\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    print(f\"Optimizing hyperparameters for product: {id}\")\n",
    "    \n",
    "    \n",
    "    # Run the optimization process for the current product\n",
    "    study.optimize(lambda trial: objective_optuna(trial, y_train, y_test), n_trials=10, n_jobs=-1)\n",
    "\n",
    "    # Get the best hyperparameters and the corresponding best MAE\n",
    "    best_params = study.best_params\n",
    "    best_mae = study.best_value\n",
    "\n",
    "    # Create the best model with the obtained hyperparameters\n",
    "    best_model = ExponentialSmoothing(y_train, **best_params).fit()\n",
    "    \n",
    "    return best_model, best_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1e96217a-a286-4ecd-b8d3-9d23a0fc3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "def perform_lightgbm(product_data):\n",
    "    \n",
    "    data_train_val = product_data.iloc[:-28]\n",
    "    data_train_val = feature_extraction(data_train_val)\n",
    "    data_test = product_data.iloc[-28:]\n",
    "    data_test = feature_extraction_transfer_test(data_train_val,data_test)\n",
    "\n",
    "    data_train = data_train_val.iloc[:-112]\n",
    "    data_val = data_train_val.iloc[-112:]\n",
    "    \n",
    "    X_train = data_train.drop(columns=\"sales\")\n",
    "    y_train = data_train[\"sales\"]\n",
    "    X_val = data_val.drop(columns=\"sales\")\n",
    "    y_val = data_val[\"sales\"]\n",
    "    X_test = data_test.drop(columns=\"sales\")\n",
    "    y_test = data_test[\"sales\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define LightGBM parameters\n",
    "    params = {\n",
    "        \"n_estimators\": 1000,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"max_depth\": -1,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.4,\n",
    "        \"lambda_l1\": 1,\n",
    "        \"lambda_l2\": 1,\n",
    "        \"seed\": 46,\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    \n",
    "    # Create dataset for LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    # Train the model\n",
    "    num_round = 1000\n",
    "\n",
    "    bst = lgb.train(params, lgb_train, num_round, valid_sets=lgb_eval, callbacks=[lgb.early_stopping(stopping_rounds=50)])\n",
    "     \n",
    "    # Make predictions for the next 28 days\n",
    "    predictions = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "    return bst, mae\n",
    "\n",
    "# Example usage:\n",
    "# sales_forecast = forecast_sales(product_data)\n",
    "# print(sales_forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4313bdf-003b-428f-addb-07ad6b7058b8",
   "metadata": {},
   "source": [
    "# 2.Running all models in a loop to find for each product with lowest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e09341ed-7407-4421-87d4-b97c92ef1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\"LightGBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25636b8c-848f-4188-bc73-1546fdeb687b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing product: FOODS_2_197_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40835/1072332254.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
      "15:26:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:26:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-10 15:26:41,975] A new study created in memory with name: no-name-afbaf00f-6b93-4474-af2e-243c66442434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters for product: FOODS_2_197_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 15:26:43,606] Trial 1 finished with value: 9.388827437788668 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:43,681] Trial 4 finished with value: 9.783006525295232 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:43,702] Trial 2 finished with value: 9.388827437788668 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:43,751] Trial 3 finished with value: 9.388827437788668 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:43,810] Trial 9 finished with value: 9.388827437788668 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:43,811] Trial 5 finished with value: 9.388827437788668 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:44,282] Trial 0 finished with value: 10.937992396985061 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:44,329] Trial 8 finished with value: 10.937992396985061 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:44,333] Trial 7 finished with value: 10.937992396985061 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 9.388827437788668.\n",
      "[I 2024-05-10 15:26:44,369] Trial 6 finished with value: 10.937992396985061 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 9.388827437788668.\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4460\n",
      "[LightGBM] [Info] Number of data points in the train set: 1773, number of used features: 41\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 21.664975\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's rmse: 4.79687\n",
      "{'ARIMA': {'mae': 8.726633436944372, 'model': ARIMA(order=(2, 1, 1), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}, 'Prophet': {'mae': 11.367010469983766, 'model': <prophet.forecaster.Prophet object at 0x7fa432ce5420>}, 'ExponentialSmoothing': {'mae': 9.388827437788668, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fa432c71030>}, 'LightGBM': {'mae': 17.73258393721617, 'model': <lightgbm.basic.Booster object at 0x7fa432f2d060>}}\n",
      "Model results for FOODS_2_197_CA_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 8.726633436944372\n",
      "Analyzing product: FOODS_3_080_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40835/1072332254.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
      "15:27:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:27:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-10 15:27:01,720] A new study created in memory with name: no-name-6d07663b-88b6-40c6-8da0-d778b67f7a7e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters for product: FOODS_3_080_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 15:27:03,685] Trial 3 finished with value: 5.603251743760496 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 3 with value: 5.603251743760496.\n",
      "[I 2024-05-10 15:27:03,723] Trial 7 finished with value: 5.603251743760496 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 3 with value: 5.603251743760496.\n",
      "[I 2024-05-10 15:27:03,770] Trial 1 finished with value: 5.603251743760496 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 3 with value: 5.603251743760496.\n",
      "[I 2024-05-10 15:27:03,778] Trial 9 finished with value: 5.603251743760496 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 3 with value: 5.603251743760496.\n",
      "[I 2024-05-10 15:27:03,807] Trial 5 finished with value: 5.603251743760496 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 3 with value: 5.603251743760496.\n",
      "[I 2024-05-10 15:27:03,987] Trial 2 finished with value: 5.5737852381639 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 2 with value: 5.5737852381639.\n",
      "[I 2024-05-10 15:27:04,095] Trial 0 finished with value: 5.5737852381639 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 2 with value: 5.5737852381639.\n",
      "[I 2024-05-10 15:27:04,149] Trial 4 finished with value: 4.851012052269259 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 4 with value: 4.851012052269259.\n",
      "[I 2024-05-10 15:27:04,189] Trial 6 finished with value: 4.851012052269259 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 4 with value: 4.851012052269259.\n",
      "[I 2024-05-10 15:27:04,194] Trial 8 finished with value: 4.851012052269259 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 4 with value: 4.851012052269259.\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4072\n",
      "[LightGBM] [Info] Number of data points in the train set: 1773, number of used features: 41\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 20.687535\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 5.37814\n",
      "{'ARIMA': {'mae': 6.034984090618189, 'model': ARIMA(order=(5, 1, 1), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}, 'Prophet': {'mae': 4.776500194398421, 'model': <prophet.forecaster.Prophet object at 0x7fa432f060b0>}, 'ExponentialSmoothing': {'mae': 4.851012052269259, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fa4323bbaf0>}, 'LightGBM': {'mae': 8.694071175621318, 'model': <lightgbm.basic.Booster object at 0x7fa432c72770>}}\n",
      "Model results for FOODS_3_080_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 4.776500194398421\n",
      "Analyzing product: FOODS_3_090_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40835/1072332254.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
      "15:27:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:27:56 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-10 15:27:56,504] A new study created in memory with name: no-name-2076b8fd-c138-43b6-9476-dd959ed522ad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters for product: FOODS_3_090_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 15:27:56,781] Trial 0 finished with value: 37.241681706408414 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,128] Trial 1 finished with value: 37.241681706408414 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,217] Trial 3 finished with value: 37.241681706408414 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,281] Trial 4 finished with value: 37.241681706408414 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,522] Trial 9 finished with value: 37.241681706408414 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,563] Trial 6 finished with value: 37.241681706408414 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,610] Trial 7 finished with value: 37.241681706408414 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,863] Trial 8 finished with value: 37.243587862649186 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,879] Trial 2 finished with value: 46.84498452697279 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 0 with value: 37.241681706408414.\n",
      "[I 2024-05-10 15:27:57,917] Trial 5 finished with value: 46.84498452697279 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 0 with value: 37.241681706408414.\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5426\n",
      "[LightGBM] [Info] Number of data points in the train set: 1773, number of used features: 41\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 68.591089\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[347]\tvalid_0's rmse: 13.4825\n",
      "{'ARIMA': {'mae': 19.479598099076547, 'model': ARIMA(order=(4, 1, 3), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}, 'Prophet': {'mae': 16.664135902250575, 'model': <prophet.forecaster.Prophet object at 0x7fa438716cb0>}, 'ExponentialSmoothing': {'mae': 37.241681706408414, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fa432341330>}, 'LightGBM': {'mae': 19.488855121143693, 'model': <lightgbm.basic.Booster object at 0x7fa432c71240>}}\n",
      "Model results for FOODS_3_090_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 16.664135902250575\n",
      "Analyzing product: FOODS_3_120_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40835/1072332254.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
      "15:28:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:28:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-10 15:28:44,735] A new study created in memory with name: no-name-1ae6cf0a-1981-4423-a64a-7f8429643b4b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters for product: FOODS_3_120_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 15:28:45,368] Trial 1 finished with value: 27.01694491780205 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 1 with value: 27.01694491780205.\n",
      "[I 2024-05-10 15:28:45,421] Trial 3 finished with value: 27.01694491780205 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 1 with value: 27.01694491780205.\n",
      "[I 2024-05-10 15:28:45,494] Trial 5 finished with value: 27.01694491780205 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 1 with value: 27.01694491780205.\n",
      "[I 2024-05-10 15:28:45,557] Trial 4 finished with value: 27.01694491780205 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 1 with value: 27.01694491780205.\n",
      "[I 2024-05-10 15:28:45,651] Trial 2 finished with value: 27.01694491780205 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 1 with value: 27.01694491780205.\n",
      "[I 2024-05-10 15:28:45,672] Trial 6 finished with value: 27.01694491780205 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 1 with value: 27.01694491780205.\n",
      "[I 2024-05-10 15:28:45,744] Trial 7 finished with value: 27.01694491780205 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 1 with value: 27.01694491780205.\n",
      "[I 2024-05-10 15:28:46,137] Trial 0 finished with value: 26.524523149793517 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 0 with value: 26.524523149793517.\n",
      "[I 2024-05-10 15:28:46,211] Trial 9 finished with value: 25.157870794592952 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 9 with value: 25.157870794592952.\n",
      "[I 2024-05-10 15:28:46,215] Trial 8 finished with value: 26.524523149793517 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 9 with value: 25.157870794592952.\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4981\n",
      "[LightGBM] [Info] Number of data points in the train set: 1773, number of used features: 41\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 32.275240\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 18.9941\n",
      "{'ARIMA': {'mae': 24.7807297967242, 'model': ARIMA(order=(5, 1, 4), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}, 'Prophet': {'mae': 21.07083458938636, 'model': <prophet.forecaster.Prophet object at 0x7fa433074550>}, 'ExponentialSmoothing': {'mae': 25.157870794592952, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fa4330a3010>}, 'LightGBM': {'mae': 32.09723713760365, 'model': <lightgbm.basic.Booster object at 0x7fa433106320>}}\n",
      "Model results for FOODS_3_120_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 21.07083458938636\n",
      "Analyzing product: FOODS_3_252_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40835/1072332254.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
      "15:29:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:29:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-10 15:29:45,617] A new study created in memory with name: no-name-d2aee288-e043-4e48-b3b9-3c5781c563df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters for product: FOODS_3_252_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 15:29:46,657] Trial 2 finished with value: 10.92925276421992 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 2 with value: 10.92925276421992.\n",
      "[I 2024-05-10 15:29:46,996] Trial 5 finished with value: 10.92925276421992 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 2 with value: 10.92925276421992.\n",
      "[I 2024-05-10 15:29:47,021] Trial 4 finished with value: 10.92925276421992 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 10.92925276421992.\n",
      "[I 2024-05-10 15:29:47,116] Trial 6 finished with value: 10.92925276421992 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 10.92925276421992.\n",
      "[I 2024-05-10 15:29:47,121] Trial 8 finished with value: 10.92925276421992 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 2 with value: 10.92925276421992.\n",
      "[I 2024-05-10 15:29:47,161] Trial 9 finished with value: 10.92925276421992 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 10.92925276421992.\n",
      "[I 2024-05-10 15:29:47,335] Trial 3 finished with value: 10.364052936266356 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 3 with value: 10.364052936266356.\n",
      "[I 2024-05-10 15:29:47,394] Trial 1 finished with value: 10.655908601442151 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 3 with value: 10.364052936266356.\n",
      "[I 2024-05-10 15:29:47,404] Trial 7 finished with value: 10.655908601442151 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 3 with value: 10.364052936266356.\n",
      "[I 2024-05-10 15:29:47,455] Trial 0 finished with value: 6.591632596564805 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 6.591632596564805.\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4793\n",
      "[LightGBM] [Info] Number of data points in the train set: 1773, number of used features: 41\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 39.639594\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 6.55657\n",
      "{'ARIMA': {'mae': 6.680438583319882, 'model': ARIMA(order=(5, 1, 5), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}, 'Prophet': {'mae': 6.5637324544171625, 'model': <prophet.forecaster.Prophet object at 0x7fa438643fd0>}, 'ExponentialSmoothing': {'mae': 6.591632596564805, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fa432c70f10>}, 'LightGBM': {'mae': 17.689703570355366, 'model': <lightgbm.basic.Booster object at 0x7fa4323b8970>}}\n",
      "Model results for FOODS_3_252_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 6.5637324544171625\n",
      "Analyzing product: FOODS_3_555_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40835/1072332254.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
      "15:30:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:30:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-10 15:30:52,525] A new study created in memory with name: no-name-1d26988b-2f56-41e6-85f9-8649ed6a92e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters for product: FOODS_3_555_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 15:30:54,697] Trial 0 finished with value: 5.214282383016028 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 0 with value: 5.214282383016028.\n",
      "[I 2024-05-10 15:30:54,840] Trial 4 finished with value: 5.214282383016028 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 0 with value: 5.214282383016028.\n",
      "[I 2024-05-10 15:30:54,877] Trial 5 finished with value: 5.214282383016028 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 0 with value: 5.214282383016028.\n",
      "[I 2024-05-10 15:30:54,891] Trial 6 finished with value: 5.214282383016028 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 0 with value: 5.214282383016028.\n",
      "[I 2024-05-10 15:30:54,933] Trial 9 finished with value: 5.214282383016028 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 0 with value: 5.214282383016028.\n",
      "[I 2024-05-10 15:30:54,984] Trial 7 finished with value: 5.214282383016028 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 0 with value: 5.214282383016028.\n",
      "[I 2024-05-10 15:30:55,196] Trial 1 finished with value: 3.234239988928919 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 3.234239988928919.\n",
      "[I 2024-05-10 15:30:55,272] Trial 3 finished with value: 3.234239988928919 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 3.234239988928919.\n",
      "[I 2024-05-10 15:30:55,381] Trial 2 finished with value: 5.1269945338729075 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 1 with value: 3.234239988928919.\n",
      "[I 2024-05-10 15:30:55,385] Trial 8 finished with value: 5.1269945338729075 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 1 with value: 3.234239988928919.\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4065\n",
      "[LightGBM] [Info] Number of data points in the train set: 1773, number of used features: 41\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 20.000564\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 3.96733\n",
      "{'ARIMA': {'mae': 4.34514653363894, 'model': ARIMA(order=(4, 1, 4), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}, 'Prophet': {'mae': 4.261908361923384, 'model': <prophet.forecaster.Prophet object at 0x7fa4330a0e80>}, 'ExponentialSmoothing': {'mae': 3.234239988928919, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fa4330a2aa0>}, 'LightGBM': {'mae': 11.110303566214885, 'model': <lightgbm.basic.Booster object at 0x7fa432c72200>}}\n",
      "Model results for FOODS_3_555_CA_1_validation\n",
      "Best model: ExponentialSmoothing\n",
      "Best score: 3.234239988928919\n",
      "Analyzing product: FOODS_3_586_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40835/1072332254.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
      "15:31:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:31:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-10 15:31:41,058] A new study created in memory with name: no-name-a6aafdf3-c790-4bb7-af64-1fcc778370ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters for product: FOODS_3_586_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 15:31:42,597] Trial 0 finished with value: 10.693124076299275 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 10.693124076299275.\n",
      "[I 2024-05-10 15:31:42,834] Trial 2 finished with value: 10.693124076299275 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 0 with value: 10.693124076299275.\n",
      "[I 2024-05-10 15:31:43,190] Trial 6 finished with value: 10.693124076299275 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 0 with value: 10.693124076299275.\n",
      "[I 2024-05-10 15:31:43,672] Trial 7 finished with value: 10.693124076299275 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 10.693124076299275.\n",
      "[I 2024-05-10 15:31:43,886] Trial 5 finished with value: 10.693124076299275 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 10.693124076299275.\n",
      "[I 2024-05-10 15:31:44,251] Trial 9 finished with value: 10.143969255782157 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 9 with value: 10.143969255782157.\n",
      "[I 2024-05-10 15:31:44,425] Trial 3 finished with value: 9.749473041311031 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 3 with value: 9.749473041311031.\n",
      "[I 2024-05-10 15:31:44,451] Trial 1 finished with value: 9.749473041311031 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 3 with value: 9.749473041311031.\n",
      "[I 2024-05-10 15:31:44,516] Trial 4 finished with value: 9.749473041311031 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 3 with value: 9.749473041311031.\n",
      "[I 2024-05-10 15:31:44,564] Trial 8 finished with value: 6.407874992421177 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 8 with value: 6.407874992421177.\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4653\n",
      "[LightGBM] [Info] Number of data points in the train set: 1773, number of used features: 41\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 46.627750\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's rmse: 8.59475\n",
      "{'ARIMA': {'mae': 7.991362870463669, 'model': ARIMA(order=(2, 1, 3), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}, 'Prophet': {'mae': 6.241775733242483, 'model': <prophet.forecaster.Prophet object at 0x7fa438173430>}, 'ExponentialSmoothing': {'mae': 6.407874992421177, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fa432342bf0>}, 'LightGBM': {'mae': 9.255567869387699, 'model': <lightgbm.basic.Booster object at 0x7fa4323b9540>}}\n",
      "Model results for FOODS_3_586_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 6.241775733242483\n",
      "Analyzing product: FOODS_3_587_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40835/1072332254.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_product_df['ds'])\n",
      "15:32:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:32:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-10 15:32:52,681] A new study created in memory with name: no-name-3cd29add-05a1-46c3-981e-87956a114c18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameters for product: FOODS_3_587_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 15:32:54,681] Trial 7 finished with value: 17.481420998759102 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 7 with value: 17.481420998759102.\n",
      "[I 2024-05-10 15:32:54,726] Trial 3 finished with value: 17.481420998759102 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 7 with value: 17.481420998759102.\n",
      "[I 2024-05-10 15:32:54,838] Trial 5 finished with value: 17.481420998759102 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 7 with value: 17.481420998759102.\n",
      "[I 2024-05-10 15:32:54,870] Trial 9 finished with value: 17.481420998759102 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 7 with value: 17.481420998759102.\n",
      "[I 2024-05-10 15:32:54,889] Trial 8 finished with value: 17.481420998759102 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 7 with value: 17.481420998759102.\n",
      "[I 2024-05-10 15:32:55,049] Trial 0 finished with value: 21.13969652134222 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 7 with value: 17.481420998759102.\n",
      "[I 2024-05-10 15:32:55,241] Trial 2 finished with value: 20.943506213244387 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 7 with value: 17.481420998759102.\n",
      "[I 2024-05-10 15:32:55,471] Trial 4 finished with value: 17.311694281927434 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 4 with value: 17.311694281927434.\n",
      "[I 2024-05-10 15:32:55,523] Trial 1 finished with value: 17.311694281927434 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 4 with value: 17.311694281927434.\n",
      "[I 2024-05-10 15:32:55,549] Trial 6 finished with value: 17.311694281927434 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 4 with value: 17.311694281927434.\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/jonas/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4710\n",
      "[LightGBM] [Info] Number of data points in the train set: 1773, number of used features: 41\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 27.139876\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 8.68011\n",
      "{'ARIMA': {'mae': 15.636063191263302, 'model': ARIMA(order=(3, 1, 3), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}, 'Prophet': {'mae': 10.36622612532744, 'model': <prophet.forecaster.Prophet object at 0x7fa432f38940>}, 'ExponentialSmoothing': {'mae': 17.311694281927434, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fa432425b40>}, 'LightGBM': {'mae': 8.650968999189798, 'model': <lightgbm.basic.Booster object at 0x7fa43229e4d0>}}\n",
      "Model results for FOODS_3_587_CA_1_validation\n",
      "Best model: LightGBM\n",
      "Best score: 8.650968999189798\n",
      "Analyzing product: FOODS_3_714_CA_1_validation\n"
     ]
    }
   ],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "# Dictionary to store MAE results for each unique time-series identified by id\n",
    "product_results = {}\n",
    "average_mae = []\n",
    "\n",
    "# Iterate over each unique product series identified by id\n",
    "for id in merge_df_scaled['id'].unique()[:10]:\n",
    "    print(f\"Analyzing product: {id}\")\n",
    "    product_data = merge_df_scaled[merge_df_scaled['id'] == id].drop(columns=\"id\")\n",
    "    product_data_with_id = merge_df_scaled[merge_df_scaled['id'] == id]\n",
    "\n",
    "    # Results list for the current product time-series\n",
    "    results = {}\n",
    "    best_score = 999.99\n",
    "    best_model_name = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    #Looping all models\n",
    "    for model_name in models_list:\n",
    "\n",
    "        if model_name == \"ARIMA\":\n",
    "            #TODO: Add 5-fold split here for another loop (or inside the model function?) and then take the average score per model as their mae score\n",
    "            \n",
    "            # Fit ARIMA model on the training data using auto_arima to find the best (p, d, q)\n",
    "            model, mae = perform_auto_arima(product_data)\n",
    "            results[model_name] = {\"mae\": mae, \"model\": model}\n",
    "            if mae < best_score:\n",
    "                best_score = mae\n",
    "                best_model = model\n",
    "                best_model_name = model_name\n",
    "\n",
    "        elif model_name == \"ExponentialSmoothing\":\n",
    "\n",
    "            # To be built\n",
    "            model, mae = perform_exp_smoothing(product_data)\n",
    "            results[model_name] = {\"mae\": mae, \"model\": model}\n",
    "            if mae < best_score:\n",
    "                best_score = mae\n",
    "                best_model = model\n",
    "                best_model_name = model_name\n",
    "\n",
    "        elif model_name == \"Prophet\":\n",
    "\n",
    "            model, mae = perform_prophet(product_data_with_id)\n",
    "            results[model_name] = {\"mae\": mae, \"model\": model}\n",
    "            if mae < best_score:\n",
    "                best_score = mae\n",
    "                best_model = model\n",
    "                best_model_name = model_name\n",
    "\n",
    "\n",
    "        elif model_name == \"LightGBM\":\n",
    "\n",
    "            model, mae = perform_lightgbm(product_data)\n",
    "            results[model_name] = {\"mae\": mae, \"model\": model}\n",
    "            if mae < best_score:\n",
    "                best_score = mae\n",
    "                best_model = model\n",
    "                best_model_name = model_name\n",
    "\n",
    "\n",
    "    #Printing results for this product\n",
    "    print(results)\n",
    "    print(f\"Model results for {id}\")\n",
    "    print(f\"Best model: {best_model_name}\")\n",
    "    print(f\"Best score: {best_score}\")\n",
    "\n",
    "    average_mae.append(best_score)\n",
    "\n",
    "    # Store the average MAE for the current product time-series\n",
    "    product_results[id] = {\"best_score\": best_score, \"best_model\": best_model_name, \"model\": best_model}\n",
    "\n",
    "    #Store the best model in a pkl file\n",
    "    filename = f'../models/{id}_model.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df_arima = pd.DataFrame(product_results.items(), columns=['id', 'MAE'])\n",
    "\n",
    "# Set the 'id' column as the index\n",
    "results_df_arima.set_index('id', inplace=True)\n",
    "\n",
    "average_mae = np.mean(average_mae)\n",
    "\n",
    "print(f\"Total average MAE: {average_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13ac0a-fa34-4333-9abf-2dc1e7592607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
