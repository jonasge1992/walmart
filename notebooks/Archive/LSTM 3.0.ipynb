{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed87cd7b-df5f-4791-a0e6-ca2d62e7a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c053399-9f33-4dc8-9c1c-df89eeb2a010",
   "metadata": {},
   "source": [
    "1️⃣ [FOLDS] Cross-Validation in Time Series\n",
    "\n",
    "Starting from this single Time Series:\n",
    "- We will create FOLDS\n",
    "-Train/Evaluate our LSTM  on each of these different FOLDS to conclude about the robustness of the model.\n",
    "(It is very common to create hundreds of folds in Time Series forecasting, in order to cover all types of external conditions: crash market periods, bull markets, atone markets, etc...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ca2752d-cec7-4a1e-83ae-55d1fc56fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned and merged dataset\n",
    "data_path = '../raw_data/cleaned_merge_df_top10.csv'  \n",
    "data = pd.read_csv(data_path)\n",
    "data['date'] = pd.to_datetime(data['date'])  # Ensure 'date' is a datetime object\n",
    "data.set_index('date', inplace=True)  # Set 'date' as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d68fd3e0-d59c-4da0-a6fc-bf7873c2f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1740, 17), Test shape: (1739, 17)\n",
      "Train shape: (3479, 17), Test shape: (1739, 17)\n",
      "Train shape: (5218, 17), Test shape: (1739, 17)\n",
      "Train shape: (6957, 17), Test shape: (1739, 17)\n",
      "Train shape: (8696, 17), Test shape: (1739, 17)\n",
      "Train shape: (10435, 17), Test shape: (1739, 17)\n",
      "Train shape: (12174, 17), Test shape: (1739, 17)\n",
      "Train shape: (13913, 17), Test shape: (1739, 17)\n",
      "Train shape: (15652, 17), Test shape: (1739, 17)\n",
      "Train shape: (17391, 17), Test shape: (1739, 17)\n"
     ]
    }
   ],
   "source": [
    "# Define the number of splits\n",
    "n_splits = 10  # we can increase this depending on the length and granularity of your data\n",
    "\n",
    "# Create time series cross-validator\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Generate the indices to split data into training and test set\n",
    "for train_index, test_index in tscv.split(data):\n",
    "    train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "    print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
    "    # Here, we could fit our LSTM model on 'train' and evaluate it on 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e681d41f-3b8c-49b8-9b88-bf6d978f1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train the LSTM model\n",
    "def train_lstm(train_data, test_data):\n",
    "    # 'sales' is the column to predict\n",
    "    X_train, y_train = train_data.drop('sales', axis=1), train_data['sales']\n",
    "    X_test, y_test = test_data.drop('sales', axis=1), test_data['sales']\n",
    "    \n",
    "    # Reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    # Build LSTM Model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=72, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_predict = model.predict(X_test)\n",
    "    # Compute error metrics, e.g., RMSE\n",
    "    return model, test_predict\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test Loss for the fold: {test_loss}')\n",
    "\n",
    "# Apply this function in your cross-validation loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ee9b5e-07bd-4aa8-99df-d8ced9d111cf",
   "metadata": {},
   "source": [
    "2️⃣ [TRAIN-TEST SPLIT] Holdout method\n",
    "\n",
    "For each FOLD, we will do a TRAIN-TEST SPLIT to:\n",
    "fit the model on the train set\n",
    "evaluate it on the test set\n",
    "(Always split the train set **chronologically** before the test set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22dacd91-0dd7-45a3-9358-7d551c214554",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gh/g9g2sc7s7tv915tj0kbjqqjm0000gn/T/ipykernel_90435/1098822816.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.80\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjusted comment to match 80%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Prepare data for LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mX_validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gh/g9g2sc7s7tv915tj0kbjqqjm0000gn/T/ipykernel_90435/1098822816.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Assuming 'sales' is the column to predict and others are features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# Updated function to prepare data for LSTM\n",
    "def prepare_data(data):\n",
    "    # Assuming 'sales' is the column to predict and others are features\n",
    "    X = data.drop('sales', axis=1)\n",
    "    y = data['sales']\n",
    "    X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
    "    return X, y\n",
    "\n",
    "# Updated function to create the LSTM model\n",
    "def build_lstm(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))         # Define input shape with Input layer\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# Loop through each fold (assuming tscv and data are defined)\n",
    "for train_index, test_index in tscv.split(data):\n",
    "    # Split data into train and test sets\n",
    "    train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "    \n",
    "    # Train-test split inside the train data for validation\n",
    "    train_size = int(len(train) * 0.80)  # Adjusted comment to match 80%\n",
    "    train_data, validate_data = train[:train_size], train[train_size:]\n",
    "    \n",
    "    # Prepare data for LSTM\n",
    "    X_train, y_train = prepare_data(train_data)\n",
    "    X_validate, y_validate = prepare_data(validate_data)\n",
    "    X_test, y_test = prepare_data(test)\n",
    "    \n",
    "    # Build and fit the LSTM model\n",
    "    model = build_lstm((1, X_train.shape[2]))  # Updated to pass the correct shape\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=72, validation_data=(X_validate, y_validate), verbose=2, shuffle=False)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test Loss for the fold: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc703c4-e163-4735-ba29-d44c300572fe",
   "metadata": {},
   "source": [
    "3️⃣ [SEQUENCES] Sampling/Extracting sequences\n",
    "After splitting each fold into a train set and a test set, it is time to:\n",
    "- 🏋 sample lots of sequences on which the model will be trained\n",
    "- 👩🏻‍🏫 sample lots of sequences on which the model will be evaluated\n",
    "\n",
    "👉 All these sequences in the train set and the test set will have a common shape `(input_length, n_features)`\n",
    "👉 Each sequence has a target, the shape of which will be `(output_length, n_targets)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3af63196-4ccb-49bf-bb5a-55037c139e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sequences(data, input_length, output_length):\n",
    "    \"\"\"\n",
    "    Samples sequences for LSTM training and evaluation.\n",
    "\n",
    "    Args:\n",
    "    data (DataFrame): The dataset containing features and target.\n",
    "    input_length (int): The number of timesteps in each input sequence.\n",
    "    output_length (int): The number of timesteps in each output sequence.\n",
    "\n",
    "    Returns:\n",
    "    X, y (np.array): Arrays of input sequences and corresponding target sequences.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - input_length - output_length + 1):\n",
    "        # Extract input sequence and corresponding targets\n",
    "        X.append(data.iloc[i:(i + input_length)].values)\n",
    "        y.append(data.iloc[(i + input_length):(i + input_length + output_length)]['sales'].values)\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a61928ca-839e-4e39-ae64-974514d888a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m sample_sequences(test, input_length, output_length)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Assuming the function to build and train the model is already defined\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Build the LSTM model and fit it\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure this matches the model definition\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m, in \u001b[0;36mbuild_lstm\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_lstm\u001b[39m(input_shape):\n\u001b[1;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m---> 12\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(\u001b[43mInput\u001b[49m(shape\u001b[38;5;241m=\u001b[39minput_shape))         \u001b[38;5;66;03m# Define input shape with Input layer\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m50\u001b[39m))\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "# Define parameters\n",
    "input_length = 112  # Number of days in each input sequence\n",
    "output_length = 28  # Number of days to predict\n",
    "\n",
    "# Initialize the TimeSeriesSplit object\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for train_index, test_index in tscv.split(data):\n",
    "    # Split data into train and test sets\n",
    "    train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "    \n",
    "    # Sample sequences from train and test data\n",
    "    X_train, y_train = sample_sequences(train, input_length, output_length)\n",
    "    X_test, y_test = sample_sequences(test, input_length, output_length)\n",
    "    \n",
    "    # Assuming the function to build and train the model is already defined\n",
    "    # Build the LSTM model and fit it\n",
    "    model = build_lstm((X_train.shape[1], X_train.shape[2]))  # Ensure this matches the model definition\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=2)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test Loss for the fold: {test_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bf6b8-6aa9-410b-a951-0a483ff94e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
