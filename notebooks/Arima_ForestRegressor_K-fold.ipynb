{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c8918c-632b-4657-a3ce-411ec7ad7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from pmdarima import auto_arima\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c609b4d-0ec3-4925-88a4-d0682c52a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../raw_data/cleaned_merge_df_top10.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a250b3ce-e14e-478c-969a-11a31263da86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_2_197_CA_1_validation</td>\n",
       "      <td>FOODS_2_197</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>38</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_080_CA_1_validation</td>\n",
       "      <td>FOODS_3_080</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>33</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_090_CA_1_validation</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>107</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_120_CA_1_validation</td>\n",
       "      <td>FOODS_3_120</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_252_CA_1_validation</td>\n",
       "      <td>FOODS_3_252</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>19</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id      item_id  dept_id cat_id store_id  \\\n",
       "date                                                                            \n",
       "2011-01-29  FOODS_2_197_CA_1_validation  FOODS_2_197  FOODS_2  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_080_CA_1_validation  FOODS_3_080  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_090_CA_1_validation  FOODS_3_090  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_120_CA_1_validation  FOODS_3_120  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_252_CA_1_validation  FOODS_3_252  FOODS_3  FOODS     CA_1   \n",
       "\n",
       "           state_id  sales   weekday  wday event_name_1 event_type_1  \\\n",
       "date                                                                   \n",
       "2011-01-29       CA     38  Saturday     1            0            0   \n",
       "2011-01-29       CA     33  Saturday     1            0            0   \n",
       "2011-01-29       CA    107  Saturday     1            0            0   \n",
       "2011-01-29       CA      0  Saturday     1            0            0   \n",
       "2011-01-29       CA     19  Saturday     1            0            0   \n",
       "\n",
       "           event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \n",
       "date                                                                         \n",
       "2011-01-29            0            0        0        0        0        2.98  \n",
       "2011-01-29            0            0        0        0        0        1.48  \n",
       "2011-01-29            0            0        0        0        0        1.25  \n",
       "2011-01-29            0            0        0        0        0        0.00  \n",
       "2011-01-29            0            0        0        0        0        1.48  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5e08fb-96f4-4391-a71f-4d4e07184bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FOODS_2_197_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 11.455723560225175, RF MAE: 10.341722499533716\n",
      "Fold completed. ARIMA MAE: 12.588663154758894, RF MAE: 9.201569681576464\n",
      "Fold completed. ARIMA MAE: 20.004147728214548, RF MAE: 9.267003976907906\n",
      "Fold completed. ARIMA MAE: 6.966593783212147, RF MAE: 8.614751181525243\n",
      "Fold completed. ARIMA MAE: 5.930905216998448, RF MAE: 7.761411238383719\n",
      "Processing FOODS_3_080_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 5.770661692250511, RF MAE: 6.933755555555555\n",
      "Fold completed. ARIMA MAE: 6.384335172725188, RF MAE: 6.4566975812547245\n",
      "Fold completed. ARIMA MAE: 5.856336763401625, RF MAE: 6.854338926681784\n",
      "Fold completed. ARIMA MAE: 4.288200259923211, RF MAE: 6.127151020408163\n",
      "Fold completed. ARIMA MAE: 5.463257695939435, RF MAE: 6.954212849584278\n",
      "Processing FOODS_3_090_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 39.58494074682603, RF MAE: 42.20307941957396\n",
      "Fold completed. ARIMA MAE: 59.03203725879767, RF MAE: 36.44437696626981\n",
      "Fold completed. ARIMA MAE: 290.5936124081807, RF MAE: 26.614663460043616\n",
      "Fold completed. ARIMA MAE: 38.726714638923596, RF MAE: 21.65855579372828\n",
      "Fold completed. ARIMA MAE: 46.69064304190017, RF MAE: 24.854604883181537\n",
      "Processing FOODS_3_120_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 52.60377358490566, RF MAE: 53.10476190476191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/pmdarima/arima/auto.py:444: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold completed. ARIMA MAE: 120.95479299693288, RF MAE: 17.528479436783226\n",
      "Fold completed. ARIMA MAE: 26.568387045797028, RF MAE: 19.351807883178054\n",
      "Fold completed. ARIMA MAE: 21.07701740580339, RF MAE: 22.074143210602806\n",
      "Fold completed. ARIMA MAE: 38.566311396061394, RF MAE: 19.009118752029888\n",
      "Processing FOODS_3_252_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 10.584738709656099, RF MAE: 13.01434814814815\n",
      "Fold completed. ARIMA MAE: 13.105612751051275, RF MAE: 14.025446560846559\n",
      "Fold completed. ARIMA MAE: 38.45116147652414, RF MAE: 12.326678306878307\n",
      "Fold completed. ARIMA MAE: 27.506876869128366, RF MAE: 12.326512698412698\n",
      "Fold completed. ARIMA MAE: 12.18900183742526, RF MAE: 11.532054572940288\n",
      "Processing FOODS_3_555_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 17.423916727705627, RF MAE: 6.173224111866969\n",
      "Fold completed. ARIMA MAE: 5.429391771068531, RF MAE: 6.232328647014361\n",
      "Fold completed. ARIMA MAE: 5.281615837480839, RF MAE: 6.104027538422776\n",
      "Fold completed. ARIMA MAE: 5.421564537706883, RF MAE: 6.130507671957672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/pmdarima/arima/_auto_solvers.py:524: ModelFitWarning: Error fitting  ARIMA(2,0,2)(2,0,1)[7] intercept (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/pmdarima/arima/_auto_solvers.py\", line 508, in _fit_candidate_model\n",
      "    fit.fit(y, X=X, **fit_params)\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/pmdarima/arima/arima.py\", line 603, in fit\n",
      "    self._fit(y, X, **fit_args)\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/pmdarima/arima/arima.py\", line 524, in _fit\n",
      "    fit, self.arima_res_ = _fit_wrapper()\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/pmdarima/arima/arima.py\", line 510, in _fit_wrapper\n",
      "    fitted = arima.fit(\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 703, in fit\n",
      "    mlefit = super().fit(start_params, method=method,\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/base/model.py\", line 566, in fit\n",
      "    xopt, retvals, optim_settings = optimizer._fit(f, score, start_params,\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/base/optimizer.py\", line 243, in _fit\n",
      "    xopt, retvals = func(objective, gradient, start_params, fargs, kwargs,\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/base/optimizer.py\", line 660, in _fit_lbfgs\n",
      "    retvals = optimize.fmin_l_bfgs_b(func, start_params, maxiter=maxiter,\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 237, in fmin_l_bfgs_b\n",
      "    res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py\", line 407, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 296, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 262, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 163, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py\", line 145, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/base/model.py\", line 534, in f\n",
      "    return -self.loglike(params, *args) / nobs\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 938, in loglike\n",
      "    loglike = self.ssm.loglike(complex_step=complex_step, **kwargs)\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 1001, in loglike\n",
      "    kfilter = self._filter(**kwargs)\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 921, in _filter\n",
      "    self._initialize_state(prefix=prefix, complex_step=complex_step)\n",
      "  File \"/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/statsmodels/tsa/statespace/representation.py\", line 1058, in _initialize_state\n",
      "    self._statespaces[prefix].initialize(self.initialization,\n",
      "  File \"statsmodels/tsa/statespace/_representation.pyx\", line 1362, in statsmodels.tsa.statespace._representation.dStatespace.initialize\n",
      "  File \"statsmodels/tsa/statespace/_initialization.pyx\", line 288, in statsmodels.tsa.statespace._initialization.dInitialization.initialize\n",
      "  File \"statsmodels/tsa/statespace/_initialization.pyx\", line 406, in statsmodels.tsa.statespace._initialization.dInitialization.initialize_stationary_stationary_cov\n",
      "  File \"statsmodels/tsa/statespace/_tools.pyx\", line 1548, in statsmodels.tsa.statespace._tools._dsolve_discrete_lyapunov\n",
      "numpy.linalg.LinAlgError: LU decomposition error.\n",
      "\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold completed. ARIMA MAE: 4.787165930330738, RF MAE: 5.527988107835727\n",
      "Processing FOODS_3_586_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 15.332695430333656, RF MAE: 13.492632275132275\n",
      "Fold completed. ARIMA MAE: 13.246389778301284, RF MAE: 11.855555555555556\n",
      "Fold completed. ARIMA MAE: 11.178444201409338, RF MAE: 11.327628571428571\n",
      "Fold completed. ARIMA MAE: 26.926922600832157, RF MAE: 11.835697959183674\n",
      "Fold completed. ARIMA MAE: 11.36623325324494, RF MAE: 11.479730687830687\n",
      "Processing FOODS_3_587_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 21.283304525090234, RF MAE: 11.40168253968254\n",
      "Fold completed. ARIMA MAE: 23.438018660117756, RF MAE: 12.080049886621312\n",
      "Fold completed. ARIMA MAE: 24.228789512960457, RF MAE: 6.66794962639945\n",
      "Fold completed. ARIMA MAE: 19.283835717804358, RF MAE: 7.684779807447977\n",
      "Fold completed. ARIMA MAE: 17.47381967415282, RF MAE: 9.683838246409675\n",
      "Processing FOODS_3_714_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 14.476563094307803, RF MAE: 12.74560574452003\n",
      "Fold completed. ARIMA MAE: 15.293921505280705, RF MAE: 10.214619198790627\n",
      "Fold completed. ARIMA MAE: 8.924105021442724, RF MAE: 10.339371730914587\n",
      "Fold completed. ARIMA MAE: 24.138530016419264, RF MAE: 9.736206386999244\n",
      "Fold completed. ARIMA MAE: 6.1449744216269275, RF MAE: 9.404366666666666\n",
      "Processing FOODS_3_808_CA_1_validation\n",
      "Fold completed. ARIMA MAE: 32.68847569699765, RF MAE: 18.088127397260273\n",
      "Fold completed. ARIMA MAE: 44.781157115351725, RF MAE: 15.514027182137152\n",
      "Fold completed. ARIMA MAE: 20.281165273881676, RF MAE: 13.034608991340171\n",
      "Fold completed. ARIMA MAE: 34.11709489116121, RF MAE: 6.5617961079921265\n",
      "Fold completed. ARIMA MAE: 14.777218458157982, RF MAE: 6.678106140105266\n",
      "Product ID FOODS_2_197_CA_1_validation: ARIMA MAE = 11.389206688681842, RF MAE = 9.037291715585411\n",
      "Product ID FOODS_3_080_CA_1_validation: ARIMA MAE = 5.552558316847994, RF MAE = 6.665231186696902\n",
      "Product ID FOODS_3_090_CA_1_validation: ARIMA MAE = 94.92558961892563, RF MAE = 30.35505610455944\n",
      "Product ID FOODS_3_120_CA_1_validation: ARIMA MAE = 51.95405648590007, RF MAE = 26.213662237471176\n",
      "Product ID FOODS_3_252_CA_1_validation: ARIMA MAE = 20.36747832875703, RF MAE = 12.6450080574452\n",
      "Product ID FOODS_3_555_CA_1_validation: ARIMA MAE = 7.6687309608585235, RF MAE = 6.033615215419502\n",
      "Product ID FOODS_3_586_CA_1_validation: ARIMA MAE = 15.610137052824276, RF MAE = 11.998249009826154\n",
      "Product ID FOODS_3_587_CA_1_validation: ARIMA MAE = 21.141553618025124, RF MAE = 9.50366002131219\n",
      "Product ID FOODS_3_714_CA_1_validation: ARIMA MAE = 13.795618811815483, RF MAE = 10.48803394557823\n",
      "Product ID FOODS_3_808_CA_1_validation: ARIMA MAE = 29.329022287110046, RF MAE = 11.975333163766997\n",
      "Average ARIMA MAE across all products: 27.173395216974605\n",
      "Average RF MAE across all products: 13.49151406576612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../raw_data/cleaned_merge_df_top10.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Prepare results storage\n",
    "results = {}\n",
    "\n",
    "# Assuming there is a id column to iterate over and 'sales' as the target\n",
    "for id in df['id'].unique():\n",
    "    print(f\"Processing {id}\")\n",
    "    series = df[df['id'] == id]['sales']\n",
    "\n",
    "    # Initialize time-series cross-validator\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    # Lists to store MAE scores for comparison\n",
    "    mae_scores_arima = []\n",
    "    mae_scores_rf = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for train_idx, test_idx in tscv.split(series):\n",
    "        train_data, test_data = series.iloc[train_idx], series.iloc[test_idx]\n",
    "\n",
    "        # Auto-ARIMA model\n",
    "        arima_model = auto_arima(train_data, seasonal=True, m=7, suppress_warnings=True, stepwise=True)\n",
    "        arima_predictions = arima_model.predict(n_periods=len(test_data))\n",
    "        mae_arima = mean_absolute_error(test_data, arima_predictions)\n",
    "        mae_scores_arima.append(mae_arima)\n",
    "\n",
    "        # Random Forest model with lag features\n",
    "        X_train = pd.DataFrame({\n",
    "            'lag1': train_data.shift(1),\n",
    "            'lag2': train_data.shift(2),\n",
    "            'lag3': train_data.shift(3)\n",
    "        }).dropna()\n",
    "        y_train = train_data.iloc[3:]\n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        X_test = pd.DataFrame({\n",
    "            'lag1': test_data.shift(1),\n",
    "            'lag2': test_data.shift(2),\n",
    "            'lag3': test_data.shift(3)\n",
    "        }).dropna()\n",
    "        y_test_aligned = test_data.iloc[3:]  # Align y_test with the available X_test\n",
    "        rf_predictions = rf_model.predict(X_test)\n",
    "        mae_rf = mean_absolute_error(y_test_aligned, rf_predictions)\n",
    "        mae_scores_rf.append(mae_rf)\n",
    "\n",
    "        print(f\"Fold completed. ARIMA MAE: {mae_arima}, RF MAE: {mae_rf}\")\n",
    "\n",
    "    # Store results\n",
    "    results[id] = {\n",
    "        'ARIMA_MAE': np.mean(mae_scores_arima),\n",
    "        'RF_MAE': np.mean(mae_scores_rf)\n",
    "    }\n",
    "\n",
    "# Print overall results\n",
    "for product, scores in results.items():\n",
    "    print(f\"Product ID {product}: ARIMA MAE = {scores['ARIMA_MAE']}, RF MAE = {scores['RF_MAE']}\")\n",
    "\n",
    "# Optionally, summarize all results\n",
    "average_arima_mae = np.mean([res['ARIMA_MAE'] for res in results.values()])\n",
    "average_rf_mae = np.mean([res['RF_MAE'] for res in results.values()])\n",
    "print(f\"Average ARIMA MAE across all products: {average_arima_mae}\")\n",
    "print(f\"Average RF MAE across all products: {average_rf_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "583d7657-aacf-4f85-8f1d-10cc3623a871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0a6a3b-6cb3-4c34-b66d-8864a1b38ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julietta/.pyenv/versions/3.10.6/envs/walmart/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 59884 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 3.5194842680202996\n",
      "Average Mean Absolute Error across all products: 3.5194842680202996\n"
     ]
    }
   ],
   "source": [
    "# Start a Dask client\n",
    "client = Client()\n",
    "\n",
    "# Define the specifics of the custom time-series cross-validation\n",
    "num_splits = 5\n",
    "days_per_split = 28\n",
    "\n",
    "# Dictionary to store results for each product id\n",
    "product_results = {}\n",
    "auto_arima_models = {}\n",
    "\n",
    "# Function to perform ARIMA modeling and calculate MAE\n",
    "def perform_auto_arima(train_data, test_data):\n",
    "    y_train = train_data[\"sales\"]\n",
    "    y_test = test_data[\"sales\"]\n",
    "\n",
    "    # Fit ARIMA model on the training data\n",
    "    model = auto_arima(y_train, start_p=0, start_q=0, max_p=5, max_q=5, d=1,\n",
    "                       seasonal=True, trace=False, error_action='ignore', \n",
    "                       suppress_warnings=True, stepwise=True)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(n_periods=len(y_test))\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "    return model, mae\n",
    "\n",
    "# Iterate over each unique product series identified by id\n",
    "for product_id in df['id'].unique():\n",
    "    print(f\"Analyzing product: {id}\")\n",
    "    product_data = df[df['id'] == id]\n",
    "\n",
    "    # Check if enough data is available\n",
    "    if len(product_data) < days_per_split * num_splits:\n",
    "        print(f\"Not enough data for product {id} to perform {num_splits} splits with {days_per_split} days each.\")\n",
    "        continue\n",
    "    \n",
    "    mae_scores = []\n",
    "    \n",
    "    # Create data slices for 5-fold validation with each test slice being exactly 28 days\n",
    "    for i in range(1, num_splits + 1):\n",
    "        train_data = product_data.iloc[:-days_per_split * i]\n",
    "        test_data = product_data.iloc[-days_per_split * i: -days_per_split * (i - 1) if i > 1 else None]\n",
    "\n",
    "        # Perform Auto ARIMA in parallel\n",
    "        future = client.submit(perform_auto_arima, train_data, test_data)\n",
    "        model, mae = client.gather(future)\n",
    "\n",
    "        # Store results\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "    # Calculate average MAE and store the model\n",
    "    average_mae = np.mean(mae_scores)\n",
    "    product_results[id] = average_mae\n",
    "    auto_arima_models[id] = model\n",
    "    print(f'Average Mean Absolute Error for {id}: {average_mae}')\n",
    "\n",
    "    # Save the model\n",
    "    #filename = f'/path_to_save_models/{id}_model.pkl'\n",
    "    #with open(filename, 'wb') as f:\n",
    "        #pickle.dump(model, f)\n",
    "\n",
    "# Print average MAE across all products\n",
    "average_mae_across_products = np.mean(list(product_results.values()))\n",
    "print(f'Average Mean Absolute Error across all products: {average_mae_across_products}')\n",
    "\n",
    "# Handle possible convergence warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc74d49e-772f-46c6-adf0-ae66e85c72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pickle\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e44770ee-123e-4c03-b2b0-2256bd07f0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_2_197_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_080_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_090_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_120_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_252_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_555_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_586_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_587_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_714_CA_1_validation: 4.685929990104027\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n",
      "Average Mean Absolute Error for FOODS_3_808_CA_1_validation: 4.685929990104027\n",
      "Average Mean Absolute Error across all products: 4.685929990104027\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the specifics of the custom time-series cross-validation\n",
    "num_splits = 5\n",
    "days_per_split = 28\n",
    "\n",
    "# Dictionary to store results for each product id\n",
    "product_results = {}\n",
    "random_forest_models = {}\n",
    "\n",
    "# Function to perform Random Forest modeling and calculate MAE\n",
    "def perform_random_forest(train_data, test_data):\n",
    "    # Prepare features by creating lags\n",
    "    y_train = train_data[\"sales\"]\n",
    "    y_test = test_data[\"sales\"]\n",
    "    X_train = pd.DataFrame({\n",
    "        'lag1': y_train.shift(1),\n",
    "        'lag2': y_train.shift(2),\n",
    "        'lag3': y_train.shift(3)\n",
    "    }).dropna()\n",
    "    y_train = y_train.iloc[3:]  # Align target with available features\n",
    "    \n",
    "    X_test = pd.DataFrame({\n",
    "        'lag1': y_test.shift(1),\n",
    "        'lag2': y_test.shift(2),\n",
    "        'lag3': y_test.shift(3)\n",
    "    }).dropna()\n",
    "    y_test = y_test.iloc[3:]  # Align target with available features\n",
    "\n",
    "    # Fit Random Forest model on the training data\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "    return model, mae\n",
    "\n",
    "# Iterate over each unique product series identified by id\n",
    "for product_id in df['id'].unique():\n",
    "    print(f\"Analyzing product: {id}\")\n",
    "    product_data = df[df['id'] == id]\n",
    "\n",
    "    # Check if enough data is available\n",
    "    if len(product_data) < days_per_split * num_splits:\n",
    "        print(f\"Not enough data for product {id} to perform {num_splits} splits with {days_per_split} days each.\")\n",
    "        continue\n",
    "    \n",
    "    mae_scores = []\n",
    "    \n",
    "# Create data slices for 5-fold validation with each test slice being exactly 28 days\n",
    "    for i in range(1, num_splits + 1):\n",
    "        train_data = product_data.iloc[:-days_per_split * i]\n",
    "        test_data = product_data.iloc[-days_per_split * i: -days_per_split * (i - 1) if i > 1 else None]\n",
    "\n",
    "        # Perform Random Forest modeling in parallel\n",
    "        future = client.submit(perform_random_forest, train_data, test_data)\n",
    "        model, mae = client.gather(future)\n",
    "\n",
    "        # Store results\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "    # Calculate average MAE and store the model\n",
    "    average_mae = np.mean(mae_scores)\n",
    "    product_results[product_id] = average_mae\n",
    "    random_forest_models[product_id] = model\n",
    "    print(f'Average Mean Absolute Error for {product_id}: {average_mae}')\n",
    "\n",
    "# Print average MAE across all products\n",
    "average_mae_across_products = np.mean(list(product_results.values()))\n",
    "print(f'Average Mean Absolute Error across all products: {average_mae_across_products}')\n",
    "\n",
    "# Handle possible convergence warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279e64d-98cc-4053-b067-4656196a6346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
