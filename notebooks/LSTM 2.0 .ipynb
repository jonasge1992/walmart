{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc7ca504-dd2d-454b-95ee-23bb599d40ec",
   "metadata": {},
   "source": [
    "Forecast model for Walmart's top 10 best-selling products using an LSTM based on detailed specifications for cross-validation, train-test splits, and sequence handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff93732-38dd-400f-b4ec-f21445cd4d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 11:12:51.858722: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 11:12:52.825662: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868b6ab8-2a29-4c76-9d53-fb2e52a90dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../raw_data/cleaned_merge_df_top10.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70e7f98-b793-4157-8b7b-7e42fcd42bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['scaled_sales'] = scaler.fit_transform(df[['sales']])\n",
    "\n",
    "def create_sequences(data, input_length, output_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - input_length - output_length + 1):\n",
    "        X.append(data[i:(i + input_length)])\n",
    "        y.append(data[(i + input_length):(i + input_length + output_length)])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "input_length = 200\n",
    "output_length = 28\n",
    "n_features = 1  # since we are only using sales as feature\n",
    "n_splits = 10  # Number of folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d94bfb-2d55-42f6-a019-810f091f13ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 11:12:54.039113: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 11:12:54.039653: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Time Series Cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Define the LSTM model outside the loop\n",
    "model = Sequential([LSTM(50, activation='relu'), Dense(output_length)])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e814e63-4793-4eb6-941a-93101eb6026c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation\n",
    "fold_results = []\n",
    "\n",
    "for train_index, test_index in tscv.split(df):\n",
    "    train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "\n",
    "    # Create sequences\n",
    "    X_train, y_train = create_sequences(train['scaled_sales'].values, input_length, output_length)\n",
    "    X_test, y_test = create_sequences(test['scaled_sales'].values, input_length, output_length)\n",
    "\n",
    "    # Reshape for LSTM input\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    fold_results.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5701d8-92cc-4bbc-97ad-4fff67076a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.300954867704963, 17.80040276465064, 20.875092110706454, 17.507685447234213, 20.81703526627847, 12.060208551523202, 12.464558223213617, 10.620830240844686, 9.662697408328611, 9.394611731343602]\n"
     ]
    }
   ],
   "source": [
    "print(fold_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb26c287-cb3f-49d8-b1cb-b1cb99df2330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE per fold: [24.300954867704963, 17.80040276465064, 20.875092110706454, 17.507685447234213, 20.81703526627847, 12.060208551523202, 12.464558223213617, 10.620830240844686, 9.662697408328611, 9.394611731343602]\n",
      "Average MAE: 15.550407661182845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Forecast for the next 28 days: [19.929655   17.335506   43.516296   39.287666   31.189104   19.33259\n",
      " 32.195198   17.676855   17.938084    2.0670536  14.995823   17.32747\n",
      " 34.288174   33.34412    24.17708    12.287469   19.785622   13.292426\n",
      " 10.820728    0.64970976 16.070171   17.874363   36.542915   34.42241\n",
      " 23.064554   16.216448   25.215542   12.286285  ]\n"
     ]
    }
   ],
   "source": [
    "# Report results\n",
    "print(\"MAE per fold:\", fold_results)\n",
    "print(\"Average MAE:\", np.mean(fold_results))\n",
    "\n",
    "# Forecast next 28 days for the last sequence of the last fold\n",
    "last_sequence = df['scaled_sales'].values[-input_length:]\n",
    "last_sequence = last_sequence.reshape((1, input_length, n_features))\n",
    "future_sales = model.predict(last_sequence)\n",
    "future_sales = scaler.inverse_transform(future_sales)\n",
    "print(\"Forecast for the next 28 days:\", future_sales.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958d600-da35-49ad-9f88-8be7f001a823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
