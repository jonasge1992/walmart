{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c91c641-7676-421d-aef8-79ef55aa0315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5842e-7d08-4165-90ec-b7edfc62dcc7",
   "metadata": {},
   "source": [
    "# 0 Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "023fbbd9-6c97-41d6-bf76-920c4aee83ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_2_197_CA_1_validation</td>\n",
       "      <td>FOODS_2_197</td>\n",
       "      <td>FOODS_2</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>38</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_080_CA_1_validation</td>\n",
       "      <td>FOODS_3_080</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>33</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_090_CA_1_validation</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>107</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_120_CA_1_validation</td>\n",
       "      <td>FOODS_3_120</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_252_CA_1_validation</td>\n",
       "      <td>FOODS_3_252</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>19</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id      item_id  dept_id cat_id store_id  \\\n",
       "date                                                                            \n",
       "2011-01-29  FOODS_2_197_CA_1_validation  FOODS_2_197  FOODS_2  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_080_CA_1_validation  FOODS_3_080  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_090_CA_1_validation  FOODS_3_090  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_120_CA_1_validation  FOODS_3_120  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_252_CA_1_validation  FOODS_3_252  FOODS_3  FOODS     CA_1   \n",
       "\n",
       "           state_id  sales   weekday  wday event_name_1 event_type_1  \\\n",
       "date                                                                   \n",
       "2011-01-29       CA     38  Saturday     1            0            0   \n",
       "2011-01-29       CA     33  Saturday     1            0            0   \n",
       "2011-01-29       CA    107  Saturday     1            0            0   \n",
       "2011-01-29       CA      0  Saturday     1            0            0   \n",
       "2011-01-29       CA     19  Saturday     1            0            0   \n",
       "\n",
       "           event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \n",
       "date                                                                         \n",
       "2011-01-29            0            0        0        0        0        2.98  \n",
       "2011-01-29            0            0        0        0        0        1.48  \n",
       "2011-01-29            0            0        0        0        0        1.25  \n",
       "2011-01-29            0            0        0        0        0        0.00  \n",
       "2011-01-29            0            0        0        0        0        1.48  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset\n",
    "merge_df_scaled = pd.read_csv('../raw_data/cleaned_merge_df_top10.csv')\n",
    "merge_df_scaled['date'] = pd.to_datetime(merge_df_scaled['date'])\n",
    "merge_df_scaled.set_index('date', inplace=True)\n",
    "\n",
    "merge_df_scaled.head()\n",
    "# 382600 rows Ã— 64 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c90d7-181f-4c34-b9db-73d5632292e5",
   "metadata": {},
   "source": [
    "# 1. Defining Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44c2e333-1676-4450-a8ac-b1d64ce1fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prophet(product_data):\n",
    "\n",
    "    product_data.reset_index(inplace=True,names=\"date\")\n",
    "    \n",
    "    prophet_product_df = product_data[[\"id\",\"date\",\"sales\"]]\n",
    "    prophet_product_df.columns = [\"id\",\"ds\",\"y\"]\n",
    "    prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
    "    \n",
    "    data_train = prophet_product_df.iloc[:-28]\n",
    "    data_test = prophet_product_df.iloc[-28:]\n",
    "    X_train = data_train[\"ds\"]\n",
    "    y_train = data_train[\"y\"]\n",
    "    X_test = data_test[\"ds\"]\n",
    "    y_test = data_test[\"y\"]\n",
    "    \n",
    "    fbp = Prophet()\n",
    "\n",
    "    model = fbp.fit(data_train)\n",
    "    \n",
    "    predict_placeholder = fbp.make_future_dataframe(28,freq=\"D\")\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = fbp.predict(predict_placeholder[-28:])\n",
    "    \n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    mae = mean_absolute_error(y_test, y_pred[\"yhat\"])\n",
    "    \n",
    "    return model, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "151bd3d5-e70c-41ef-8a3e-2da51e4fe900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_auto_arima(product_data):\n",
    "    data_train = product_data.iloc[:-28]\n",
    "    data_test = product_data.iloc[-28:]\n",
    "    y_train = data_train[\"sales\"]\n",
    "    y_test = data_test[\"sales\"]\n",
    "\n",
    "    # Fit ARIMA model on the training data using auto_arima to find the best (p, d, q)\n",
    "    model = auto_arima(y_train, start_p=0, start_q=0, max_p=5, max_q=5, d=1,\n",
    "                       seasonal=True, trace=False, error_action='ignore', \n",
    "                       suppress_warnings=True, stepwise=True)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(n_periods=len(y_test))\n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "    return model, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4313bdf-003b-428f-addb-07ad6b7058b8",
   "metadata": {},
   "source": [
    "# 2.Running all models in a loop to find for each product with lowest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e09341ed-7407-4421-87d4-b97c92ef1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\"ARIMA\",\"Prophet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25636b8c-848f-4188-bc73-1546fdeb687b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing product: FOODS_2_197_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:24:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:24:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_2_197_CA_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 8.726633436944372\n",
      "Analyzing product: FOODS_3_080_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:24:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:24:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_080_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 5.460836328763631\n",
      "Analyzing product: FOODS_3_090_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:25:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:25:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_090_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 17.08460121656075\n",
      "Analyzing product: FOODS_3_120_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:26:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:26:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_120_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 24.60149551782473\n",
      "Analyzing product: FOODS_3_252_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:27:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:27:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_252_CA_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 6.680438583319882\n",
      "Analyzing product: FOODS_3_555_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:28:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:28:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_555_CA_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 4.34514653363894\n",
      "Analyzing product: FOODS_3_586_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:28:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:28:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_586_CA_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 7.991362870463669\n",
      "Analyzing product: FOODS_3_587_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:29:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:29:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_587_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 9.546208647532103\n",
      "Analyzing product: FOODS_3_714_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:30:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:30:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_714_CA_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 5.518778222112147\n",
      "Analyzing product: FOODS_3_808_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70471/1215182328.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_product_df['ds'] = pd.to_datetime(prophet_df['ds'])\n",
      "14:31:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:31:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results for FOODS_3_808_CA_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 3.219758128147768\n",
      "                                                                           MAE\n",
      "id                                                                            \n",
      "FOODS_2_197_CA_1_validation  {'best_score': 8.726633436944372, 'best_model'...\n",
      "FOODS_3_080_CA_1_validation  {'best_score': 5.460836328763631, 'best_model'...\n",
      "FOODS_3_090_CA_1_validation  {'best_score': 17.08460121656075, 'best_model'...\n",
      "FOODS_3_120_CA_1_validation  {'best_score': 24.60149551782473, 'best_model'...\n",
      "FOODS_3_252_CA_1_validation  {'best_score': 6.680438583319882, 'best_model'...\n",
      "FOODS_3_555_CA_1_validation  {'best_score': 4.34514653363894, 'best_model':...\n",
      "FOODS_3_586_CA_1_validation  {'best_score': 7.991362870463669, 'best_model'...\n",
      "FOODS_3_587_CA_1_validation  {'best_score': 9.546208647532103, 'best_model'...\n",
      "FOODS_3_714_CA_1_validation  {'best_score': 5.518778222112147, 'best_model'...\n",
      "FOODS_3_808_CA_1_validation  {'best_score': 3.219758128147768, 'best_model'...\n",
      "Total average MAE: 9.3175259485308\n"
     ]
    }
   ],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "# Dictionary to store MAE results for each unique time-series identified by id\n",
    "product_results = {}\n",
    "average_mae = []\n",
    "\n",
    "# Iterate over each unique product series identified by id\n",
    "for id in merge_df_scaled['id'].unique()[:10]:\n",
    "    print(f\"Analyzing product: {id}\")\n",
    "    product_data = merge_df_scaled[merge_df_scaled['id'] == id]\n",
    "\n",
    "    # Results list for the current product time-series\n",
    "    results = {}\n",
    "    best_score = 999.99\n",
    "    best_model_name = \"\"\n",
    "\n",
    "\n",
    "\n",
    "    #Looping all models\n",
    "    for model_name in models_list:\n",
    "\n",
    "        if model_name == \"ARIMA\":\n",
    "            #TODO: Add 5-fold split here for another loop (or inside the model function?) and then take the average score per model as their mae score\n",
    "            \n",
    "            # Fit ARIMA model on the training data using auto_arima to find the best (p, d, q)\n",
    "            model, mae = perform_auto_arima(product_data)\n",
    "            results[model_name] = {\"mae\": mae, \"model\": model}\n",
    "            if mae < best_score:\n",
    "                best_score = mae\n",
    "                best_model = model\n",
    "                best_model_name = model_name\n",
    "\n",
    "        #elif model_name == \"ExponentialSmoothing\":\n",
    "\n",
    "            # To be built\n",
    "            #model, mae = perform_exp_smth(product_data)\n",
    "            #results[model_name] = {\"mae\": mae, \"model\": model}\n",
    "            #if mae < best_score:\n",
    "             #   best_score = mae\n",
    "              #  best_model = model\n",
    "               # best_model_name = model_name\n",
    "\n",
    "        elif model_name == \"Prophet\":\n",
    "\n",
    "            model, mae = perform_prophet(product_data)\n",
    "            results[model_name] = {\"mae\": mae, \"model\": model}\n",
    "            if mae < best_score:\n",
    "                best_score = mae\n",
    "                best_model = model\n",
    "                best_model_name = model_name\n",
    "\n",
    "\n",
    "    #Printing results for this product\n",
    "    print(results)\n",
    "    print(f\"Model results for {id}\")\n",
    "    print(f\"Best model: {best_model_name}\")\n",
    "    print(f\"Best score: {best_score}\")\n",
    "\n",
    "    average_mae.append(best_score)\n",
    "\n",
    "    # Store the average MAE for the current product time-series\n",
    "    product_results[id] = {\"best_score\": best_score, \"best_model\": best_model_name, \"model\": best_model}\n",
    "\n",
    "    #Store the best model in a pkl file\n",
    "    filename = f'../models/{id}_model.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df_arima = pd.DataFrame(product_results.items(), columns=['id', 'MAE'])\n",
    "\n",
    "# Set the 'id' column as the index\n",
    "results_df_arima.set_index('id', inplace=True)\n",
    "\n",
    "average_mae = np.mean(average_mae)\n",
    "\n",
    "print(f\"Total average MAE: {average_mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802283de-40e3-44e5-8123-a7df61265b43",
   "metadata": {},
   "source": [
    "# ----------- Jonas Cleaned and Optimized until here -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34cf118d-0c1e-4418-a5dd-40d154aee999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define the objective function\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial, y_train, tscv):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial, y_train, tscv):\n",
    "    trend = trial.suggest_categorical('trend', ['add'])\n",
    "    seasonal = trial.suggest_categorical('seasonal', [None, 'add'])\n",
    "    seasonal_periods = trial.suggest_categorical('seasonal_periods', [None, 4, 7, 12])\n",
    "    \n",
    "    product_results = []\n",
    "    for train_index, test_index in tscv.split(y_train):\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Fit Holt-Winters model on the training data\n",
    "        model = ExponentialSmoothing(y_train_fold, trend=trend, seasonal=seasonal, seasonal_periods=seasonal_periods,freq='D')\n",
    "        fitted_model = model.fit(optimized=True)\n",
    "\n",
    "        # Predict on the test data\n",
    "        predictions = fitted_model.forecast(steps=len(y_test_fold))\n",
    "\n",
    "        # Calculate and store the error metric\n",
    "        mae = mean_absolute_error(y_test_fold, predictions)\n",
    "        product_results.append(mae)\n",
    "\n",
    "    # Average MAE for this product\n",
    "    average_mae = np.mean(product_results)\n",
    "    return average_mae\n",
    "\n",
    "# Create a dictionary to store results\n",
    "results_dict = {}\n",
    "\n",
    "# Iterate over each unique product ID\n",
    "for id in merge_df_scaled['id'].unique()[:10]:\n",
    "\n",
    "    # Create a study object\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    print(f\"Optimizing hyperparameters for product: {id}\")\n",
    "    product_data = merge_df_scaled[merge_df_scaled['id'] == id]\n",
    "    y_train = product_data['sales']\n",
    "    \n",
    "    # Initialize time series cross-validator\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # Run the optimization process for the current product\n",
    "    study.optimize(lambda trial: objective(trial, y_train, tscv), n_trials=10)\n",
    "\n",
    "    # Get the best hyperparameters and the corresponding best MAE\n",
    "    best_params = study.best_params\n",
    "    best_mae = study.best_value\n",
    "    \n",
    "    # Store the results in the dictionary\n",
    "    results_dict[id] = {'ExpSmoothing_params': best_params, 'ExpSmoothing_MAE': best_mae}\n",
    "\n",
    "# Print the results dictionary\n",
    "print(results_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4d1187-fb23-450a-ac87-0ad96d294124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExpSmoothing_params</th>\n",
       "      <th>ExpSmoothing_MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_008_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>7.610342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_015_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>6.258854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_016_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>4.346778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_019_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>5.017659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_032_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>5.799883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_048_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>6.325378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_067_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>6.161814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_169_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>5.085608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_178_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>9.991154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_189_CA_1_validation</th>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>5.564773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             ExpSmoothing_params  \\\n",
       "id                                                                                 \n",
       "HOBBIES_1_008_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_015_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_016_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "HOBBIES_1_019_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_032_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "HOBBIES_1_048_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "HOBBIES_1_067_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_169_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "HOBBIES_1_178_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_189_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "\n",
       "                              ExpSmoothing_MAE  \n",
       "id                                              \n",
       "HOBBIES_1_008_CA_1_validation         7.610342  \n",
       "HOBBIES_1_015_CA_1_validation         6.258854  \n",
       "HOBBIES_1_016_CA_1_validation         4.346778  \n",
       "HOBBIES_1_019_CA_1_validation         5.017659  \n",
       "HOBBIES_1_032_CA_1_validation         5.799883  \n",
       "HOBBIES_1_048_CA_1_validation         6.325378  \n",
       "HOBBIES_1_067_CA_1_validation         6.161814  \n",
       "HOBBIES_1_169_CA_1_validation         5.085608  \n",
       "HOBBIES_1_178_CA_1_validation         9.991154  \n",
       "HOBBIES_1_189_CA_1_validation         5.564773  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results dictionary to a DataFrame\n",
    "results_df_exp = pd.DataFrame(results_dict).T.reset_index()\n",
    "results_df_exp.columns = ['id', 'ExpSmoothing_params', 'ExpSmoothing_MAE']\n",
    "\n",
    "# Set the 'Product ID' column as the index\n",
    "results_df_exp.set_index('id', inplace=True)\n",
    "results_df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f631d89f-54a6-4f72-a360-5162b82f0dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARIMA_MAE</th>\n",
       "      <th>ExpSmoothing_params</th>\n",
       "      <th>ExpSmoothing_MAE</th>\n",
       "      <th>Best MAE</th>\n",
       "      <th>Best Method</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_008_CA_1_validation</th>\n",
       "      <td>6.531440</td>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>7.610342</td>\n",
       "      <td>6.53144</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_015_CA_1_validation</th>\n",
       "      <td>5.591126</td>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>6.258854</td>\n",
       "      <td>5.591126</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_016_CA_1_validation</th>\n",
       "      <td>4.480105</td>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>4.346778</td>\n",
       "      <td>4.346778</td>\n",
       "      <td>Exponential Smoothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_019_CA_1_validation</th>\n",
       "      <td>5.017305</td>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>5.017659</td>\n",
       "      <td>5.017305</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_032_CA_1_validation</th>\n",
       "      <td>5.426358</td>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>5.799883</td>\n",
       "      <td>5.426358</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_048_CA_1_validation</th>\n",
       "      <td>6.173675</td>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>6.325378</td>\n",
       "      <td>6.173675</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_067_CA_1_validation</th>\n",
       "      <td>5.050134</td>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>6.161814</td>\n",
       "      <td>5.050134</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_169_CA_1_validation</th>\n",
       "      <td>5.745132</td>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>5.085608</td>\n",
       "      <td>5.085608</td>\n",
       "      <td>Exponential Smoothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_178_CA_1_validation</th>\n",
       "      <td>7.523928</td>\n",
       "      <td>{'trend': 'add', 'seasonal': 'add', 'seasonal_...</td>\n",
       "      <td>9.991154</td>\n",
       "      <td>7.523928</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOBBIES_1_189_CA_1_validation</th>\n",
       "      <td>5.307592</td>\n",
       "      <td>{'trend': 'add', 'seasonal': None, 'seasonal_p...</td>\n",
       "      <td>5.564773</td>\n",
       "      <td>5.307592</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ARIMA_MAE  \\\n",
       "id                                         \n",
       "HOBBIES_1_008_CA_1_validation   6.531440   \n",
       "HOBBIES_1_015_CA_1_validation   5.591126   \n",
       "HOBBIES_1_016_CA_1_validation   4.480105   \n",
       "HOBBIES_1_019_CA_1_validation   5.017305   \n",
       "HOBBIES_1_032_CA_1_validation   5.426358   \n",
       "HOBBIES_1_048_CA_1_validation   6.173675   \n",
       "HOBBIES_1_067_CA_1_validation   5.050134   \n",
       "HOBBIES_1_169_CA_1_validation   5.745132   \n",
       "HOBBIES_1_178_CA_1_validation   7.523928   \n",
       "HOBBIES_1_189_CA_1_validation   5.307592   \n",
       "\n",
       "                                                             ExpSmoothing_params  \\\n",
       "id                                                                                 \n",
       "HOBBIES_1_008_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_015_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_016_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "HOBBIES_1_019_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_032_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "HOBBIES_1_048_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "HOBBIES_1_067_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_169_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "HOBBIES_1_178_CA_1_validation  {'trend': 'add', 'seasonal': 'add', 'seasonal_...   \n",
       "HOBBIES_1_189_CA_1_validation  {'trend': 'add', 'seasonal': None, 'seasonal_p...   \n",
       "\n",
       "                              ExpSmoothing_MAE  Best MAE  \\\n",
       "id                                                         \n",
       "HOBBIES_1_008_CA_1_validation         7.610342   6.53144   \n",
       "HOBBIES_1_015_CA_1_validation         6.258854  5.591126   \n",
       "HOBBIES_1_016_CA_1_validation         4.346778  4.346778   \n",
       "HOBBIES_1_019_CA_1_validation         5.017659  5.017305   \n",
       "HOBBIES_1_032_CA_1_validation         5.799883  5.426358   \n",
       "HOBBIES_1_048_CA_1_validation         6.325378  6.173675   \n",
       "HOBBIES_1_067_CA_1_validation         6.161814  5.050134   \n",
       "HOBBIES_1_169_CA_1_validation         5.085608  5.085608   \n",
       "HOBBIES_1_178_CA_1_validation         9.991154  7.523928   \n",
       "HOBBIES_1_189_CA_1_validation         5.564773  5.307592   \n",
       "\n",
       "                                         Best Method  \n",
       "id                                                    \n",
       "HOBBIES_1_008_CA_1_validation                  ARIMA  \n",
       "HOBBIES_1_015_CA_1_validation                  ARIMA  \n",
       "HOBBIES_1_016_CA_1_validation  Exponential Smoothing  \n",
       "HOBBIES_1_019_CA_1_validation                  ARIMA  \n",
       "HOBBIES_1_032_CA_1_validation                  ARIMA  \n",
       "HOBBIES_1_048_CA_1_validation                  ARIMA  \n",
       "HOBBIES_1_067_CA_1_validation                  ARIMA  \n",
       "HOBBIES_1_169_CA_1_validation  Exponential Smoothing  \n",
       "HOBBIES_1_178_CA_1_validation                  ARIMA  \n",
       "HOBBIES_1_189_CA_1_validation                  ARIMA  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two DataFrames based on the product ID\n",
    "comparison_df = pd.merge(results_df_arima, results_df_exp, left_index=True, right_index=True, suffixes=('_arima', '_exp'))\n",
    "comparison_df['Best MAE'] = comparison_df[['ARIMA_MAE', 'ExpSmoothing_MAE']].min(axis=1)\n",
    "comparison_df['Best Method'] = comparison_df.apply(lambda row: 'ARIMA' if row['Best MAE'] == row['ARIMA_MAE'] else 'Exponential Smoothing', axis=1)\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b314d-6a14-476e-a6da-e020b326229b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d164fe-efdf-4bb7-b9a5-8aa23fde84c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d964ed-ad0d-411e-b4c6-cd32c72bb440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13ac0a-fa34-4333-9abf-2dc1e7592607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
