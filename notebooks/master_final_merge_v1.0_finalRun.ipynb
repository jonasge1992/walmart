{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c91c641-7676-421d-aef8-79ef55aa0315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import timedelta \n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pmdarima\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models.forecasting.tft_model import TFTModel\n",
    "from darts.metrics import mse\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import smape, mae\n",
    "from torchmetrics.regression import MeanAbsoluteError\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ab5d5-4860-4ec1-854b-9a5fbcf69082",
   "metadata": {},
   "source": [
    "# -1 Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c23922c-8d99-4757-aa9b-2a4684ab8a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#csv_file_path = \n",
    "train_df = pd.read_csv('../raw_data/sales_train_validation.csv')\n",
    "prices_df = pd.read_csv('../raw_data/sell_prices.csv')\n",
    "calendar_df = pd.read_csv('../raw_data/calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c295793-539c-449e-9f97-da1c7b7fe453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        item_id    dept_id   cat_id  \\\n",
       "0      HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1      HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "2      HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "3      HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "4      HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "...                              ...            ...        ...      ...   \n",
       "30485    FOODS_3_823_WI_3_validation    FOODS_3_823    FOODS_3    FOODS   \n",
       "30486    FOODS_3_824_WI_3_validation    FOODS_3_824    FOODS_3    FOODS   \n",
       "30487    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS   \n",
       "30488    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS   \n",
       "30489    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS   \n",
       "\n",
       "      store_id state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  \\\n",
       "0         CA_1       CA    0    0    0    0  ...       1       3       0   \n",
       "1         CA_1       CA    0    0    0    0  ...       0       0       0   \n",
       "2         CA_1       CA    0    0    0    0  ...       2       1       2   \n",
       "3         CA_1       CA    0    0    0    0  ...       1       0       5   \n",
       "4         CA_1       CA    0    0    0    0  ...       2       1       1   \n",
       "...        ...      ...  ...  ...  ...  ...  ...     ...     ...     ...   \n",
       "30485     WI_3       WI    0    0    2    2  ...       2       0       0   \n",
       "30486     WI_3       WI    0    0    0    0  ...       0       0       0   \n",
       "30487     WI_3       WI    0    6    0    2  ...       2       1       0   \n",
       "30488     WI_3       WI    0    0    0    0  ...       0       0       1   \n",
       "30489     WI_3       WI    0    0    0    0  ...       0       0       0   \n",
       "\n",
       "       d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0           1       1       1       3       0       1       1  \n",
       "1           0       0       1       0       0       0       0  \n",
       "2           1       1       1       0       1       1       1  \n",
       "3           4       1       0       1       3       7       2  \n",
       "4           0       1       1       2       2       2       4  \n",
       "...       ...     ...     ...     ...     ...     ...     ...  \n",
       "30485       0       0       0       1       0       0       1  \n",
       "30486       0       0       0       0       0       1       0  \n",
       "30487       2       0       1       0       0       1       0  \n",
       "30488       0       0       1       0       3       1       3  \n",
       "30489       0       0       0       0       0       0       0  \n",
       "\n",
       "[30490 rows x 1919 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d48c042e-22f7-422a-9d51-35eab4459cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Sum up sales data across the last 1800 columns\n",
    "sales_data = train_df.iloc[:, 6:].sum(axis=1)\n",
    "\n",
    "train_df[\"sales_sum\"] = sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "823403ca-5328-4c38-a0d2-480575821e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_df = train_df[[\"id\",\"sales_sum\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "57f2de76-2db7-46fd-be33-59d44cb369bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'sales_sum' column in descending order\n",
    "sorted_df = filtered_df.sort_values(by='sales_sum', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5280dd23-5c78-40c4-bf17-092608e94e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_ids = sorted_df.head(50)[\"id\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3021e742-b66b-49a0-a8ba-f35473a4eca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#csv_file_path = \n",
    "train_df = pd.read_csv('../raw_data/sales_train_validation.csv')\n",
    "prices_df = pd.read_csv('../raw_data/sell_prices.csv')\n",
    "calendar_df = pd.read_csv('../raw_data/calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2710ee16-c392-4150-8c59-aaeb8709ae53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FOODS_3_090_CA_3_validation',\n",
       " 'FOODS_3_586_TX_2_validation',\n",
       " 'FOODS_3_586_TX_3_validation',\n",
       " 'FOODS_3_586_CA_3_validation',\n",
       " 'FOODS_3_090_CA_1_validation',\n",
       " 'FOODS_3_090_WI_3_validation',\n",
       " 'FOODS_3_090_TX_2_validation',\n",
       " 'FOODS_3_090_TX_3_validation',\n",
       " 'FOODS_3_252_TX_2_validation',\n",
       " 'FOODS_3_586_TX_1_validation',\n",
       " 'FOODS_3_226_WI_3_validation',\n",
       " 'FOODS_3_555_TX_2_validation',\n",
       " 'FOODS_3_090_TX_1_validation',\n",
       " 'FOODS_3_120_CA_3_validation',\n",
       " 'FOODS_3_586_CA_1_validation',\n",
       " 'FOODS_3_252_TX_3_validation',\n",
       " 'FOODS_3_586_WI_3_validation',\n",
       " 'FOODS_3_694_WI_3_validation',\n",
       " 'FOODS_3_252_CA_3_validation',\n",
       " 'FOODS_3_541_CA_3_validation',\n",
       " 'FOODS_3_635_CA_3_validation',\n",
       " 'FOODS_3_226_WI_1_validation',\n",
       " 'FOODS_3_555_TX_3_validation',\n",
       " 'FOODS_3_252_CA_1_validation',\n",
       " 'FOODS_3_377_TX_3_validation',\n",
       " 'FOODS_3_808_CA_3_validation',\n",
       " 'FOODS_3_587_CA_3_validation',\n",
       " 'FOODS_3_226_WI_2_validation',\n",
       " 'FOODS_3_555_TX_1_validation',\n",
       " 'FOODS_3_586_CA_2_validation',\n",
       " 'FOODS_3_377_TX_2_validation',\n",
       " 'FOODS_3_120_CA_1_validation',\n",
       " 'FOODS_3_694_WI_2_validation',\n",
       " 'FOODS_3_555_CA_3_validation',\n",
       " 'FOODS_3_555_WI_3_validation',\n",
       " 'FOODS_3_252_CA_2_validation',\n",
       " 'FOODS_3_252_TX_1_validation',\n",
       " 'FOODS_3_090_CA_2_validation',\n",
       " 'FOODS_3_681_CA_3_validation',\n",
       " 'FOODS_3_318_WI_3_validation',\n",
       " 'FOODS_3_714_WI_3_validation',\n",
       " 'FOODS_3_714_CA_1_validation',\n",
       " 'FOODS_3_090_CA_4_validation',\n",
       " 'FOODS_3_007_WI_2_validation',\n",
       " 'FOODS_3_714_CA_3_validation',\n",
       " 'FOODS_3_587_CA_1_validation',\n",
       " 'FOODS_3_202_CA_3_validation',\n",
       " 'FOODS_3_587_TX_2_validation',\n",
       " 'FOODS_3_234_WI_2_validation',\n",
       " 'FOODS_3_607_CA_3_validation']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c409408-a4ff-4dc0-8384-d0b36ff68a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestmodelsperid = pd.read_csv(\"../raw_data/bestmodelperid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e347a725-e6fc-4a63-9a65-6f58854a7385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>best_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FOODS_3_090_CA_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FOODS_3_586_TX_2_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FOODS_3_586_TX_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FOODS_3_586_CA_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FOODS_3_090_CA_1_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>FOODS_3_090_WI_3_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>FOODS_3_090_TX_2_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>FOODS_3_090_TX_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>FOODS_3_252_TX_2_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>FOODS_3_586_TX_1_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>FOODS_3_555_TX_2_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>FOODS_3_090_TX_1_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>FOODS_3_120_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>FOODS_3_586_CA_1_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>FOODS_3_252_TX_3_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>FOODS_3_586_WI_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>FOODS_3_694_WI_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>FOODS_3_252_CA_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>FOODS_3_541_CA_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>FOODS_3_635_CA_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>FOODS_3_226_WI_1_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>FOODS_3_555_TX_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>FOODS_3_252_CA_1_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>FOODS_3_377_TX_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>FOODS_3_808_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>FOODS_3_587_CA_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>FOODS_3_226_WI_2_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>FOODS_3_555_TX_1_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>FOODS_3_586_CA_2_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>FOODS_3_377_TX_2_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>FOODS_3_120_CA_1_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>FOODS_3_694_WI_2_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>FOODS_3_555_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>FOODS_3_555_WI_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>FOODS_3_252_CA_2_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>FOODS_3_252_TX_1_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>FOODS_3_090_CA_2_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>FOODS_3_681_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>FOODS_3_318_WI_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>FOODS_3_714_WI_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>FOODS_3_714_CA_1_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>FOODS_3_090_CA_4_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>FOODS_3_007_WI_2_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>FOODS_3_714_CA_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>FOODS_3_587_CA_1_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>FOODS_3_202_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>FOODS_3_587_TX_2_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>FOODS_3_234_WI_2_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>FOODS_3_607_CA_3_validation</td>\n",
       "      <td>Booster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                           id                 best_model\n",
       "0            0  FOODS_3_090_CA_3_validation      RandomForestRegressor\n",
       "1            1  FOODS_3_586_TX_2_validation                    Prophet\n",
       "2            2  FOODS_3_586_TX_3_validation  HoltWintersResultsWrapper\n",
       "3            3  FOODS_3_586_CA_3_validation                    Prophet\n",
       "4            4  FOODS_3_090_CA_1_validation                      ARIMA\n",
       "5            5  FOODS_3_090_WI_3_validation                      ARIMA\n",
       "6            6  FOODS_3_090_TX_2_validation      RandomForestRegressor\n",
       "7            7  FOODS_3_090_TX_3_validation      RandomForestRegressor\n",
       "8            8  FOODS_3_252_TX_2_validation                    Prophet\n",
       "9            9  FOODS_3_586_TX_1_validation                      ARIMA\n",
       "10          10  FOODS_3_555_TX_2_validation                    Prophet\n",
       "11          11  FOODS_3_090_TX_1_validation  HoltWintersResultsWrapper\n",
       "12          12  FOODS_3_120_CA_3_validation  HoltWintersResultsWrapper\n",
       "13          13  FOODS_3_586_CA_1_validation      RandomForestRegressor\n",
       "14          14  FOODS_3_252_TX_3_validation                      ARIMA\n",
       "15          15  FOODS_3_586_WI_3_validation                    Prophet\n",
       "16          16  FOODS_3_694_WI_3_validation                    Prophet\n",
       "17          17  FOODS_3_252_CA_3_validation                    Prophet\n",
       "18          18  FOODS_3_541_CA_3_validation      RandomForestRegressor\n",
       "19          19  FOODS_3_635_CA_3_validation      RandomForestRegressor\n",
       "20          20  FOODS_3_226_WI_1_validation                    Prophet\n",
       "21          21  FOODS_3_555_TX_3_validation  HoltWintersResultsWrapper\n",
       "22          22  FOODS_3_252_CA_1_validation                    Prophet\n",
       "23          23  FOODS_3_377_TX_3_validation                    Prophet\n",
       "24          24  FOODS_3_808_CA_3_validation  HoltWintersResultsWrapper\n",
       "25          25  FOODS_3_587_CA_3_validation      RandomForestRegressor\n",
       "26          26  FOODS_3_226_WI_2_validation  HoltWintersResultsWrapper\n",
       "27          27  FOODS_3_555_TX_1_validation  HoltWintersResultsWrapper\n",
       "28          28  FOODS_3_586_CA_2_validation                    Prophet\n",
       "29          29  FOODS_3_377_TX_2_validation  HoltWintersResultsWrapper\n",
       "30          30  FOODS_3_120_CA_1_validation  HoltWintersResultsWrapper\n",
       "31          31  FOODS_3_694_WI_2_validation                      ARIMA\n",
       "32          32  FOODS_3_555_CA_3_validation  HoltWintersResultsWrapper\n",
       "33          33  FOODS_3_555_WI_3_validation                    Prophet\n",
       "34          34  FOODS_3_252_CA_2_validation      RandomForestRegressor\n",
       "35          35  FOODS_3_252_TX_1_validation                    Prophet\n",
       "36          36  FOODS_3_090_CA_2_validation      RandomForestRegressor\n",
       "37          37  FOODS_3_681_CA_3_validation  HoltWintersResultsWrapper\n",
       "38          38  FOODS_3_318_WI_3_validation      RandomForestRegressor\n",
       "39          39  FOODS_3_714_WI_3_validation  HoltWintersResultsWrapper\n",
       "40          40  FOODS_3_714_CA_1_validation                    Prophet\n",
       "41          41  FOODS_3_090_CA_4_validation                    Prophet\n",
       "42          42  FOODS_3_007_WI_2_validation      RandomForestRegressor\n",
       "43          43  FOODS_3_714_CA_3_validation                    Prophet\n",
       "44          44  FOODS_3_587_CA_1_validation      RandomForestRegressor\n",
       "45          45  FOODS_3_202_CA_3_validation  HoltWintersResultsWrapper\n",
       "46          46  FOODS_3_587_TX_2_validation  HoltWintersResultsWrapper\n",
       "47          47  FOODS_3_234_WI_2_validation  HoltWintersResultsWrapper\n",
       "48          48  FOODS_3_607_CA_3_validation                    Booster"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodelsperid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d77e2ade-155d-43f2-b676-fd8c4b203c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_filtered = train_df[train_df['id'].isin(filtered_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bed29bb3-435c-4c7e-93cf-ca208ab5ee68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_sample = train_df_filtered.melt(id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9357d41-9baa-49b9-8cc9-e5f46c8fa05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_sample.rename(columns={'variable': 'd', 'value':'sales'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2cdabd0b-3596-4d78-b3cd-e1216f64dd60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_df = train_df_sample.merge(calendar_df,on='d',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc759ed2-cffe-4513-9a95-82f06bdfffae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_090_CA_1_validation</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>107</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_3_120_CA_1_validation</td>\n",
       "      <td>FOODS_3_120</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_3_252_CA_1_validation</td>\n",
       "      <td>FOODS_3_252</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>19</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_3_586_CA_1_validation</td>\n",
       "      <td>FOODS_3_586</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>42</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_3_587_CA_1_validation</td>\n",
       "      <td>FOODS_3_587</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>50</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95645</th>\n",
       "      <td>FOODS_3_318_WI_3_validation</td>\n",
       "      <td>FOODS_3_318</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>14</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95646</th>\n",
       "      <td>FOODS_3_555_WI_3_validation</td>\n",
       "      <td>FOODS_3_555</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>25</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95647</th>\n",
       "      <td>FOODS_3_586_WI_3_validation</td>\n",
       "      <td>FOODS_3_586</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>44</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95648</th>\n",
       "      <td>FOODS_3_694_WI_3_validation</td>\n",
       "      <td>FOODS_3_694</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>48</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95649</th>\n",
       "      <td>FOODS_3_714_WI_3_validation</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>20</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>11613</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95650 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id      item_id  dept_id cat_id store_id  \\\n",
       "0      FOODS_3_090_CA_1_validation  FOODS_3_090  FOODS_3  FOODS     CA_1   \n",
       "1      FOODS_3_120_CA_1_validation  FOODS_3_120  FOODS_3  FOODS     CA_1   \n",
       "2      FOODS_3_252_CA_1_validation  FOODS_3_252  FOODS_3  FOODS     CA_1   \n",
       "3      FOODS_3_586_CA_1_validation  FOODS_3_586  FOODS_3  FOODS     CA_1   \n",
       "4      FOODS_3_587_CA_1_validation  FOODS_3_587  FOODS_3  FOODS     CA_1   \n",
       "...                            ...          ...      ...    ...      ...   \n",
       "95645  FOODS_3_318_WI_3_validation  FOODS_3_318  FOODS_3  FOODS     WI_3   \n",
       "95646  FOODS_3_555_WI_3_validation  FOODS_3_555  FOODS_3  FOODS     WI_3   \n",
       "95647  FOODS_3_586_WI_3_validation  FOODS_3_586  FOODS_3  FOODS     WI_3   \n",
       "95648  FOODS_3_694_WI_3_validation  FOODS_3_694  FOODS_3  FOODS     WI_3   \n",
       "95649  FOODS_3_714_WI_3_validation  FOODS_3_714  FOODS_3  FOODS     WI_3   \n",
       "\n",
       "      state_id       d  sales        date  wm_yr_wk  ... month  year  \\\n",
       "0           CA     d_1    107  2011-01-29     11101  ...     1  2011   \n",
       "1           CA     d_1      0  2011-01-29     11101  ...     1  2011   \n",
       "2           CA     d_1     19  2011-01-29     11101  ...     1  2011   \n",
       "3           CA     d_1     42  2011-01-29     11101  ...     1  2011   \n",
       "4           CA     d_1     50  2011-01-29     11101  ...     1  2011   \n",
       "...        ...     ...    ...         ...       ...  ...   ...   ...   \n",
       "95645       WI  d_1913     14  2016-04-24     11613  ...     4  2016   \n",
       "95646       WI  d_1913     25  2016-04-24     11613  ...     4  2016   \n",
       "95647       WI  d_1913     44  2016-04-24     11613  ...     4  2016   \n",
       "95648       WI  d_1913     48  2016-04-24     11613  ...     4  2016   \n",
       "95649       WI  d_1913     20  2016-04-24     11613  ...     4  2016   \n",
       "\n",
       "       event_name_1  event_type_1 event_name_2 event_type_2 snap_CA snap_TX  \\\n",
       "0               NaN           NaN          NaN          NaN       0       0   \n",
       "1               NaN           NaN          NaN          NaN       0       0   \n",
       "2               NaN           NaN          NaN          NaN       0       0   \n",
       "3               NaN           NaN          NaN          NaN       0       0   \n",
       "4               NaN           NaN          NaN          NaN       0       0   \n",
       "...             ...           ...          ...          ...     ...     ...   \n",
       "95645           NaN           NaN          NaN          NaN       0       0   \n",
       "95646           NaN           NaN          NaN          NaN       0       0   \n",
       "95647           NaN           NaN          NaN          NaN       0       0   \n",
       "95648           NaN           NaN          NaN          NaN       0       0   \n",
       "95649           NaN           NaN          NaN          NaN       0       0   \n",
       "\n",
       "       snap_WI  sell_price  \n",
       "0            0        1.25  \n",
       "1            0         NaN  \n",
       "2            0        1.48  \n",
       "3            0        1.48  \n",
       "4            0        2.28  \n",
       "...        ...         ...  \n",
       "95645        0        1.48  \n",
       "95646        0        1.68  \n",
       "95647        0        1.68  \n",
       "95648        0        1.68  \n",
       "95649        0        1.58  \n",
       "\n",
       "[95650 rows x 22 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df = merge_df.merge(prices_df,on=['store_id', 'item_id','wm_yr_wk'],how='left')\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b428e553-c303-4c1c-b301-7d37068aa852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "FOODS_3_090_CA_1_validation    1913\n",
       "FOODS_3_586_TX_3_validation    1913\n",
       "FOODS_3_090_TX_2_validation    1913\n",
       "FOODS_3_252_TX_2_validation    1913\n",
       "FOODS_3_377_TX_2_validation    1913\n",
       "FOODS_3_555_TX_2_validation    1913\n",
       "FOODS_3_586_TX_2_validation    1913\n",
       "FOODS_3_587_TX_2_validation    1913\n",
       "FOODS_3_090_TX_3_validation    1913\n",
       "FOODS_3_252_TX_3_validation    1913\n",
       "FOODS_3_377_TX_3_validation    1913\n",
       "FOODS_3_555_TX_3_validation    1913\n",
       "FOODS_3_226_WI_1_validation    1913\n",
       "FOODS_3_120_CA_1_validation    1913\n",
       "FOODS_3_007_WI_2_validation    1913\n",
       "FOODS_3_226_WI_2_validation    1913\n",
       "FOODS_3_234_WI_2_validation    1913\n",
       "FOODS_3_694_WI_2_validation    1913\n",
       "FOODS_3_090_WI_3_validation    1913\n",
       "FOODS_3_226_WI_3_validation    1913\n",
       "FOODS_3_318_WI_3_validation    1913\n",
       "FOODS_3_555_WI_3_validation    1913\n",
       "FOODS_3_586_WI_3_validation    1913\n",
       "FOODS_3_694_WI_3_validation    1913\n",
       "FOODS_3_586_TX_1_validation    1913\n",
       "FOODS_3_555_TX_1_validation    1913\n",
       "FOODS_3_252_TX_1_validation    1913\n",
       "FOODS_3_090_TX_1_validation    1913\n",
       "FOODS_3_252_CA_1_validation    1913\n",
       "FOODS_3_586_CA_1_validation    1913\n",
       "FOODS_3_587_CA_1_validation    1913\n",
       "FOODS_3_714_CA_1_validation    1913\n",
       "FOODS_3_090_CA_2_validation    1913\n",
       "FOODS_3_252_CA_2_validation    1913\n",
       "FOODS_3_586_CA_2_validation    1913\n",
       "FOODS_3_090_CA_3_validation    1913\n",
       "FOODS_3_120_CA_3_validation    1913\n",
       "FOODS_3_202_CA_3_validation    1913\n",
       "FOODS_3_252_CA_3_validation    1913\n",
       "FOODS_3_541_CA_3_validation    1913\n",
       "FOODS_3_555_CA_3_validation    1913\n",
       "FOODS_3_586_CA_3_validation    1913\n",
       "FOODS_3_587_CA_3_validation    1913\n",
       "FOODS_3_607_CA_3_validation    1913\n",
       "FOODS_3_635_CA_3_validation    1913\n",
       "FOODS_3_681_CA_3_validation    1913\n",
       "FOODS_3_714_CA_3_validation    1913\n",
       "FOODS_3_808_CA_3_validation    1913\n",
       "FOODS_3_090_CA_4_validation    1913\n",
       "FOODS_3_714_WI_3_validation    1913\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df['id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c5842e-7d08-4165-90ec-b7edfc62dcc7",
   "metadata": {},
   "source": [
    "# 0 Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "023fbbd9-6c97-41d6-bf76-920c4aee83ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_090_CA_1_validation</td>\n",
       "      <td>FOODS_3_090</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>107</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_120_CA_1_validation</td>\n",
       "      <td>FOODS_3_120</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_252_CA_1_validation</td>\n",
       "      <td>FOODS_3_252</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>19</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_586_CA_1_validation</td>\n",
       "      <td>FOODS_3_586</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>42</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-29</th>\n",
       "      <td>FOODS_3_587_CA_1_validation</td>\n",
       "      <td>FOODS_3_587</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>50</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_318_WI_3_validation</td>\n",
       "      <td>FOODS_3_318</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>14</td>\n",
       "      <td>11613</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_555_WI_3_validation</td>\n",
       "      <td>FOODS_3_555</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>25</td>\n",
       "      <td>11613</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_586_WI_3_validation</td>\n",
       "      <td>FOODS_3_586</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>44</td>\n",
       "      <td>11613</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_694_WI_3_validation</td>\n",
       "      <td>FOODS_3_694</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>48</td>\n",
       "      <td>11613</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-24</th>\n",
       "      <td>FOODS_3_714_WI_3_validation</td>\n",
       "      <td>FOODS_3_714</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1913</td>\n",
       "      <td>20</td>\n",
       "      <td>11613</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95650 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id      item_id  dept_id cat_id store_id  \\\n",
       "date                                                                            \n",
       "2011-01-29  FOODS_3_090_CA_1_validation  FOODS_3_090  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_120_CA_1_validation  FOODS_3_120  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_252_CA_1_validation  FOODS_3_252  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_586_CA_1_validation  FOODS_3_586  FOODS_3  FOODS     CA_1   \n",
       "2011-01-29  FOODS_3_587_CA_1_validation  FOODS_3_587  FOODS_3  FOODS     CA_1   \n",
       "...                                 ...          ...      ...    ...      ...   \n",
       "2016-04-24  FOODS_3_318_WI_3_validation  FOODS_3_318  FOODS_3  FOODS     WI_3   \n",
       "2016-04-24  FOODS_3_555_WI_3_validation  FOODS_3_555  FOODS_3  FOODS     WI_3   \n",
       "2016-04-24  FOODS_3_586_WI_3_validation  FOODS_3_586  FOODS_3  FOODS     WI_3   \n",
       "2016-04-24  FOODS_3_694_WI_3_validation  FOODS_3_694  FOODS_3  FOODS     WI_3   \n",
       "2016-04-24  FOODS_3_714_WI_3_validation  FOODS_3_714  FOODS_3  FOODS     WI_3   \n",
       "\n",
       "           state_id       d  sales  wm_yr_wk   weekday  ...  month  year  \\\n",
       "date                                                    ...                \n",
       "2011-01-29       CA     d_1    107     11101  Saturday  ...      1  2011   \n",
       "2011-01-29       CA     d_1      0     11101  Saturday  ...      1  2011   \n",
       "2011-01-29       CA     d_1     19     11101  Saturday  ...      1  2011   \n",
       "2011-01-29       CA     d_1     42     11101  Saturday  ...      1  2011   \n",
       "2011-01-29       CA     d_1     50     11101  Saturday  ...      1  2011   \n",
       "...             ...     ...    ...       ...       ...  ...    ...   ...   \n",
       "2016-04-24       WI  d_1913     14     11613    Sunday  ...      4  2016   \n",
       "2016-04-24       WI  d_1913     25     11613    Sunday  ...      4  2016   \n",
       "2016-04-24       WI  d_1913     44     11613    Sunday  ...      4  2016   \n",
       "2016-04-24       WI  d_1913     48     11613    Sunday  ...      4  2016   \n",
       "2016-04-24       WI  d_1913     20     11613    Sunday  ...      4  2016   \n",
       "\n",
       "            event_name_1 event_type_1 event_name_2 event_type_2 snap_CA  \\\n",
       "date                                                                      \n",
       "2011-01-29           NaN          NaN          NaN          NaN       0   \n",
       "2011-01-29           NaN          NaN          NaN          NaN       0   \n",
       "2011-01-29           NaN          NaN          NaN          NaN       0   \n",
       "2011-01-29           NaN          NaN          NaN          NaN       0   \n",
       "2011-01-29           NaN          NaN          NaN          NaN       0   \n",
       "...                  ...          ...          ...          ...     ...   \n",
       "2016-04-24           NaN          NaN          NaN          NaN       0   \n",
       "2016-04-24           NaN          NaN          NaN          NaN       0   \n",
       "2016-04-24           NaN          NaN          NaN          NaN       0   \n",
       "2016-04-24           NaN          NaN          NaN          NaN       0   \n",
       "2016-04-24           NaN          NaN          NaN          NaN       0   \n",
       "\n",
       "            snap_TX  snap_WI  sell_price  \n",
       "date                                      \n",
       "2011-01-29        0        0        1.25  \n",
       "2011-01-29        0        0         NaN  \n",
       "2011-01-29        0        0        1.48  \n",
       "2011-01-29        0        0        1.48  \n",
       "2011-01-29        0        0        2.28  \n",
       "...             ...      ...         ...  \n",
       "2016-04-24        0        0        1.48  \n",
       "2016-04-24        0        0        1.68  \n",
       "2016-04-24        0        0        1.68  \n",
       "2016-04-24        0        0        1.68  \n",
       "2016-04-24        0        0        1.58  \n",
       "\n",
       "[95650 rows x 21 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset\n",
    "merge_df['date'] = pd.to_datetime(merge_df['date'])\n",
    "merge_df.set_index('date', inplace=True)\n",
    "\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7aba503c-a29f-4f0c-8c1a-8279222635bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd',\n",
       "       'sales', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year', 'event_name_1',\n",
       "       'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX',\n",
       "       'snap_WI', 'sell_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b21ccbb8-ef5f-4cd7-aa78-aa216738475d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FILLING THE EMPTY PLACES\n",
    "merge_df['sell_price'].fillna(0, inplace=True)\n",
    "merge_df['event_name_1'].fillna('missing', inplace=True)\n",
    "merge_df['event_type_1'].fillna('missing', inplace=True)\n",
    "merge_df['event_name_2'].fillna('missing', inplace=True)\n",
    "merge_df['event_type_2'].fillna('missing', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c394d6c-7e1e-4570-bdd5-b03c0828fbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with datetime index and \"id\" column\n",
    "start_date = merge_df.index.min()\n",
    "end_date = merge_df.index.max()\n",
    "\n",
    "# Generate the complete date range\n",
    "complete_date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "# Get unique values of \"id\" column\n",
    "unique_ids = merge_df['id'].unique()\n",
    "\n",
    "merge_df = merge_df.reset_index()\n",
    "\n",
    "# Create a MultiIndex with Cartesian product of date range and unique ids\n",
    "multi_index = pd.MultiIndex.from_product([complete_date_range, unique_ids], names=['date', 'id'])\n",
    "\n",
    "# Reindex the DataFrame using the MultiIndex\n",
    "merge_df = merge_df.set_index(['date', 'id']).reindex(multi_index)\n",
    "\n",
    "# Reset the index to make \"date\" and \"id\" columns again\n",
    "merge_df = merge_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f5c4156b-8860-413e-9e54-1178d2d03650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_df.set_index(\"date\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4bd28632-fbba-4622-bf9b-e7cd07cb3e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale 'sell_price' and 'year' by using MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "merge_df[['sell_price']] = minmax_scaler.fit_transform(merge_df[['sell_price']])\n",
    "merge_df[['year']] = minmax_scaler.fit_transform(merge_df[['year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1d6e1682-e512-4ea7-aefc-97d9fee2a919",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for 'cat_id' are ['FOODS']\n",
      "The unique values for 'store_id' are ['CA_1' 'CA_2' 'CA_3' 'CA_4' 'TX_1' 'TX_2' 'TX_3' 'WI_1' 'WI_2' 'WI_3']\n",
      "The categories detected by the OneHotEncoder are [array(['FOODS'], dtype=object), array(['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1',\n",
      "       'WI_2', 'WI_3'], dtype=object)]\n",
      "The column names for the encoded values are ['cat_id_FOODS' 'store_id_CA_1' 'store_id_CA_2' 'store_id_CA_3'\n",
      " 'store_id_CA_4' 'store_id_TX_1' 'store_id_TX_2' 'store_id_TX_3'\n",
      " 'store_id_WI_1' 'store_id_WI_2' 'store_id_WI_3']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for 'cat_id'\n",
    "print(f\"The unique values for 'cat_id' are {merge_df['cat_id'].unique()}\")\n",
    "\n",
    "# Check unique values for 'store_id'\n",
    "print(f\"The unique values for 'store_id' are {merge_df['store_id'].unique()}\")\n",
    "\n",
    "# Instantiate the OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit encoder for both 'cat_id' and 'store_id'\n",
    "ohe.fit(merge_df[['cat_id', 'store_id']])\n",
    "\n",
    "# Display the detected categories for both columns\n",
    "print(f\"The categories detected by the OneHotEncoder are {ohe.categories_}\")\n",
    "\n",
    "# Display the generated names for both columns\n",
    "print(f\"The column names for the encoded values are {ohe.get_feature_names_out()}\")\n",
    "\n",
    "# Transform the 'cat_id' and 'store_id' columns\n",
    "encoded_columns = ohe.transform(merge_df[['cat_id', 'store_id']])\n",
    "\n",
    "# Drop the original 'cat_id' and 'store_id' columns\n",
    "merge_df.drop(columns=['cat_id', 'store_id'], inplace=True)\n",
    "\n",
    "# Concatenate the encoded columns to the DataFrame\n",
    "merge_df[ ohe.get_feature_names_out()] = encoded_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8ad5349-0e57-4e5b-a1a1-60e799c25eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for 'event_type_1' are ['missing' 'Sporting' 'Cultural' 'National' 'Religious']\n",
      "The categories detected by the OneHotEncoder are [array(['Cultural', 'National', 'Religious', 'Sporting', 'missing'],\n",
      "      dtype=object)]\n",
      "The column names for the encoded values are ['event_type_1_Cultural' 'event_type_1_National' 'event_type_1_Religious'\n",
      " 'event_type_1_Sporting' 'event_type_1_missing']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values\n",
    "print(f\"The unique values for 'event_type_1' are {merge_df['event_type_1'].unique()}\")\n",
    "\n",
    "# Fit encoder\n",
    "ohe.fit(merge_df[['event_type_1']])\n",
    "\n",
    "# Display the detected categories\n",
    "print(f\"The categories detected by the OneHotEncoder are {ohe.categories_}\")\n",
    "\n",
    "# Display the generated names\n",
    "print(f\"The column names for the encoded values are {ohe.get_feature_names_out()}\")\n",
    "\n",
    "# Transform the current \"cat_id\" column\n",
    "merge_df[ohe.get_feature_names_out()] = ohe.transform(merge_df[['event_type_1']])\n",
    "\n",
    "# Drop the column \"cat_id\" which has been encoded\n",
    "merge_df.drop(columns = ['event_type_1'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "adefde7a-880f-49e2-ac3d-05570dce8685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for 'event_type_2' are ['missing' 'Cultural' 'Religious']\n",
      "The categories detected by the OneHotEncoder are [array(['Cultural', 'Religious', 'missing'], dtype=object)]\n",
      "The column names for the encoded values are ['event_type_2_Cultural' 'event_type_2_Religious' 'event_type_2_missing']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values\n",
    "print(f\"The unique values for 'event_type_2' are {merge_df['event_type_2'].unique()}\")\n",
    "\n",
    "# Fit encoder\n",
    "ohe.fit(merge_df[['event_type_2']])\n",
    "\n",
    "# Display the detected categories\n",
    "print(f\"The categories detected by the OneHotEncoder are {ohe.categories_}\")\n",
    "\n",
    "# Display the generated names\n",
    "print(f\"The column names for the encoded values are {ohe.get_feature_names_out()}\")\n",
    "\n",
    "# Transform the current \"cat_id\" column\n",
    "merge_df[ohe.get_feature_names_out()] = ohe.transform(merge_df[['event_type_2']])\n",
    "\n",
    "# Drop the column \"cat_id\" which has been encoded\n",
    "merge_df.drop(columns = ['event_type_2'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e24abdb8-3be4-4608-91b0-ef0331e80133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for 'event_name_1' are ['missing' 'SuperBowl' 'ValentinesDay' 'PresidentsDay' 'LentStart'\n",
      " 'LentWeek2' 'StPatricksDay' 'Purim End' 'OrthodoxEaster' 'Pesach End'\n",
      " 'Cinco De Mayo' \"Mother's day\" 'MemorialDay' 'NBAFinalsStart'\n",
      " 'NBAFinalsEnd' \"Father's day\" 'IndependenceDay' 'Ramadan starts'\n",
      " 'Eid al-Fitr' 'LaborDay' 'ColumbusDay' 'Halloween' 'EidAlAdha'\n",
      " 'VeteransDay' 'Thanksgiving' 'Christmas' 'Chanukah End' 'NewYear'\n",
      " 'OrthodoxChristmas' 'MartinLutherKingDay' 'Easter']\n",
      "The categories detected by the OneHotEncoder are [array(['Chanukah End', 'Christmas', 'Cinco De Mayo', 'ColumbusDay',\n",
      "       'Easter', 'Eid al-Fitr', 'EidAlAdha', \"Father's day\", 'Halloween',\n",
      "       'IndependenceDay', 'LaborDay', 'LentStart', 'LentWeek2',\n",
      "       'MartinLutherKingDay', 'MemorialDay', \"Mother's day\",\n",
      "       'NBAFinalsEnd', 'NBAFinalsStart', 'NewYear', 'OrthodoxChristmas',\n",
      "       'OrthodoxEaster', 'Pesach End', 'PresidentsDay', 'Purim End',\n",
      "       'Ramadan starts', 'StPatricksDay', 'SuperBowl', 'Thanksgiving',\n",
      "       'ValentinesDay', 'VeteransDay', 'missing'], dtype=object)]\n",
      "The column names for the encoded values are ['event_name_1_Chanukah End' 'event_name_1_Christmas'\n",
      " 'event_name_1_Cinco De Mayo' 'event_name_1_ColumbusDay'\n",
      " 'event_name_1_Easter' 'event_name_1_Eid al-Fitr' 'event_name_1_EidAlAdha'\n",
      " \"event_name_1_Father's day\" 'event_name_1_Halloween'\n",
      " 'event_name_1_IndependenceDay' 'event_name_1_LaborDay'\n",
      " 'event_name_1_LentStart' 'event_name_1_LentWeek2'\n",
      " 'event_name_1_MartinLutherKingDay' 'event_name_1_MemorialDay'\n",
      " \"event_name_1_Mother's day\" 'event_name_1_NBAFinalsEnd'\n",
      " 'event_name_1_NBAFinalsStart' 'event_name_1_NewYear'\n",
      " 'event_name_1_OrthodoxChristmas' 'event_name_1_OrthodoxEaster'\n",
      " 'event_name_1_Pesach End' 'event_name_1_PresidentsDay'\n",
      " 'event_name_1_Purim End' 'event_name_1_Ramadan starts'\n",
      " 'event_name_1_StPatricksDay' 'event_name_1_SuperBowl'\n",
      " 'event_name_1_Thanksgiving' 'event_name_1_ValentinesDay'\n",
      " 'event_name_1_VeteransDay' 'event_name_1_missing']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values\n",
    "print(f\"The unique values for 'event_name_1' are {merge_df['event_name_1'].unique()}\")\n",
    "\n",
    "# Fit encoder\n",
    "ohe.fit(merge_df[['event_name_1']])\n",
    "\n",
    "# Display the detected categories\n",
    "print(f\"The categories detected by the OneHotEncoder are {ohe.categories_}\")\n",
    "\n",
    "# Display the generated names\n",
    "print(f\"The column names for the encoded values are {ohe.get_feature_names_out()}\")\n",
    "\n",
    "# Transform the current \"cat_id\" column\n",
    "merge_df[ohe.get_feature_names_out()] = ohe.transform(merge_df[['event_name_1']])\n",
    "\n",
    "# Drop the column \"cat_id\" which has been encoded\n",
    "merge_df.drop(columns = ['event_name_1'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "63c1b1c5-3631-4720-bfd9-92f4f381c73a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for 'event_name_2' are ['missing' 'Easter' 'Cinco De Mayo' 'OrthodoxEaster' \"Father's day\"]\n",
      "The categories detected by the OneHotEncoder are [array(['Cinco De Mayo', 'Easter', \"Father's day\", 'OrthodoxEaster',\n",
      "       'missing'], dtype=object)]\n",
      "The column names for the encoded values are ['event_name_2_Cinco De Mayo' 'event_name_2_Easter'\n",
      " \"event_name_2_Father's day\" 'event_name_2_OrthodoxEaster'\n",
      " 'event_name_2_missing']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values\n",
    "print(f\"The unique values for 'event_name_2' are {merge_df['event_name_2'].unique()}\")\n",
    "\n",
    "# Fit encoder\n",
    "ohe.fit(merge_df[['event_name_2']])\n",
    "\n",
    "# Display the detected categories\n",
    "print(f\"The categories detected by the OneHotEncoder are {ohe.categories_}\")\n",
    "\n",
    "# Display the generated names\n",
    "print(f\"The column names for the encoded values are {ohe.get_feature_names_out()}\")\n",
    "\n",
    "# Transform the current \"cat_id\" column\n",
    "merge_df[ohe.get_feature_names_out()] = ohe.transform(merge_df[['event_name_2']])\n",
    "\n",
    "# Drop the column \"cat_id\" which has been encoded\n",
    "merge_df.drop(columns = ['event_name_2'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9e7ea5ba-4d85-483b-a890-f5d148cddf08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Encoding Cyclical Features for weekdays\n",
    "# Notice that Sat starts as 1 till Fri as 7 for 'wday'\n",
    "merge_df['wday_sin'] = np.sin(2 * np.pi * merge_df['wday'] /7.0)\n",
    "merge_df['wday_cos'] = np.cos(2 * np.pi * merge_df['wday'] /7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "922ddcea-9ad4-47ea-8157-2498fde75a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Encoding Cyclical Features for month\n",
    "\n",
    "merge_df['month_sin'] = np.sin(2 * np.pi * merge_df['month'] /12.0)\n",
    "merge_df['month_cos'] = np.cos(2 * np.pi * merge_df['month'] /12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "91872056-89ef-4a5b-bc70-bc2f1ebf0526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_df_scaled = merge_df.drop(columns=['d', 'wm_yr_wk','weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "250e4c27-5980-4e8f-9714-66905ab51ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dtype('O') dtype('int16') dtype('int8') dtype('float32')]\n"
     ]
    }
   ],
   "source": [
    "# Downcast numeric columns\n",
    "numeric_columns = merge_df_scaled.select_dtypes(include=['int64', 'float64']).columns\n",
    "merge_df_scaled[numeric_columns] = merge_df_scaled[numeric_columns].apply(lambda x: pd.to_numeric(x, downcast='integer' if np.issubdtype(x.dtype, np.integer) else 'float'))\n",
    "\n",
    "# Confirm the new datatypes\n",
    "print(merge_df_scaled.dtypes.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93811f0b-32c4-4beb-b498-127548d1ddf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_extraction(merge_df_scaled):\n",
    "    # Ignore all warnings within this function\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "        #lagged features\n",
    "        for i in range(1, 8):\n",
    "            merge_df_scaled[f'sales_lag_{i}'] = merge_df_scaled['sales'].shift(i)\n",
    "    \n",
    "        #lagged features per years\n",
    "        for i in range(1, 4):\n",
    "            merge_df_scaled[f'sales_lag_{i}years'] = merge_df_scaled['sales'].shift(i * 365)\n",
    "    \n",
    "            #rolling sum\n",
    "        merge_df_scaled['rolling_sum_7'] = merge_df_scaled['sales'].rolling(window=7).sum()\n",
    "        merge_df_scaled['rolling_sum_30'] = merge_df_scaled['sales'].rolling(window=30).sum()\n",
    "        merge_df_scaled['rolling_sum_60'] = merge_df_scaled['sales'].rolling(window=60).sum()\n",
    "        merge_df_scaled['rolling_sum_90'] = merge_df_scaled['sales'].rolling(window=90).sum()\n",
    "        merge_df_scaled['rolling_sum_120'] = merge_df_scaled['sales'].rolling(window=120).sum()\n",
    "    \n",
    "        #rolling average\n",
    "        merge_df_scaled['rolling_mean_7'] = merge_df_scaled['sales'].rolling(window=7).mean()\n",
    "        merge_df_scaled['rolling_mean_30'] = merge_df_scaled['sales'].rolling(window=30).mean()\n",
    "        merge_df_scaled['rolling_mean_60'] = merge_df_scaled['sales'].rolling(window=60).mean()\n",
    "        merge_df_scaled['rolling_mean_90'] = merge_df_scaled['sales'].rolling(window=90).mean()\n",
    "        merge_df_scaled['rolling_mean_120'] = merge_df_scaled['sales'].rolling(window=120).mean()\n",
    "    \n",
    "        #rolling stdv\n",
    "        merge_df_scaled['rolling_stdv_7'] = merge_df_scaled['sales'].rolling(window=7).std()\n",
    "        merge_df_scaled['rolling_stdv_30'] = merge_df_scaled['sales'].rolling(window=30).std()\n",
    "        merge_df_scaled['rolling_stdv_60'] = merge_df_scaled['sales'].rolling(window=60).std()\n",
    "        merge_df_scaled['rolling_stdv_90'] = merge_df_scaled['sales'].rolling(window=90).std()\n",
    "        merge_df_scaled['rolling_stdv_120'] = merge_df_scaled['sales'].rolling(window=120).std()\n",
    "    \n",
    "        merge_df_scaled.fillna(0,inplace=True)\n",
    "        \n",
    "\n",
    "    return merge_df_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b02df851-703f-412f-8f52-cf105070d070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_extraction_transfer_test(train_df,test_df):\n",
    "\n",
    "    # Ignore all warnings within this function\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "           \n",
    "    \n",
    "        #lagged features per years\n",
    "        for i in range(1, 4):\n",
    "            test_df[f'sales_lag_{i}years'] = train_df[f'sales_lag_{i}years'].iloc[-1]\n",
    "    \n",
    "            #rolling sum\n",
    "        test_df['rolling_sum_7'] = train_df['rolling_sum_7'].iloc[-1]\n",
    "        test_df['rolling_sum_30'] = train_df['rolling_sum_30'].iloc[-1]\n",
    "        test_df['rolling_sum_60'] = train_df['rolling_sum_60'].iloc[-1]\n",
    "        test_df['rolling_sum_90'] = train_df['rolling_sum_90'].iloc[-1]\n",
    "        test_df['rolling_sum_120'] = train_df['rolling_sum_120'].iloc[-1]\n",
    "        \n",
    "        # Rolling average\n",
    "        test_df['rolling_mean_7'] = train_df['rolling_mean_7'].iloc[-1]\n",
    "        test_df['rolling_mean_30'] = train_df['rolling_mean_30'].iloc[-1]\n",
    "        test_df['rolling_mean_60'] = train_df['rolling_mean_60'].iloc[-1]\n",
    "        test_df['rolling_mean_90'] = train_df['rolling_mean_90'].iloc[-1]\n",
    "        test_df['rolling_mean_120'] = train_df['rolling_mean_120'].iloc[-1]\n",
    "        \n",
    "        # Rolling standard deviation\n",
    "        test_df['rolling_stdv_7'] = train_df['rolling_stdv_7'].iloc[-1]\n",
    "        test_df['rolling_stdv_30'] = train_df['rolling_stdv_30'].iloc[-1]\n",
    "        test_df['rolling_stdv_60'] = train_df['rolling_stdv_60'].iloc[-1]\n",
    "        test_df['rolling_stdv_90'] = train_df['rolling_stdv_90'].iloc[-1]\n",
    "        test_df['rolling_stdv_120'] = train_df['rolling_stdv_120'].iloc[-1]\n",
    "    \n",
    "        # Identify the last available date in the training data\n",
    "        last_date_train = train_df.index[-1]\n",
    "    \n",
    "        # Fill in lagged features for the first few rows where future knowledge is available\n",
    "        #for i in range(1, 8):\n",
    "        #    # Identify the lagged date for the current lag\n",
    "        #    lagged_date = last_date_train - pd.Timedelta(days=i)\n",
    "            \n",
    "            # Fill in the lagged sales values for corresponding lagged days from the training data\n",
    "        #    test_df[f'sales_lag_{i}'] = test_df.index.map(lambda x: train_df.loc[x - pd.Timedelta(days=i), 'sales'] if x <= last_date_train else train_df[f'sales_lag_{i}'].iloc[-1])\n",
    "\n",
    "\n",
    "        # Fill in lagged features for the first few rows where future knowledge is available\n",
    "        for i in range(1, 8):\n",
    "            test_df[f'sales_lag_{i}'] = np.nan  # Initialize with NaN\n",
    "            \n",
    "            # Iterate over each row in the test DataFrame\n",
    "            for idx, row in test_df.iterrows():\n",
    "                lagged_date = idx - pd.Timedelta(days=i)  # Calculate the lagged date\n",
    "                \n",
    "                # Check if the lagged date is within the training data range\n",
    "                if lagged_date in train_df.index:\n",
    "                    test_df.at[idx, f'sales_lag_{i}'] = train_df.loc[lagged_date, 'sales']\n",
    "                else:\n",
    "                    test_df.at[idx, f'sales_lag_{i}'] = train_df['sales'].iloc[-1]\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "013dda06-1b86-4216-a9f8-366e5e27f7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_rmsse(train, test, predictions):\n",
    "    forecast_mse = mean_squared_error(test, predictions)\n",
    "    train_mse = ((train - train.shift(1)) ** 2).mean()\n",
    "    return np.sqrt(forecast_mse / train_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6e0fca26-43dc-4b21-b08e-65bd9d58aa40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_last_28_days_weights(df):\n",
    "    most_recent_date = df.index.max()\n",
    "    cutoff_date = most_recent_date - timedelta(days=27)\n",
    "    last_28_days_df = df.loc[cutoff_date:most_recent_date]\n",
    "    last_28_days_df['revenues'] = last_28_days_df['sales'] * last_28_days_df['sell_price']\n",
    "    \n",
    "    weights_df = last_28_days_df.groupby('id')['revenues'].sum()\n",
    "    weights_df = pd.DataFrame(weights_df)\n",
    "    \n",
    "    total_revenues = last_28_days_df['revenues'].sum()\n",
    "    weights_df['weights'] = weights_df['revenues'] / total_revenues\n",
    "    \n",
    "    return weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f3bb6cf5-a720-428d-9f87-b60534928ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_ttsplit(product_data,num_splits=5, days_per_split=28):\n",
    "\n",
    "    # Check if enough data is available\n",
    "    if len(product_data) < days_per_split * num_splits:\n",
    "        print(f\"Not enough data for product {id} to perform {num_splits} splits with {days_per_split} days each.\")\n",
    "        \n",
    "    \n",
    "    # Initialize time_splits as a list of empty lists\n",
    "    time_splits = [[] for _ in range(num_splits)]\n",
    "    \n",
    "    # Create data slices for 5-fold validation with each test slice being exactly 28 days\n",
    "    for i in range(1, num_splits + 1):\n",
    "        data_train = product_data.iloc[:-days_per_split * i]\n",
    "        data_test = product_data.iloc[-days_per_split * i: (-days_per_split * (i - 1) if i > 1 else None)]   \n",
    "\n",
    "        time_splits[i-1].append(data_train)\n",
    "        time_splits[i-1].append(data_test)\n",
    "        \n",
    "        \n",
    "    return time_splits\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "88094689-eeab-4710-8000-4f701df35081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_ttsplit_onlyfeatures(product_data,num_splits=5, days_per_split=28):\n",
    "\n",
    "    # Check if enough data is available\n",
    "    if len(product_data) < days_per_split * 2 * num_splits:\n",
    "        print(f\"Not enough data for product {id} to perform {num_splits} splits with {days_per_split} days each.\")\n",
    "        \n",
    "    \n",
    "    # Initialize time_splits as a list of empty lists\n",
    "    time_splits = [[] for _ in range(num_splits)]\n",
    "    \n",
    "    # Create data slices for 5-fold validation with each test slice being exactly 28 days\n",
    "    for i in range(1, num_splits + 1):\n",
    "        data_train = product_data.iloc[:-days_per_split * i]\n",
    "        data_test = product_data.iloc[-days_per_split * i: (-days_per_split * (i - 1) if i > 1 else None)]   \n",
    "\n",
    "        data_train = feature_extraction(data_train)\n",
    "        data_test = feature_extraction_transfer_test(data_train,data_test)\n",
    "\n",
    "        data_test = data_test[data_train.columns]\n",
    "\n",
    "        time_splits[i-1].append(data_train)\n",
    "        time_splits[i-1].append(data_test)\n",
    "        \n",
    "        \n",
    "    return time_splits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1b50d66-f364-4758-a13c-8c770e34777a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_ttsplit_inclval(product_data,num_splits=5, days_per_split=28):\n",
    "\n",
    "    # Check if enough data is available\n",
    "    if len(product_data) < days_per_split * 2 * num_splits:\n",
    "        print(f\"Not enough data for product {id} to perform {num_splits} splits with {days_per_split} days each.\")\n",
    "        \n",
    "    \n",
    "    # Initialize time_splits as a list of empty lists\n",
    "    time_splits = [[] for _ in range(num_splits)]\n",
    "    \n",
    "    # Create data slices for 5-fold validation with each test slice being exactly 28 days\n",
    "    for i in range(1, num_splits + 1):\n",
    "        data_train_incl_val = product_data.iloc[:-days_per_split * i]\n",
    "        data_test = product_data.iloc[-days_per_split * i: (-days_per_split * (i - 1) if i > 1 else None)]   \n",
    "\n",
    "        data_train_incl_val = feature_extraction(data_train_incl_val)\n",
    "        data_test = feature_extraction_transfer_test(data_train_incl_val,data_test)\n",
    "        data_train = data_train_incl_val[:-days_per_split]\n",
    "        data_val = data_train_incl_val[-days_per_split:]\n",
    "\n",
    "        time_splits[i-1].append(data_train)\n",
    "        time_splits[i-1].append(data_val)\n",
    "        time_splits[i-1].append(data_test)\n",
    "        \n",
    "        \n",
    "    return time_splits\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d1e8448-ecde-4944-99b4-30f74e5f489a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_df_scaled.drop(columns=[\"item_id\",\"dept_id\",\"state_id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d9391eb6-da51-4b69-a4aa-5fd1ccba9db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_df_scaled.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "13a35134-1f8a-436c-b168-111341c17cdf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FOODS_3_090_CA_1_validation', 'FOODS_3_120_CA_1_validation',\n",
       "       'FOODS_3_252_CA_1_validation', 'FOODS_3_586_CA_1_validation',\n",
       "       'FOODS_3_587_CA_1_validation', 'FOODS_3_714_CA_1_validation',\n",
       "       'FOODS_3_090_CA_2_validation', 'FOODS_3_252_CA_2_validation',\n",
       "       'FOODS_3_586_CA_2_validation', 'FOODS_3_090_CA_3_validation',\n",
       "       'FOODS_3_120_CA_3_validation', 'FOODS_3_202_CA_3_validation',\n",
       "       'FOODS_3_252_CA_3_validation', 'FOODS_3_541_CA_3_validation',\n",
       "       'FOODS_3_555_CA_3_validation', 'FOODS_3_586_CA_3_validation',\n",
       "       'FOODS_3_587_CA_3_validation', 'FOODS_3_607_CA_3_validation',\n",
       "       'FOODS_3_635_CA_3_validation', 'FOODS_3_681_CA_3_validation',\n",
       "       'FOODS_3_714_CA_3_validation', 'FOODS_3_808_CA_3_validation',\n",
       "       'FOODS_3_090_CA_4_validation', 'FOODS_3_090_TX_1_validation',\n",
       "       'FOODS_3_252_TX_1_validation', 'FOODS_3_555_TX_1_validation',\n",
       "       'FOODS_3_586_TX_1_validation', 'FOODS_3_090_TX_2_validation',\n",
       "       'FOODS_3_252_TX_2_validation', 'FOODS_3_377_TX_2_validation',\n",
       "       'FOODS_3_555_TX_2_validation', 'FOODS_3_586_TX_2_validation',\n",
       "       'FOODS_3_587_TX_2_validation', 'FOODS_3_090_TX_3_validation',\n",
       "       'FOODS_3_252_TX_3_validation', 'FOODS_3_377_TX_3_validation',\n",
       "       'FOODS_3_555_TX_3_validation', 'FOODS_3_586_TX_3_validation',\n",
       "       'FOODS_3_226_WI_1_validation', 'FOODS_3_007_WI_2_validation',\n",
       "       'FOODS_3_226_WI_2_validation', 'FOODS_3_234_WI_2_validation',\n",
       "       'FOODS_3_694_WI_2_validation', 'FOODS_3_090_WI_3_validation',\n",
       "       'FOODS_3_226_WI_3_validation', 'FOODS_3_318_WI_3_validation',\n",
       "       'FOODS_3_555_WI_3_validation', 'FOODS_3_586_WI_3_validation',\n",
       "       'FOODS_3_694_WI_3_validation', 'FOODS_3_714_WI_3_validation'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df_scaled[\"id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "199ce411-79fa-4af8-a0cb-0bb69d6e4d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "763"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df_scaled['sales'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c90d7-181f-4c34-b9db-73d5632292e5",
   "metadata": {},
   "source": [
    "# 1. Defining Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "44c2e333-1676-4450-a8ac-b1d64ce1fee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_prophet(data_train, data_test):\n",
    "\n",
    "    temp_rmsse = []\n",
    "\n",
    "    data_train.reset_index(inplace=True,names=\"date\")\n",
    "    data_test.reset_index(inplace=True,names=\"date\")\n",
    "    \n",
    "    prophet_data_train = data_train[[\"id\",\"date\",\"sales\"]]\n",
    "    prophet_data_test = data_test[[\"id\",\"date\",\"sales\"]]\n",
    "    prophet_data_train.columns = [\"id\",\"ds\",\"y\"]\n",
    "    prophet_data_test.columns = [\"id\",\"ds\",\"y\"]\n",
    "    prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
    "    prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
    "    \n",
    "    X_train = prophet_data_train[\"ds\"]\n",
    "    y_train = prophet_data_train[\"y\"]\n",
    "    X_test = prophet_data_test[\"ds\"]\n",
    "    y_test = prophet_data_test[\"y\"]\n",
    "    \n",
    "    fbp = Prophet()\n",
    "\n",
    "    model = fbp.fit(prophet_data_train)\n",
    "    \n",
    "    predict_placeholder = fbp.make_future_dataframe(28,freq=\"D\")\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = fbp.predict(predict_placeholder[-28:])\n",
    "    \n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    rmsse = calc_rmsse(y_train, y_test, y_pred[\"yhat\"])\n",
    "    \n",
    "    return model, rmsse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "40e117ca-6a4c-42d0-9a8d-ae22cec86ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to perform Random Forest modeling and calculate MAE\n",
    "def perform_random_forest(data_train, data_test):\n",
    "        \n",
    "    X_train = data_train.drop(columns=\"sales\")\n",
    "    y_train = data_train[\"sales\"]\n",
    "    X_test = data_test.drop(columns=\"sales\")\n",
    "    y_test = data_test[\"sales\"]\n",
    "\n",
    "    # Fit Random Forest model on the training data\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate wRMSSE\n",
    "    rmsse = calc_rmsse(y_train,y_test, predictions)\n",
    "    \n",
    "    return model, rmsse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "151bd3d5-e70c-41ef-8a3e-2da51e4fe900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_auto_arima(data_train,data_test):\n",
    "    \n",
    "\n",
    "    y_train = data_train[\"sales\"]\n",
    "    y_test = data_test[\"sales\"]\n",
    "\n",
    "    # Fit ARIMA model on the training data using auto_arima to find the best (p, d, q)\n",
    "    model = auto_arima(y_train, start_p=0, start_q=0, max_p=5, max_q=5, d=1,\n",
    "                       seasonal=True, trace=False, error_action='ignore', \n",
    "                       suppress_warnings=True, stepwise=True)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(n_periods=len(y_test))\n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    rmsse = calc_rmsse(y_train,y_test,predictions)\n",
    "    \n",
    "    return model, rmsse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bc9e1224-e66f-4e66-bad4-dd867e626f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_optuna(trial, y_train, y_test):\n",
    "    \n",
    "    trend = trial.suggest_categorical('trend', ['add'])\n",
    "    seasonal = trial.suggest_categorical('seasonal', [None, 'add'])\n",
    "    seasonal_periods = trial.suggest_categorical('seasonal_periods', [None, 4, 7, 12])\n",
    "    \n",
    "    product_results = []\n",
    "\n",
    "    # Fit Holt-Winters model on the training data\n",
    "    model = ExponentialSmoothing(y_train, trend=trend, seasonal=seasonal, seasonal_periods=seasonal_periods,freq='D')\n",
    "    fitted_model = model.fit(optimized=True)\n",
    "\n",
    "    # Predict on the test data\n",
    "    predictions = fitted_model.forecast(steps=len(y_test))\n",
    "\n",
    "    # Calculate and store the error metric\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    rmsse = calc_rmsse(y_train,y_test, predictions)\n",
    "    product_results.append(rmsse)\n",
    "\n",
    "    # Average MAE for this product\n",
    "    average_rmsse = np.mean(product_results)\n",
    "    return average_rmsse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "102b594c-39b7-4817-bb4b-f3d5706c0d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_exp_smoothing(data_train, data_test):\n",
    "    y_train = data_train[\"sales\"]\n",
    "    y_test = data_test[\"sales\"]\n",
    "    # Create a study object\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    print(f\"Optimizing hyperparameters for product: {id}\")\n",
    "    \n",
    "    \n",
    "    # Run the optimization process for the current product\n",
    "    study.optimize(lambda trial: objective_optuna(trial, y_train, y_test), n_trials=10, n_jobs=-1)\n",
    "\n",
    "    # Get the best hyperparameters and the corresponding best MAE\n",
    "    best_params = study.best_params\n",
    "    best_rmsse = study.best_value\n",
    "\n",
    "    # Create the best model with the obtained hyperparameters\n",
    "    best_model = ExponentialSmoothing(y_train, **best_params).fit()\n",
    "    \n",
    "    return best_model, best_rmsse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e96217a-a286-4ecd-b8d3-9d23a0fc3811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_lightgbm(data_train, data_val, data_test):\n",
    "    \n",
    "    X_train = data_train.drop(columns=\"sales\")\n",
    "    y_train = data_train[\"sales\"]\n",
    "    X_val = data_val.drop(columns=\"sales\")\n",
    "    y_val = data_val[\"sales\"]\n",
    "    X_test = data_test.drop(columns=\"sales\")\n",
    "    y_test = data_test[\"sales\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define LightGBM parameters\n",
    "    params = {\n",
    "        \"n_estimators\": 1000,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"max_depth\": -1,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.4,\n",
    "        \"lambda_l1\": 1,\n",
    "        \"lambda_l2\": 1,\n",
    "        \"seed\": 46,\n",
    "        \"verbose\": -1\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    \n",
    "    # Create dataset for LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    # Train the model\n",
    "    num_round = 1000\n",
    "\n",
    "    bst = lgb.train(params, lgb_train, num_round, valid_sets=lgb_eval, callbacks=[lgb.early_stopping(stopping_rounds=50)])\n",
    "     \n",
    "    # Make predictions for the next 28 days\n",
    "    predictions = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "    # Calculate and return the error metric for the current fold\n",
    "    rmsse = calc_rmsse(y_train,y_test, predictions)\n",
    "    \n",
    "    return bst, rmsse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "49177452-a384-4cbe-9513-2d5e6d341606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(product_data):\n",
    "    target = product_data[['sales']]\n",
    "    past_cov = product_data.drop(columns=['sales', 'id']) # ,'item_id','dept_id','state_id','event_name_2'\n",
    "    future_cov = product_data.drop(columns=['sales','id']) # ,'item_id','dept_id','state_id','event_name_2'\n",
    "\n",
    "    y_train = target.loc[:'2016-01-01']\n",
    "    past_cov_train = past_cov.loc[:'2016-01-01']\n",
    "    future_cov_train = future_cov.loc[:'2016-01-29']\n",
    "\n",
    "    y_val = target.loc['2016-01-02':'2016-04-24']\n",
    "    past_cov_val = past_cov.loc['2016-01-02':'2016-04-24']\n",
    "    future_cov_val = future_cov.loc['2016-01-02':'2016-05-22']\n",
    "\n",
    "    return (y_train, past_cov_train, future_cov_train,\n",
    "            y_val, past_cov_val, future_cov_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2a38bf15-f7de-422c-b174-b00f28c44c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_tft_model(y_train_series, past_cov_train_series, future_cov_train_series,\n",
    "                    y_val_series, past_cov_val_series, future_cov_val_series):\n",
    "    input_chunk_length = 28*2\n",
    "    output_chunk_length = 28\n",
    "\n",
    "    from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "    from pytorch_lightning.loggers import CSVLogger\n",
    "    csv_logger = CSVLogger(\"logs\", name=\"tft_logs\")\n",
    "    patience = 5\n",
    "    my_stopper = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=patience,\n",
    "        min_delta=0.001,\n",
    "        mode='min',\n",
    "    )\n",
    "\n",
    "    pl_trainer_kwargs={\"callbacks\": [my_stopper],\n",
    "                       \"accelerator\": \"cpu\",\n",
    "                      \"logger\": csv_logger}\n",
    "\n",
    "    tft = TFTModel(input_chunk_length=input_chunk_length,\n",
    "                   output_chunk_length=output_chunk_length,\n",
    "                   pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "                   lstm_layers=2,\n",
    "                   num_attention_heads=4,\n",
    "                   dropout=0.2,\n",
    "                   batch_size=16,\n",
    "                   hidden_size=16,\n",
    "                   torch_metrics=MeanAbsoluteError(),\n",
    "                   n_epochs=50)\n",
    "\n",
    "    tft.fit(series=y_train_series,\n",
    "            past_covariates=past_cov_train_series,\n",
    "            future_covariates=future_cov_train_series,\n",
    "            val_series=y_val_series,\n",
    "            val_past_covariates=past_cov_val_series,\n",
    "            val_future_covariates=future_cov_val_series)\n",
    "\n",
    "    metrics_df = pd.read_csv(\"logs/tft_logs/version_0/metrics.csv\")\n",
    "    validation_loss = metrics_df.val_MeanAbsoluteError.dropna().iloc[-(patience+1)]\n",
    "    \n",
    "    shutil.rmtree(\"logs/tft_logs/version_0\")\n",
    "    \n",
    "    return tft, validation_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "85fd81d6-526c-42f4-95e9-4476928ce322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>best_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_3_090_CA_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_3_586_TX_2_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_3_586_TX_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_3_586_CA_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_3_090_CA_1_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FOODS_3_090_WI_3_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FOODS_3_090_TX_2_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FOODS_3_090_TX_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FOODS_3_252_TX_2_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FOODS_3_586_TX_1_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FOODS_3_555_TX_2_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FOODS_3_090_TX_1_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FOODS_3_120_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FOODS_3_586_CA_1_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FOODS_3_252_TX_3_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FOODS_3_586_WI_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FOODS_3_694_WI_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FOODS_3_252_CA_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FOODS_3_541_CA_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FOODS_3_635_CA_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FOODS_3_226_WI_1_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FOODS_3_555_TX_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FOODS_3_252_CA_1_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FOODS_3_377_TX_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>FOODS_3_808_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FOODS_3_587_CA_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>FOODS_3_226_WI_2_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FOODS_3_555_TX_1_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FOODS_3_586_CA_2_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FOODS_3_377_TX_2_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FOODS_3_120_CA_1_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>FOODS_3_694_WI_2_validation</td>\n",
       "      <td>ARIMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>FOODS_3_555_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>FOODS_3_555_WI_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FOODS_3_252_CA_2_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FOODS_3_252_TX_1_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FOODS_3_090_CA_2_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FOODS_3_681_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FOODS_3_318_WI_3_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>FOODS_3_714_WI_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>FOODS_3_714_CA_1_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FOODS_3_090_CA_4_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FOODS_3_007_WI_2_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FOODS_3_714_CA_3_validation</td>\n",
       "      <td>Prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>FOODS_3_587_CA_1_validation</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FOODS_3_202_CA_3_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>FOODS_3_587_TX_2_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FOODS_3_234_WI_2_validation</td>\n",
       "      <td>HoltWintersResultsWrapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>FOODS_3_607_CA_3_validation</td>\n",
       "      <td>Booster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                 best_model\n",
       "0   FOODS_3_090_CA_3_validation      RandomForestRegressor\n",
       "1   FOODS_3_586_TX_2_validation                    Prophet\n",
       "2   FOODS_3_586_TX_3_validation  HoltWintersResultsWrapper\n",
       "3   FOODS_3_586_CA_3_validation                    Prophet\n",
       "4   FOODS_3_090_CA_1_validation                      ARIMA\n",
       "5   FOODS_3_090_WI_3_validation                      ARIMA\n",
       "6   FOODS_3_090_TX_2_validation      RandomForestRegressor\n",
       "7   FOODS_3_090_TX_3_validation      RandomForestRegressor\n",
       "8   FOODS_3_252_TX_2_validation                    Prophet\n",
       "9   FOODS_3_586_TX_1_validation                      ARIMA\n",
       "10  FOODS_3_555_TX_2_validation                    Prophet\n",
       "11  FOODS_3_090_TX_1_validation  HoltWintersResultsWrapper\n",
       "12  FOODS_3_120_CA_3_validation  HoltWintersResultsWrapper\n",
       "13  FOODS_3_586_CA_1_validation      RandomForestRegressor\n",
       "14  FOODS_3_252_TX_3_validation                      ARIMA\n",
       "15  FOODS_3_586_WI_3_validation                    Prophet\n",
       "16  FOODS_3_694_WI_3_validation                    Prophet\n",
       "17  FOODS_3_252_CA_3_validation                    Prophet\n",
       "18  FOODS_3_541_CA_3_validation      RandomForestRegressor\n",
       "19  FOODS_3_635_CA_3_validation      RandomForestRegressor\n",
       "20  FOODS_3_226_WI_1_validation                    Prophet\n",
       "21  FOODS_3_555_TX_3_validation  HoltWintersResultsWrapper\n",
       "22  FOODS_3_252_CA_1_validation                    Prophet\n",
       "23  FOODS_3_377_TX_3_validation                    Prophet\n",
       "24  FOODS_3_808_CA_3_validation  HoltWintersResultsWrapper\n",
       "25  FOODS_3_587_CA_3_validation      RandomForestRegressor\n",
       "26  FOODS_3_226_WI_2_validation  HoltWintersResultsWrapper\n",
       "27  FOODS_3_555_TX_1_validation  HoltWintersResultsWrapper\n",
       "28  FOODS_3_586_CA_2_validation                    Prophet\n",
       "29  FOODS_3_377_TX_2_validation  HoltWintersResultsWrapper\n",
       "30  FOODS_3_120_CA_1_validation  HoltWintersResultsWrapper\n",
       "31  FOODS_3_694_WI_2_validation                      ARIMA\n",
       "32  FOODS_3_555_CA_3_validation  HoltWintersResultsWrapper\n",
       "33  FOODS_3_555_WI_3_validation                    Prophet\n",
       "34  FOODS_3_252_CA_2_validation      RandomForestRegressor\n",
       "35  FOODS_3_252_TX_1_validation                    Prophet\n",
       "36  FOODS_3_090_CA_2_validation      RandomForestRegressor\n",
       "37  FOODS_3_681_CA_3_validation  HoltWintersResultsWrapper\n",
       "38  FOODS_3_318_WI_3_validation      RandomForestRegressor\n",
       "39  FOODS_3_714_WI_3_validation  HoltWintersResultsWrapper\n",
       "40  FOODS_3_714_CA_1_validation                    Prophet\n",
       "41  FOODS_3_090_CA_4_validation                    Prophet\n",
       "42  FOODS_3_007_WI_2_validation      RandomForestRegressor\n",
       "43  FOODS_3_714_CA_3_validation                    Prophet\n",
       "44  FOODS_3_587_CA_1_validation      RandomForestRegressor\n",
       "45  FOODS_3_202_CA_3_validation  HoltWintersResultsWrapper\n",
       "46  FOODS_3_587_TX_2_validation  HoltWintersResultsWrapper\n",
       "47  FOODS_3_234_WI_2_validation  HoltWintersResultsWrapper\n",
       "48  FOODS_3_607_CA_3_validation                    Booster"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodelsperid[[\"id\",\"best_model\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b772c5e4-6892-4cf3-93c2-4e4c7cf4bead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_of_dicts = bestmodelsperid[[\"id\",\"best_model\"]].to_dict(orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4313bdf-003b-428f-addb-07ad6b7058b8",
   "metadata": {},
   "source": [
    "# 2.Running all models in a loop to find for each product with lowest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e09341ed-7407-4421-87d4-b97c92ef1fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_list = [\"ARIMA\",\"ExponentialSmoothing\", \"Prophet\", \"LightGBM\", \"RandomForest\", \"DartsTFT\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2fb14103-9737-49c8-9c2c-3643803785c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_ids.remove(\"FOODS_3_226_WI_3_validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8b525580-3a9c-4aff-aacf-f3c65381433e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RandomForestRegressor', 'Prophet', 'HoltWintersResultsWrapper',\n",
       "       'ARIMA', 'Booster'], dtype=object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodelsperid[\"best_model\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25636b8c-848f-4188-bc73-1546fdeb687b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/714081597.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_28_days_df['revenues'] = last_28_days_df['sales'] * last_28_days_df['sell_price']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing product: FOODS_3_090_CA_3_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:36:35 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 0.3667759043776664, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_090_CA_3_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.3667759043776664\n",
      "Analyzing product: FOODS_3_586_TX_2_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:36:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-16 11:36:35,220] A new study created in memory with name: no-name-e0a639f6-103d-4969-a7d2-0227633c2461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.38770427457624984, 'model': <prophet.forecaster.Prophet object at 0x7fba0e41e050>}}\n",
      "Model results for FOODS_3_586_TX_2_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.38770427457624984\n",
      "Analyzing product: FOODS_3_586_TX_3_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_586_TX_3_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:36:36,020] Trial 0 finished with value: 0.6358439824050528 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:36,046] Trial 3 finished with value: 0.6358439824050528 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:36,390] Trial 7 finished with value: 0.6358439824050528 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:36,615] Trial 4 finished with value: 0.6358439824050528 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:36,782] Trial 6 finished with value: 0.6358439824050528 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:36,956] Trial 5 finished with value: 0.7278273505470214 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:36,997] Trial 1 finished with value: 0.7278273505470214 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:37,019] Trial 8 finished with value: 0.7278273505470214 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:37,057] Trial 2 finished with value: 0.7278273505470214 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 0 with value: 0.6358439824050528.\n",
      "[I 2024-05-16 11:36:37,076] Trial 9 finished with value: 0.6749257440068105 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 0 with value: 0.6358439824050528.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:36:37 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.6358439824050528, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0e2a4f40>}}\n",
      "Model results for FOODS_3_586_TX_3_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.6358439824050528\n",
      "Analyzing product: FOODS_3_586_CA_3_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:36:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.4723531599899093, 'model': <prophet.forecaster.Prophet object at 0x7fba0e41fd60>}}\n",
      "Model results for FOODS_3_586_CA_3_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.4723531599899093\n",
      "Analyzing product: FOODS_3_090_CA_1_validation\n",
      "With best model ARIMA\n",
      "{'ARIMA': {'rmsse': 0.5453028714030256, 'model': ARIMA(order=(4, 1, 3), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}}\n",
      "Model results for FOODS_3_090_CA_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 0.5453028714030256\n",
      "Analyzing product: FOODS_3_090_WI_3_validation\n",
      "With best model ARIMA\n",
      "{'ARIMA': {'rmsse': 0.6757032994196626, 'model': ARIMA(order=(3, 1, 3), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}}\n",
      "Model results for FOODS_3_090_WI_3_validation\n",
      "Best model: ARIMA\n",
      "Best score: 0.6757032994196626\n",
      "Analyzing product: FOODS_3_090_TX_2_validation\n",
      "With best model RandomForestRegressor\n",
      "{'RandomForestRegressor': {'rmsse': 0.4302940711882724, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_090_TX_2_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.4302940711882724\n",
      "Analyzing product: FOODS_3_090_TX_3_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:37:51 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 0.3558249753150303, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_090_TX_3_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.3558249753150303\n",
      "Analyzing product: FOODS_3_252_TX_2_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:37:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.6582038206624924, 'model': <prophet.forecaster.Prophet object at 0x7fba0c5c6260>}}\n",
      "Model results for FOODS_3_252_TX_2_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.6582038206624924\n",
      "Analyzing product: FOODS_3_586_TX_1_validation\n",
      "With best model ARIMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:38:28 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARIMA': {'rmsse': 0.7426075640152381, 'model': ARIMA(order=(5, 1, 3), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}}\n",
      "Model results for FOODS_3_586_TX_1_validation\n",
      "Best model: ARIMA\n",
      "Best score: 0.7426075640152381\n",
      "Analyzing product: FOODS_3_555_TX_2_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:38:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-16 11:38:28,760] A new study created in memory with name: no-name-1cd8afdf-a20a-47af-9e96-4c9f0956f3cd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.34921088162409913, 'model': <prophet.forecaster.Prophet object at 0x7fba16a7ae90>}}\n",
      "Model results for FOODS_3_555_TX_2_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.34921088162409913\n",
      "Analyzing product: FOODS_3_090_TX_1_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_090_TX_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:38:29,748] Trial 5 finished with value: 1.2489933747504298 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 5 with value: 1.2489933747504298.\n",
      "[I 2024-05-16 11:38:30,096] Trial 6 finished with value: 1.2489933747504298 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 5 with value: 1.2489933747504298.\n",
      "[I 2024-05-16 11:38:30,872] Trial 1 finished with value: 0.9351632047508202 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 0.9351632047508202.\n",
      "[I 2024-05-16 11:38:30,909] Trial 2 finished with value: 0.9351632047508202 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 0.9351632047508202.\n",
      "[I 2024-05-16 11:38:30,982] Trial 4 finished with value: 0.9351632047508202 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 0.9351632047508202.\n",
      "[I 2024-05-16 11:38:31,018] Trial 3 finished with value: 0.9351632047508202 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 0.9351632047508202.\n",
      "[I 2024-05-16 11:38:31,047] Trial 0 finished with value: 1.3552533366650483 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 1 with value: 0.9351632047508202.\n",
      "[I 2024-05-16 11:38:31,122] Trial 7 finished with value: 0.9351632047508202 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 0.9351632047508202.\n",
      "[I 2024-05-16 11:38:31,139] Trial 8 finished with value: 1.3186562061125455 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 1 with value: 0.9351632047508202.\n",
      "[I 2024-05-16 11:38:31,172] Trial 9 finished with value: 0.9351632047508202 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 0.9351632047508202.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "[I 2024-05-16 11:38:31,443] A new study created in memory with name: no-name-ea4bfb95-3bad-4acd-ba86-9b8004963004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.9351632047508202, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0e5ae1a0>}}\n",
      "Model results for FOODS_3_090_TX_1_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.9351632047508202\n",
      "Analyzing product: FOODS_3_120_CA_3_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_120_CA_3_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:38:31,876] Trial 2 finished with value: 0.8315056891726181 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.8315056891726181.\n",
      "[I 2024-05-16 11:38:31,999] Trial 4 finished with value: 0.8315056891726181 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.8315056891726181.\n",
      "[I 2024-05-16 11:38:32,089] Trial 1 finished with value: 0.8315056891726181 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 2 with value: 0.8315056891726181.\n",
      "[I 2024-05-16 11:38:32,280] Trial 7 finished with value: 0.8315056891726181 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.8315056891726181.\n",
      "[I 2024-05-16 11:38:32,348] Trial 6 finished with value: 0.8315056891726181 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 2 with value: 0.8315056891726181.\n",
      "[I 2024-05-16 11:38:33,067] Trial 0 finished with value: 0.8430122004897865 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 2 with value: 0.8315056891726181.\n",
      "[I 2024-05-16 11:38:33,181] Trial 3 finished with value: 0.8430122004897865 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 2 with value: 0.8315056891726181.\n",
      "[I 2024-05-16 11:38:33,216] Trial 9 finished with value: 0.8590721867286752 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 2 with value: 0.8315056891726181.\n",
      "[I 2024-05-16 11:38:33,223] Trial 8 finished with value: 0.8236224418780245 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 8 with value: 0.8236224418780245.\n",
      "[I 2024-05-16 11:38:33,242] Trial 5 finished with value: 0.8590721867286752 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 8 with value: 0.8236224418780245.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.8236224418780245, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba16a7b9a0>}}\n",
      "Model results for FOODS_3_120_CA_3_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.8236224418780245\n",
      "Analyzing product: FOODS_3_586_CA_1_validation\n",
      "With best model RandomForestRegressor\n",
      "{'RandomForestRegressor': {'rmsse': 0.44416993729757503, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_586_CA_1_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.44416993729757503\n",
      "Analyzing product: FOODS_3_252_TX_3_validation\n",
      "With best model ARIMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:12 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARIMA': {'rmsse': 0.713802099956857, 'model': ARIMA(order=(2, 1, 4), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}}\n",
      "Model results for FOODS_3_252_TX_3_validation\n",
      "Best model: ARIMA\n",
      "Best score: 0.713802099956857\n",
      "Analyzing product: FOODS_3_586_WI_3_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:39:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.5470483177187816, 'model': <prophet.forecaster.Prophet object at 0x7fba3bbf4130>}}\n",
      "Model results for FOODS_3_586_WI_3_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.5470483177187816\n",
      "Analyzing product: FOODS_3_694_WI_3_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:12 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.5450079309250062, 'model': <prophet.forecaster.Prophet object at 0x7fba3bbf6c50>}}\n",
      "Model results for FOODS_3_694_WI_3_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.5450079309250062\n",
      "Analyzing product: FOODS_3_252_CA_3_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.712316233554303, 'model': <prophet.forecaster.Prophet object at 0x7fba3bbf7940>}}\n",
      "Model results for FOODS_3_252_CA_3_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.712316233554303\n",
      "Analyzing product: FOODS_3_541_CA_3_validation\n",
      "With best model RandomForestRegressor\n",
      "{'RandomForestRegressor': {'rmsse': 0.645746327464068, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_541_CA_3_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.645746327464068\n",
      "Analyzing product: FOODS_3_635_CA_3_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:13 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 0.769486923115762, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_635_CA_3_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.769486923115762\n",
      "Analyzing product: FOODS_3_226_WI_1_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-16 11:39:14,123] A new study created in memory with name: no-name-65cd88b0-747e-4e34-b60e-d23515d717ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.5292918635380535, 'model': <prophet.forecaster.Prophet object at 0x7fba0c69fbb0>}}\n",
      "Model results for FOODS_3_226_WI_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.5292918635380535\n",
      "Analyzing product: FOODS_3_555_TX_3_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_555_TX_3_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:14,586] Trial 2 finished with value: 0.5457230901804208 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.5457230901804208.\n",
      "[I 2024-05-16 11:39:14,692] Trial 0 finished with value: 0.5457230901804208 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 2 with value: 0.5457230901804208.\n",
      "[I 2024-05-16 11:39:14,805] Trial 3 finished with value: 0.5457230901804208 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.5457230901804208.\n",
      "[I 2024-05-16 11:39:15,149] Trial 5 finished with value: 0.5457230901804208 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 2 with value: 0.5457230901804208.\n",
      "[I 2024-05-16 11:39:15,223] Trial 7 finished with value: 0.5457230901804208 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.5457230901804208.\n",
      "[I 2024-05-16 11:39:15,258] Trial 9 finished with value: 0.5457230901804208 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 2 with value: 0.5457230901804208.\n",
      "[I 2024-05-16 11:39:15,313] Trial 6 finished with value: 0.5457230901804208 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.5457230901804208.\n",
      "[I 2024-05-16 11:39:15,583] Trial 1 finished with value: 0.45967629072569377 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 0.45967629072569377.\n",
      "[I 2024-05-16 11:39:15,648] Trial 4 finished with value: 0.45967629072569377 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 0.45967629072569377.\n",
      "[I 2024-05-16 11:39:15,691] Trial 8 finished with value: 0.45967629072569377 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 0.45967629072569377.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:16 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.45967629072569377, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0c5417e0>}}\n",
      "Model results for FOODS_3_555_TX_3_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.45967629072569377\n",
      "Analyzing product: FOODS_3_252_CA_1_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:16 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.47970680116178827, 'model': <prophet.forecaster.Prophet object at 0x7fba0c7ed660>}}\n",
      "Model results for FOODS_3_252_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.47970680116178827\n",
      "Analyzing product: FOODS_3_377_TX_3_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-16 11:39:16,593] A new study created in memory with name: no-name-795d91c6-5789-46c8-81eb-b87f5eba83f6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.5792791048843929, 'model': <prophet.forecaster.Prophet object at 0x7fba0c458280>}}\n",
      "Model results for FOODS_3_377_TX_3_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.5792791048843929\n",
      "Analyzing product: FOODS_3_808_CA_3_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_808_CA_3_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:17,395] Trial 2 finished with value: 1.1219096610979873 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 1.1219096610979873.\n",
      "[I 2024-05-16 11:39:17,986] Trial 6 finished with value: 1.1219096610979873 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 1.1219096610979873.\n",
      "[I 2024-05-16 11:39:18,033] Trial 9 finished with value: 1.1219096610979873 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 2 with value: 1.1219096610979873.\n",
      "[I 2024-05-16 11:39:18,060] Trial 7 finished with value: 1.1219096610979873 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 1.1219096610979873.\n",
      "[I 2024-05-16 11:39:18,276] Trial 0 finished with value: 1.142723635548296 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 2 with value: 1.1219096610979873.\n",
      "[I 2024-05-16 11:39:18,513] Trial 1 finished with value: 1.0373995311388398 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 1.0373995311388398.\n",
      "[I 2024-05-16 11:39:18,549] Trial 3 finished with value: 1.142723635548296 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 1 with value: 1.0373995311388398.\n",
      "[I 2024-05-16 11:39:18,593] Trial 5 finished with value: 1.0373995311388398 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 1.0373995311388398.\n",
      "[I 2024-05-16 11:39:18,634] Trial 4 finished with value: 1.0373995311388398 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 1.0373995311388398.\n",
      "[I 2024-05-16 11:39:18,652] Trial 8 finished with value: 1.1588161435702415 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 1 with value: 1.0373995311388398.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 1.0373995311388398, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0c77afb0>}}\n",
      "Model results for FOODS_3_808_CA_3_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 1.0373995311388398\n",
      "Analyzing product: FOODS_3_587_CA_3_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:19,566] A new study created in memory with name: no-name-7cd096e3-dc62-4b6f-9cf9-10f594fcd634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 0.5641246943975846, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_587_CA_3_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.5641246943975846\n",
      "Analyzing product: FOODS_3_226_WI_2_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_226_WI_2_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:20,269] Trial 0 finished with value: 0.8216075909836263 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 0 with value: 0.8216075909836263.\n",
      "[I 2024-05-16 11:39:20,312] Trial 1 finished with value: 0.8216075909836263 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 0 with value: 0.8216075909836263.\n",
      "[I 2024-05-16 11:39:20,491] Trial 3 finished with value: 0.8216075909836263 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 0 with value: 0.8216075909836263.\n",
      "[I 2024-05-16 11:39:20,645] Trial 5 finished with value: 0.8216075909836263 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 0.8216075909836263.\n",
      "[I 2024-05-16 11:39:20,787] Trial 9 finished with value: 0.8216075909836263 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 0.8216075909836263.\n",
      "[I 2024-05-16 11:39:21,131] Trial 4 finished with value: 0.8044561951878907 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 4 with value: 0.8044561951878907.\n",
      "[I 2024-05-16 11:39:21,281] Trial 6 finished with value: 0.8253924771590644 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 4 with value: 0.8044561951878907.\n",
      "[I 2024-05-16 11:39:21,375] Trial 8 finished with value: 0.7658606145470447 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 8 with value: 0.7658606145470447.\n",
      "[I 2024-05-16 11:39:21,428] Trial 7 finished with value: 0.7658606145470447 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 8 with value: 0.7658606145470447.\n",
      "[I 2024-05-16 11:39:21,468] Trial 2 finished with value: 0.7658606145470447 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 8 with value: 0.7658606145470447.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "[I 2024-05-16 11:39:21,770] A new study created in memory with name: no-name-b76c73b5-2906-43e5-9d17-648b39e7c6f6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.7658606145470447, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0e2a7df0>}}\n",
      "Model results for FOODS_3_226_WI_2_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.7658606145470447\n",
      "Analyzing product: FOODS_3_555_TX_1_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_555_TX_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:22,489] Trial 2 finished with value: 0.5802332676527592 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.5802332676527592.\n",
      "[I 2024-05-16 11:39:22,616] Trial 8 finished with value: 0.5802332676527592 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.5802332676527592.\n",
      "[I 2024-05-16 11:39:22,636] Trial 6 finished with value: 0.5802332676527592 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.5802332676527592.\n",
      "[I 2024-05-16 11:39:22,680] Trial 5 finished with value: 0.5802332676527592 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 0.5802332676527592.\n",
      "[I 2024-05-16 11:39:22,905] Trial 7 finished with value: 0.5802332676527592 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 0.5802332676527592.\n",
      "[I 2024-05-16 11:39:23,375] Trial 0 finished with value: 0.633779967751039 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 2 with value: 0.5802332676527592.\n",
      "[I 2024-05-16 11:39:23,567] Trial 4 finished with value: 0.5312889753706777 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 4 with value: 0.5312889753706777.\n",
      "[I 2024-05-16 11:39:23,633] Trial 1 finished with value: 0.5312889753706777 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 4 with value: 0.5312889753706777.\n",
      "[I 2024-05-16 11:39:23,665] Trial 3 finished with value: 0.5312889753706777 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 4 with value: 0.5312889753706777.\n",
      "[I 2024-05-16 11:39:23,704] Trial 9 finished with value: 0.5312889753706777 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 4 with value: 0.5312889753706777.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:24 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.5312889753706777, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0c62ec20>}}\n",
      "Model results for FOODS_3_555_TX_1_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.5312889753706777\n",
      "Analyzing product: FOODS_3_586_CA_2_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "[I 2024-05-16 11:39:24,325] A new study created in memory with name: no-name-89faa5d0-efbe-486b-9fb3-9b104ebfa456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.909479606831364, 'model': <prophet.forecaster.Prophet object at 0x7fba0c540970>}}\n",
      "Model results for FOODS_3_586_CA_2_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.909479606831364\n",
      "Analyzing product: FOODS_3_377_TX_2_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_377_TX_2_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:24,957] Trial 1 finished with value: 0.5533954107959336 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 1 with value: 0.5533954107959336.\n",
      "[I 2024-05-16 11:39:25,317] Trial 3 finished with value: 0.5533954107959336 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 1 with value: 0.5533954107959336.\n",
      "[I 2024-05-16 11:39:25,604] Trial 7 finished with value: 0.5533954107959336 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 1 with value: 0.5533954107959336.\n",
      "[I 2024-05-16 11:39:25,721] Trial 4 finished with value: 0.5533954107959336 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 1 with value: 0.5533954107959336.\n",
      "[I 2024-05-16 11:39:25,740] Trial 5 finished with value: 0.5533954107959336 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 1 with value: 0.5533954107959336.\n",
      "[I 2024-05-16 11:39:25,762] Trial 8 finished with value: 0.5533954107959336 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 1 with value: 0.5533954107959336.\n",
      "[I 2024-05-16 11:39:25,779] Trial 6 finished with value: 0.5533954107959336 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 1 with value: 0.5533954107959336.\n",
      "[I 2024-05-16 11:39:25,864] Trial 2 finished with value: 0.597565689060414 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 1 with value: 0.5533954107959336.\n",
      "[I 2024-05-16 11:39:25,919] Trial 0 finished with value: 0.4878481279193567 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.4878481279193567.\n",
      "[I 2024-05-16 11:39:25,965] Trial 9 finished with value: 0.4878481279193567 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.4878481279193567.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "[I 2024-05-16 11:39:26,256] A new study created in memory with name: no-name-92a5a014-15c3-434d-bcc5-bc9ea1cbfec3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.4878481279193567, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba16a7b310>}}\n",
      "Model results for FOODS_3_377_TX_2_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.4878481279193567\n",
      "Analyzing product: FOODS_3_120_CA_1_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_120_CA_1_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:26,652] Trial 2 finished with value: 1.3716345183479304 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 1.3716345183479304.\n",
      "[I 2024-05-16 11:39:26,772] Trial 1 finished with value: 1.3716345183479304 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 2 with value: 1.3716345183479304.\n",
      "[I 2024-05-16 11:39:26,871] Trial 3 finished with value: 1.3716345183479304 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 1.3716345183479304.\n",
      "[I 2024-05-16 11:39:27,043] Trial 5 finished with value: 1.3716345183479304 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 1.3716345183479304.\n",
      "[I 2024-05-16 11:39:27,076] Trial 8 finished with value: 1.3716345183479304 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 1.3716345183479304.\n",
      "[I 2024-05-16 11:39:27,126] Trial 6 finished with value: 1.3716345183479304 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 2 with value: 1.3716345183479304.\n",
      "[I 2024-05-16 11:39:27,534] Trial 0 finished with value: 1.348497780841098 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 0 with value: 1.348497780841098.\n",
      "[I 2024-05-16 11:39:27,736] Trial 7 finished with value: 1.2774458535239366 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 7 with value: 1.2774458535239366.\n",
      "[I 2024-05-16 11:39:27,786] Trial 4 finished with value: 1.3389941969372643 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 7 with value: 1.2774458535239366.\n",
      "[I 2024-05-16 11:39:27,815] Trial 9 finished with value: 1.3389941969372643 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 7 with value: 1.2774458535239366.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 1.2774458535239366, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba3bc8c970>}}\n",
      "Model results for FOODS_3_120_CA_1_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 1.2774458535239366\n",
      "Analyzing product: FOODS_3_694_WI_2_validation\n",
      "With best model ARIMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:42,283] A new study created in memory with name: no-name-5663b492-8096-4bcb-b2e7-2314e527aa25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ARIMA': {'rmsse': 0.6525841183435533, 'model': ARIMA(order=(2, 1, 2), scoring_args={}, suppress_warnings=True,\n",
      "      with_intercept=False)}}\n",
      "Model results for FOODS_3_694_WI_2_validation\n",
      "Best model: ARIMA\n",
      "Best score: 0.6525841183435533\n",
      "Analyzing product: FOODS_3_555_CA_3_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_555_CA_3_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:43,306] Trial 5 finished with value: 0.8534172643468753 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 5 with value: 0.8534172643468753.\n",
      "[I 2024-05-16 11:39:43,363] Trial 0 finished with value: 0.8534172643468753 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 5 with value: 0.8534172643468753.\n",
      "[I 2024-05-16 11:39:43,367] Trial 1 finished with value: 0.8534172643468753 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 5 with value: 0.8534172643468753.\n",
      "[I 2024-05-16 11:39:43,427] Trial 2 finished with value: 0.8534172643468753 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 5 with value: 0.8534172643468753.\n",
      "[I 2024-05-16 11:39:43,428] Trial 6 finished with value: 0.8534172643468753 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 5 with value: 0.8534172643468753.\n",
      "[I 2024-05-16 11:39:43,531] Trial 3 finished with value: 0.8534172643468753 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 5 with value: 0.8534172643468753.\n",
      "[I 2024-05-16 11:39:43,550] Trial 8 finished with value: 0.8534172643468753 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 5 with value: 0.8534172643468753.\n",
      "[I 2024-05-16 11:39:43,594] Trial 7 finished with value: 0.8534172643468753 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 5 with value: 0.8534172643468753.\n",
      "[I 2024-05-16 11:39:43,667] Trial 4 finished with value: 0.846604863128028 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 4 with value: 0.846604863128028.\n",
      "[I 2024-05-16 11:39:43,712] Trial 9 finished with value: 0.8674023418905182 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 4 with value: 0.846604863128028.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:44 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.846604863128028, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0c542350>}}\n",
      "Model results for FOODS_3_555_CA_3_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.846604863128028\n",
      "Analyzing product: FOODS_3_555_WI_3_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.8408542515476604, 'model': <prophet.forecaster.Prophet object at 0x7fba0d396710>}}\n",
      "Model results for FOODS_3_555_WI_3_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.8408542515476604\n",
      "Analyzing product: FOODS_3_252_CA_2_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:44 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 0.7854298550605577, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_252_CA_2_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.7854298550605577\n",
      "Analyzing product: FOODS_3_252_TX_1_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.7226083783655807, 'model': <prophet.forecaster.Prophet object at 0x7fba0c45b610>}}\n",
      "Model results for FOODS_3_252_TX_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.7226083783655807\n",
      "Analyzing product: FOODS_3_090_CA_2_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:45,692] A new study created in memory with name: no-name-ed105ef6-23a4-4ee0-93f3-903bf84a921e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 0.7339958997532022, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_090_CA_2_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.7339958997532022\n",
      "Analyzing product: FOODS_3_681_CA_3_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_681_CA_3_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:45,960] Trial 0 finished with value: 0.7470530576876717 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 0.7470530576876717.\n",
      "[I 2024-05-16 11:39:46,343] Trial 4 finished with value: 0.7470530576876717 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 0 with value: 0.7470530576876717.\n",
      "[I 2024-05-16 11:39:46,726] Trial 5 finished with value: 0.7470530576876717 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 0 with value: 0.7470530576876717.\n",
      "[I 2024-05-16 11:39:46,746] Trial 9 finished with value: 0.7470530576876717 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 0 with value: 0.7470530576876717.\n",
      "[I 2024-05-16 11:39:46,962] Trial 6 finished with value: 0.7470530576876717 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 0.7470530576876717.\n",
      "[I 2024-05-16 11:39:47,227] Trial 1 finished with value: 0.7465644725497367 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 1 with value: 0.7465644725497367.\n",
      "[I 2024-05-16 11:39:47,409] Trial 8 finished with value: 0.7279565489988991 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 8 with value: 0.7279565489988991.\n",
      "[I 2024-05-16 11:39:47,442] Trial 3 finished with value: 0.7358503137932809 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 8 with value: 0.7279565489988991.\n",
      "[I 2024-05-16 11:39:47,457] Trial 2 finished with value: 0.7279565489988991 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 8 with value: 0.7279565489988991.\n",
      "[I 2024-05-16 11:39:47,484] Trial 7 finished with value: 0.7279565489988991 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 8 with value: 0.7279565489988991.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.7279565489988991, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0c8be1d0>}}\n",
      "Model results for FOODS_3_681_CA_3_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.7279565489988991\n",
      "Analyzing product: FOODS_3_318_WI_3_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:48,307] A new study created in memory with name: no-name-37f9f527-d5e1-4378-9efe-0acef932ee39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 0.49861795873244635, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_318_WI_3_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.49861795873244635\n",
      "Analyzing product: FOODS_3_714_WI_3_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_714_WI_3_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:49,136] Trial 2 finished with value: 0.7583196193879366 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,139] Trial 4 finished with value: 0.7583196193879366 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,258] Trial 1 finished with value: 0.7583196193879366 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,316] Trial 6 finished with value: 0.7583196193879366 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,389] Trial 5 finished with value: 0.7583196193879366 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,570] Trial 8 finished with value: 0.7583196193879366 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,593] Trial 7 finished with value: 0.7583196193879366 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,653] Trial 0 finished with value: 0.7814468433455842 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,736] Trial 3 finished with value: 0.7814468433455842 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 2 with value: 0.7583196193879366.\n",
      "[I 2024-05-16 11:39:49,776] Trial 9 finished with value: 0.7648918694271121 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 2 with value: 0.7583196193879366.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:49 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.7583196193879366, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0d395b70>}}\n",
      "Model results for FOODS_3_714_WI_3_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.7583196193879366\n",
      "Analyzing product: FOODS_3_714_CA_1_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:50 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.45647331604135233, 'model': <prophet.forecaster.Prophet object at 0x7fba0c779a50>}}\n",
      "Model results for FOODS_3_714_CA_1_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.45647331604135233\n",
      "Analyzing product: FOODS_3_090_CA_4_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.5358138577232768, 'model': <prophet.forecaster.Prophet object at 0x7fba0d394940>}}\n",
      "Model results for FOODS_3_090_CA_4_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.5358138577232768\n",
      "Analyzing product: FOODS_3_007_WI_2_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2095975/1261245201.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_train['ds'] = pd.to_datetime(prophet_data_train['ds'])\n",
      "/var/tmp/ipykernel_2095975/1261245201.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prophet_data_test['ds'] = pd.to_datetime(prophet_data_test['ds'])\n",
      "11:39:51 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 1.292450437261874, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_007_WI_2_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 1.292450437261874\n",
      "Analyzing product: FOODS_3_714_CA_3_validation\n",
      "With best model Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:39:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prophet': {'rmsse': 0.8905116880083693, 'model': <prophet.forecaster.Prophet object at 0x7fba0d3948e0>}}\n",
      "Model results for FOODS_3_714_CA_3_validation\n",
      "Best model: Prophet\n",
      "Best score: 0.8905116880083693\n",
      "Analyzing product: FOODS_3_587_CA_1_validation\n",
      "With best model RandomForestRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:51,814] A new study created in memory with name: no-name-d1a7a67f-ec84-4358-9d59-a8fa9da40648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestRegressor': {'rmsse': 0.6743320253721792, 'model': RandomForestRegressor(random_state=42)}}\n",
      "Model results for FOODS_3_587_CA_1_validation\n",
      "Best model: RandomForestRegressor\n",
      "Best score: 0.6743320253721792\n",
      "Analyzing product: FOODS_3_202_CA_3_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_202_CA_3_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:52,778] Trial 6 finished with value: 1.112560539290166 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 6 with value: 1.112560539290166.\n",
      "[I 2024-05-16 11:39:52,968] Trial 2 finished with value: 1.112560539290166 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 6 with value: 1.112560539290166.\n",
      "[I 2024-05-16 11:39:53,058] Trial 7 finished with value: 1.112560539290166 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 6 with value: 1.112560539290166.\n",
      "[I 2024-05-16 11:39:53,102] Trial 5 finished with value: 1.112560539290166 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 6 with value: 1.112560539290166.\n",
      "[I 2024-05-16 11:39:53,188] Trial 1 finished with value: 0.704408092296857 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 0.704408092296857.\n",
      "[I 2024-05-16 11:39:53,208] Trial 8 finished with value: 1.112560539290166 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 1 with value: 0.704408092296857.\n",
      "[I 2024-05-16 11:39:53,458] Trial 0 finished with value: 0.704408092296857 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 1 with value: 0.704408092296857.\n",
      "[I 2024-05-16 11:39:53,619] Trial 4 finished with value: 0.704408092296857 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 1 with value: 0.704408092296857.\n",
      "[I 2024-05-16 11:39:53,632] Trial 3 finished with value: 1.127897747239765 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 1 with value: 0.704408092296857.\n",
      "[I 2024-05-16 11:39:53,657] Trial 9 finished with value: 1.127897747239765 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 1 with value: 0.704408092296857.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "[I 2024-05-16 11:39:53,950] A new study created in memory with name: no-name-3709f230-c529-46af-81fe-d6d4b139d0e2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.704408092296857, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0c45b880>}}\n",
      "Model results for FOODS_3_202_CA_3_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.704408092296857\n",
      "Analyzing product: FOODS_3_587_TX_2_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_587_TX_2_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:54,587] Trial 3 finished with value: 0.840212115247155 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': None}. Best is trial 3 with value: 0.840212115247155.\n",
      "[I 2024-05-16 11:39:54,923] Trial 5 finished with value: 0.840212115247155 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 3 with value: 0.840212115247155.\n",
      "[I 2024-05-16 11:39:55,388] Trial 8 finished with value: 0.840212115247155 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 3 with value: 0.840212115247155.\n",
      "[I 2024-05-16 11:39:55,470] Trial 7 finished with value: 0.840212115247155 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 3 with value: 0.840212115247155.\n",
      "[I 2024-05-16 11:39:55,819] Trial 1 finished with value: 0.884382733054565 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 3 with value: 0.840212115247155.\n",
      "[I 2024-05-16 11:39:55,894] Trial 2 finished with value: 0.8845637831469721 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 3 with value: 0.840212115247155.\n",
      "[I 2024-05-16 11:39:55,923] Trial 4 finished with value: 0.884382733054565 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 3 with value: 0.840212115247155.\n",
      "[I 2024-05-16 11:39:56,006] Trial 0 finished with value: 0.6125792510828659 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.6125792510828659.\n",
      "[I 2024-05-16 11:39:56,032] Trial 6 finished with value: 0.8845637831469721 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 0 with value: 0.6125792510828659.\n",
      "[I 2024-05-16 11:39:56,085] Trial 9 finished with value: 0.6125792510828659 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.6125792510828659.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "[I 2024-05-16 11:39:56,386] A new study created in memory with name: no-name-f25bcf2d-ca0d-4911-9de8-82bcb2508a24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.6125792510828659, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0d3959c0>}}\n",
      "Model results for FOODS_3_587_TX_2_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.6125792510828659\n",
      "Analyzing product: FOODS_3_234_WI_2_validation\n",
      "With best model HoltWintersResultsWrapper\n",
      "Optimizing hyperparameters for product: FOODS_3_234_WI_2_validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-16 11:39:56,618] Trial 0 finished with value: 0.6215581112021868 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 7}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:56,741] Trial 1 finished with value: 0.6215581112021868 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 12}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:57,066] Trial 5 finished with value: 0.6215581112021868 and parameters: {'trend': 'add', 'seasonal': None, 'seasonal_periods': 4}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:58,238] Trial 4 finished with value: 0.6821079794797411 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:58,241] Trial 3 finished with value: 0.6821079794797411 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 7}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:58,504] Trial 9 finished with value: 0.6763196439796808 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:58,539] Trial 8 finished with value: 0.694529707174151 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:58,588] Trial 2 finished with value: 0.6763196439796808 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 4}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:58,636] Trial 6 finished with value: 0.6821079794797411 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.6215581112021868.\n",
      "[I 2024-05-16 11:39:58,650] Trial 7 finished with value: 0.6821079794797411 and parameters: {'trend': 'add', 'seasonal': 'add', 'seasonal_periods': None}. Best is trial 0 with value: 0.6215581112021868.\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency D will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:172: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HoltWintersResultsWrapper': {'rmsse': 0.6215581112021868, 'model': <statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper object at 0x7fba0c3125c0>}}\n",
      "Model results for FOODS_3_234_WI_2_validation\n",
      "Best model: HoltWintersResultsWrapper\n",
      "Best score: 0.6215581112021868\n",
      "Analyzing product: FOODS_3_607_CA_3_validation\n",
      "With best model Booster\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 12.8075\n",
      "{'Booster': {'rmsse': 0.9149074709972956, 'model': <lightgbm.basic.Booster object at 0x7fba0c4dfa00>}}\n",
      "Model results for FOODS_3_607_CA_3_validation\n",
      "Best model: Booster\n",
      "Best score: 0.9149074709972956\n",
      "Total average wRMSSE: 0.661965816455926\n"
     ]
    }
   ],
   "source": [
    "from pmdarima import auto_arima\n",
    "\n",
    "# Dictionary to store MAE results for each unique time-series identified by id\n",
    "product_results = {}\n",
    "average_rmsse = []\n",
    "\n",
    "# download the files for 200 ids.\n",
    "filtered_df = merge_df_scaled[merge_df_scaled['id'].isin(filtered_ids)]\n",
    "weights=calculate_last_28_days_weights(filtered_df)   \n",
    "\n",
    "# Iterate over each unique product series identified by id\n",
    "for items in list_of_dicts:\n",
    "    id = items[\"id\"]\n",
    "    model_name = items[\"best_model\"]\n",
    "    print(f\"Analyzing product: {id}\")\n",
    "    print(f\"With best model {model_name}\")\n",
    "    product_data = merge_df_scaled[merge_df_scaled['id'] == id].drop(columns=\"id\")\n",
    "    product_data_with_id = merge_df_scaled[merge_df_scaled['id'] == id]\n",
    "\n",
    "    # Results list for the current product time-series\n",
    "    results = {}\n",
    "    best_score = 999.99\n",
    "    best_model_name = \"\"\n",
    "\n",
    "\n",
    "    product_weight=weights.loc[id].weights\n",
    "\n",
    "\n",
    "    if model_name == \"ARIMA\":\n",
    "        rmsse_list = []\n",
    "        # Fit ARIMA model on the training data using auto_arima to find the best (p, d, q)\n",
    "        data_train = product_data.iloc[:-28]\n",
    "        data_test = product_data.iloc[-28:]\n",
    "        model, rmsse = perform_auto_arima(data_train,data_test)\n",
    "        rmsse_list.append(rmsse)\n",
    "\n",
    "        rmsse = np.mean(rmsse_list)\n",
    "        results[model_name] = {\"rmsse\": rmsse, \"model\": model}\n",
    "        if rmsse < best_score:\n",
    "            best_score = rmsse\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "\n",
    "    elif model_name == \"HoltWintersResultsWrapper\":\n",
    "        rmsse_list = []\n",
    "        data_train = product_data.iloc[:-28]\n",
    "        data_test = product_data.iloc[-28:]\n",
    "        model, rmsse = perform_exp_smoothing(data_train, data_test)\n",
    "        rmsse_list.append(rmsse)\n",
    "\n",
    "        rmsse = np.mean(rmsse_list)\n",
    "        results[model_name] = {\"rmsse\": rmsse, \"model\": model}\n",
    "        if rmsse < best_score:\n",
    "            best_score = rmsse\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "\n",
    "    elif model_name == \"Prophet\":\n",
    "        rmsse_list = []\n",
    "        data_train = product_data_with_id.iloc[:-28]\n",
    "        data_test = product_data_with_id.iloc[-28:]\n",
    "        model, rmsse = perform_prophet(data_train,data_test)\n",
    "        rmsse_list.append(rmsse)\n",
    "\n",
    "        rmsse = np.mean(rmsse_list)\n",
    "        results[model_name] = {\"rmsse\": rmsse, \"model\": model}\n",
    "        if rmsse < best_score:\n",
    "            best_score = rmsse\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "\n",
    "\n",
    "    elif model_name == \"Booster\":\n",
    "        rmsse_list = []\n",
    "\n",
    "        data_train = product_data.iloc[:-56]\n",
    "        data_val = product_data.iloc[-56:-28]\n",
    "        data_test = product_data.iloc[-28:]\n",
    "\n",
    "        model, rmsse = perform_lightgbm(data_train, data_val, data_test)\n",
    "        rmsse_list.append(rmsse)\n",
    "\n",
    "        rmsse = np.mean(rmsse_list)\n",
    "        results[model_name] = {\"rmsse\": rmsse, \"model\": model}\n",
    "        if rmsse < best_score:\n",
    "            best_score = rmsse\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "\n",
    "\n",
    "    elif model_name == \"RandomForestRegressor\":\n",
    "        rmsse_list = []\n",
    "\n",
    "        data_train = product_data.iloc[:-28]\n",
    "        data_test = product_data.iloc[-28:]\n",
    "\n",
    "        model, rmsse = perform_random_forest(data_train, data_test)\n",
    "        rmsse_list.append(rmsse)\n",
    "\n",
    "        rmsse = np.mean(rmsse_list)\n",
    "        results[model_name] = {\"rmsse\": rmsse, \"model\": model}\n",
    "        if rmsse < best_score:\n",
    "            best_score = rmsse\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "\n",
    "\n",
    "    elif model_name == \"DartsTFT\":\n",
    "        shutil.rmtree(\"logs/tft_logs\")\n",
    "        # Prepare data for TFT model\n",
    "        (y_train, past_cov_train, future_cov_train,\n",
    "         y_val, past_cov_val, future_cov_val) = prepare_data(product_data_with_id)\n",
    "\n",
    "        # Example code assuming daily frequency ('D')\n",
    "        y_train_series = TimeSeries.from_dataframe(y_train, fill_missing_dates=True, freq='D')\n",
    "        past_cov_train_series = TimeSeries.from_dataframe(past_cov_train, fill_missing_dates=True, freq='D')\n",
    "        future_cov_train_series = TimeSeries.from_dataframe(future_cov_train, fill_missing_dates=True, freq='D')\n",
    "\n",
    "        y_val_series = TimeSeries.from_dataframe(y_val, fill_missing_dates=True, freq='D')\n",
    "        past_cov_val_series = TimeSeries.from_dataframe(past_cov_val, fill_missing_dates=True, freq='D')\n",
    "        future_cov_val_series = TimeSeries.from_dataframe(future_cov_val, fill_missing_dates=True, freq='D')\n",
    "\n",
    "        trained_model, validation_loss = train_tft_model(y_train_series, past_cov_train_series, future_cov_train_series,\n",
    "                                        y_val_series, past_cov_val_series, future_cov_val_series)\n",
    "\n",
    "\n",
    "        # Store the trained TFT model in the results dictionary\n",
    "        results[model_name] = {\"rmsse\": validation_loss, \"model\": trained_model}\n",
    "        if validation_loss < best_score:\n",
    "            best_score = validation_loss\n",
    "            best_model = trained_model\n",
    "            best_model_name = model_name\n",
    "\n",
    "\n",
    "    #Printing results for this product\n",
    "    print(results)\n",
    "    print(f\"Model results for {id}\")\n",
    "    print(f\"Best model: {best_model_name}\")\n",
    "    print(f\"Best score: {best_score}\")\n",
    "\n",
    "    average_rmsse.append(best_score*product_weight)\n",
    "\n",
    "    # Store the average MAE for the current product time-series\n",
    "    product_results[id] = {\"best_score\": best_score, \"best_model\": best_model_name, \"model\": best_model}\n",
    "\n",
    "    #Store the best model in a pkl file\n",
    "    if best_model_name == \"DartsTFT\":\n",
    "        filename = f'../models/{id}_model.pt'\n",
    "        best_model.save(filename)\n",
    "    # elif best_model_name == \"LSTM\":\n",
    "    #     filename = f'../models/{id}_model.h5'\n",
    "    #     best_model.save(filename)\n",
    "    else:\n",
    "        filename = f'../models/{id}_model.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump((best_model, product_data, data_test), f)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df_arima = pd.DataFrame(product_results.items(), columns=['id', 'RMSSE'])\n",
    "\n",
    "# Set the 'id' column as the index\n",
    "results_df_arima.set_index('id', inplace=True)\n",
    "\n",
    "average_rmsse_score = np.sum(average_rmsse)\n",
    "\n",
    "print(f\"Total average wRMSSE: {average_rmsse_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6752189-3c59-43db-bdca-1538095d58d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c2e1d-77c1-45b2-b5e1-97ded9501914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d4c26-7684-462d-bcff-9686788292e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
